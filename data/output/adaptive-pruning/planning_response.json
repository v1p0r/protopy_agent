[{"id": "chatcmpl-ff7544f4-b7a5-43c9-884e-c61695303156", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "# Reproduction Plan for APT: Adaptive Pruning and Tuning Pretrained Language Models\n\n## 1. Core Methodology Extraction\n\n### 1.1 Overall Framework\nAPT (Adaptive Pruning and Tuning) is a method that simultaneously prunes and tunes pretrained language models during fine-tuning to improve both training and inference efficiency. The key innovation is the dynamic adjustment of:\n- Pruning masks (removing unimportant parameters)\n- Tuning ranks (adding salient tuning parameters)\n\nThe framework operates by:\n1. Starting with an initial sparse configuration\n2. Dynamically pruning less important parameter blocks based on salience scores\n3. Dynamically increasing tuning capacity in more important layers\n4. Using self-distillation to maintain performance\n\n### 1.2 APT Adapter Architecture\nThe APT adapter builds upon LoRA but adds dynamic capabilities:\n\n**Mathematical Formulation:**\n```\nH_apt(X) = m_o \u2218 (W + s \u00b7 W_B W_A) X \u2218 m_i\n```\n\nWhere:\n- `m_i` \u2208 \u211d^d_i: binary input pruning mask\n- `m_o` \u2208 \u211d^d_o: binary output pruning mask  \n- `W_A` \u2208 \u211d^(r_apt \u00d7 d_i): low-rank decomposition matrix\n- `W_B` \u2208 \u211d^(d_o \u00d7 r_apt): low-rank decomposition matrix\n- `s`: scaling factor (constant)\n- `\u2218`: Hadamard product\n- `r_apt`: dynamic rank that can be increased during training\n\n**Implementation Details:**\n- Applied to queries and values in Multi-Head Attention (MHA) layers\n- Also applied to Feed-Forward Network (FFN) layers for smaller models (RoBERTa, T5)\n- Input mask `m_i` prunes transformer hidden dimensions\n- Output mask `m_o` prunes attention heads in MHA and neurons in FFN layers\n\n### 1.3 Adaptive Pruning (\ud835\udc9c\u209a)\n\n**Outlier-aware Salience Scoring:**\n```\n\u015c(W_:j) = \u03a3_(x,y\u2208\ud835\udc9f_t) \u03a3_i |\u2202\u2112/\u2202H_j,i| \u00b7 \u03a3_(x,y\u2208\ud835\udc9f_t) \u03a3_i |H_j,i| + (Kurt(O_j,:))^(1/2)\n```\n\nWhere:\n- First term: activation-gradient magnitude product (compressed across batches)\n- Second term: square root of kurtosis of activation O_j,: = W_:j \u2218 X_j,^T\n- Kurtosis captures outlier parameters important for task-specific capabilities\n\n**Efficient Search Algorithm:**\n1. Calculate salience score for each parameter block\n2. Sort blocks by salience density (salience / parameter count)\n3. Use binary search to identify top-salient blocks to retain given sparsity constraint \u03b3_t\n4. Gradually decrease pruning masks by \u03b1=0.01 instead of instant zeroing for stability\n\n### 1.4 Adaptive Tuning (\ud835\udc9c\u209c)\n\n**APT Adapter Salience Scoring:**\n```\n\ud835\udcaf(H_apt) = \u03a3_(i,j) S(W_Bi,j)\n```\nWhere S(W_Bi,j) = |W_Bi,j \u00b7 \u2202\u2112/\u2202W_Bi,j| is the standard salience score\n\n**Dynamic Rank Adjustment:**\n1. Calculate importance score \ud835\udcaf(H_apt) for each APT adapter\n2. Sort adapters by importance\n3. Increase ranks of top-half most salient adapters\n4. When increasing from \u0394_t to \u0394_t':\n   - New rank r'_apt = \u230ar_apt \u00b7 (\u0394_t' / \u0394_t)\u230b\n   - Initialize new parameters: concatenate random Gaussian N(0,\u03c3\u00b2) to W_A and zeros to W_B\n   - This preserves layer output before/after expansion\n\n### 1.5 Efficient Self-Knowledge Distillation\n\n**Distillation Objective:**\n```\n\u2112 = \u03bc\u2112_distill + (1-\u03bc)\u2112_ft\n\u2112_layer = \u03a3_(i=1)^\u03c4 MSE(Tr(H_s^\u03c6(i)), H_t^i)\n```\n\nKey features:\n- \u03bc linearly scales from 0 to 1 during training\n- Teacher model uses same parameters as student (self-distillation)\n- Only tuning layers are duplicated as teachers\n- Frozen parameters shared between teacher and student\n- \u03c4: number of randomly sampled teacher layers\n- \u03c6(\u00b7): teacher-student layer mapping function\n- Tr: tunable LoRA layer initialized as identity matrix\n\n## 2. Experimental Requirements\n\n### 2.1 Datasets\n\n**For BERT/RoBERTa/T5 Models:**\n- **GLUE Benchmark:**\n  - SST-2: Binary sentiment classification\n  - MNLI: Multi-genre Natural Language Inference\n  - QNLI, QQP, MRPC, CoLA, RTE, STS-B (mentioned in Appendix D)\n- **SQuAD v2.0:** Question answering with unanswerable questions\n- **CNN/DM:** Summarization dataset (for T5 models)\n\n**For LLaMA Models:**\n- **Alpaca Dataset:** GPT-4 generated instruction-following data\n- Evaluation on Open LLM Leaderboard tasks:\n  - 25-shot ARC (AI2 Reasoning Challenge)\n  - 10-shot HellaSwag\n  - 5-shot MMLU (Massive Multitask Language Understanding)\n  - Zero-shot TruthfulQA\n\n### 2.2 Model Architectures\n\n**Small-to-Medium Models:**\n- RoBERTa-base (12 layers, 768 hidden dim, 12 heads)\n- T5-base (encoder-decoder architecture)\n\n**Large Models:**\n- LLaMA-2 7B\n- LLaMA-2 13B (mentioned in Appendix D.3)\n\n### 2.3 Baseline Methods for Comparison\n\n**PEFT Methods:**\n- Full Fine-tuning (FT)\n- LoRA (Hu et al., 2022)\n\n**Pruning Methods:**\n- LoRA+Prune: Post-training pruning using Mask Tuning (Kwon et al., 2022)\n- Prune+Distill: CoFi (Xia et al., 2022) with L0 regularization\n- LoRA+Prune+Distill: CoFi pruning with only LoRA parameters tuned\n\n**State-of-the-Art Comparisons:**\n- LLMPruner (Ma et al., 2023): Task-agnostic pruning for LLaMA\n- PST (Li et al., 2022) and LRP (Zhang et al., 2023a): Additional baselines in Appendix D\n\n### 2.4 Hyperparameters and Training Settings\n\n**General Hyperparameters (from Table 6):**\n\n| Hyperparameter | GLUE-small | GLUE-big | SQuAD | CNN/DM | Alpaca |\n|----------------|------------|---------|-------|--------|--------|\n| Learning rate | 2e-4 | 2e-4 | 2e-4 | 1e-4 | 1e-4 |\n| Batch size | 32 | 32 | 32 | 16 | 32 |\n| Epochs | 40 | 40 | 40 | 16 | 15 |\n| Distill epochs | 20 | 20 | 20 | 6 | - |\n\n**APT-Specific Parameters:**\n- Initial adapter rank: 8\n- Scaling factor (s): 2 (static)\n- Target sparsity (\u03b3_T): Varies by experiment (60% for RoBERTa/T5, 30% for LLaMA)\n- Sparsity scheduling: Cubic schedule \u03b3_t = \u03b3_T + (1-\u03b3_T)(1-t/T)\u00b3\n- Momentum for salience averaging (\u03b2): Not specified \"\"\n- Pruning mask decay rate (\u03b1): 0.01\n- Distillation coefficient (\u03bc): Linearly increases from 0 to 1\n\n**Optimizer Settings:**\n- Standard Adam optimizer (implied, not explicitly stated) \"\"\n- Reset optimizer every time parameter sizes change (for stability)\n\n### 2.5 Implementation Architecture\n\n**Model Integration:**\n- Add APT adapters to:\n  - Query and value projections in MHA layers (all models)\n  - FFN layers (RoBERTa and T5 only, not mentioned for LLaMA)\n- For encoder-decoder models (T5), include cross-attention layers in decoder\n\n**Memory Management:**\n- Single A100 GPU for all experiments\n- Inference batch sizes:\n  - Small models: 128\n  - LLaMA 7B: 32\n  - LLaMA 13B: 4\n\n### 2.6 Evaluation Metrics\n\n**Training Efficiency Metrics:**\n- Relative training peak memory (Train Mem \u2193): Compared to full fine-tuning\n- Time to Accuracy (TTA): For small models, time to reach 97% of final accuracy\n- Training time per step: For large models (LLaMA)\n\n**Inference Efficiency Metrics:**\n- Inference peak memory (Inf Mem \u2193)\n- Inference speedup: Based on throughput (data processed per second)\n- Absolute metrics reported in Tables 11 and 12\n\n**Performance Metrics:**\n- Classification tasks: Accuracy\n- SQuAD v2.0: F1 score\n- CNN/DM: ROUGE-1/2/L scores\n- Large model evaluation: Average of four task scores\n\n## 3. Step-by-Step Implementation Plan\n\n### Step 1: Environment Setup\n1. Install PyTorch and Hugging Face Transformers library\n2. Set up single GPU environment (A100 as specified)\n3. Prepare dataset loading pipelines for all required datasets\n\n### Step 2: Base Model and Adapter Implementation\n1. Implement base transformer model classes with support for:\n   - Loading pretrained weights (RoBERTa, T5, LLaMA)\n   - Standard forward pass\n2. Implement APT adapter module with:\n   - Dynamic rank capability\n   - Input/output pruning masks\n   - Proper initialization (Gaussian for W_A, zero for W_B)\n   - Merge functionality for inference\n\n### Step 3: APT Adapter Integration\n1. Modify transformer layers to include APT adapters in:\n   - MHA query and value projections\n   - FFN layers (for RoBERTa and T5)\n2. Implement proper masking operations that respect pruning masks\n3. Ensure gradient flow only through unpruned parameters\n\n### Step 4: Adaptive Pruning Module\n1. Implement outlier-aware salience scoring function:\n   - Activation-gradient product calculation\n   - Kurtosis computation for outlier detection\n   - Batch compression to reduce memory\n2. Implement efficient search algorithm:\n   - Block sorting by salience density\n   - Binary search for sparsity-constrained selection\n   - Gradual mask updating mechanism\n\n### Step 5: Adaptive Tuning Module\n1. Implement APT adapter salience scoring:\n   - Per-parameter salience calculation\n   - Adapter-level importance aggregation\n2. Implement dynamic rank adjustment:\n   - Top-half adapter selection\n   - Rank interpolation formula\n   - Parameter initialization for new ranks\n   - Output-preserving expansion\n\n### Step 6: Self-Distillation Framework\n1. Implement teacher-student architecture with shared parameters:\n   - Duplicate tuning layers as teachers\n   - Shared frozen parameters\n2. Implement distillation objectives:\n   - Layer-wise MSE loss\n   - Dynamic layer mapping function \u03c6(\u00b7)\n   - Moving average coefficient \u03bc scheduling\n\n### Step 7: Training Loop Implementation\n1. Implement main training loop following Algorithm 1:\n   ```python\n   for t in range(T):\n       # Forward pass and loss computation\n       # Cache summed hidden states\n       # Backward pass\n       # Calculate approximated salience\n       # Update global scores with exponential moving average\n       # Select blocks via binary search against constraints\n       # Update masks gradually\n       # Apply parameter updates\n       \n       # Periodically adjust ranks based on adapter importance\n       # Reset optimizer when parameter counts change\n   ```\n\n### Step 8: Sparsity Scheduling\n1. Implement cubic sparsity scheduling:\n   ```\n   \u03b3_t = \u03b3_T + (1-\u03b3_T)(1-t/T)\u00b3\n   ```\n2. Schedule distillation coefficient \u03bc to increase linearly from 0 to 1\n\n### Step 9: Baseline Implementations\n1. Implement all comparison methods:\n   - LoRA (standard implementation)\n   - LoRA+Prune with Mask Tuning\n   - Prune+Distill (CoFi)\n   - LoRA+Prune+Distill\n   - LLMPruner (for LLaMA comparisons)\n\n### Step 10: Evaluation Framework\n1. Implement comprehensive evaluation suite:\n   - Training metrics collection (memory, time)\n   - Inference metrics collection (throughput, memory)\n   - Task-specific performance evaluation\n2. Create reporting system that matches paper's tables and figures\n\n### Step 11: Hyperparameter Configuration\n1. Set up configuration files matching Table 6 specifications\n2. Implement automatic logging of all hyperparameters\n3. Ensure reproducibility through fixed random seeds \"\"\n\n### Step 12: Experiment Execution\n1. Run experiments on specified datasets:\n   - RoBERTa on SST-2 and MNLI\n   - T5 on CNN/DM\n   - LLaMA on Alpaca\n2. Collect results for all baseline comparisons\n3. Generate all figures and tables presented in the paper\n\n## 4. Critical Ambiguities and Uncertainties\n\n1. **Optimizer Type**: The specific optimizer (Adam, AdamW, etc.) is not specified in the paper \"\"\n\n2. **Random Seeds**: The paper does not specify random seed settings for reproducibility \"\"\n\n3. **Gradient Accumulation**: Whether gradient accumulation is used for larger batch sizes is not mentioned \"\"\n\n4. **Weight Decay**: The value of weight decay, if any, is not specified \"\"\n\n5. **Salience Averaging Parameter**: The momentum parameter \u03b2 for exponential moving average of salience scores is not specified \"\"\n\n6. **Layer Mapping Function \u03c6(\u00b7)**: The exact implementation of the teacher-student layer mapping function is not detailed beyond \"closest non-pruned student layer\" \"\"\n\n7. **Block Definition**: The precise definition of parameter blocks for pruning (especially for gated FFNs in T5/LLaMA) could use more detail \"\"\n\n8. **Rank Initialization Variance**: The variance \u03c3\u00b2 for Gaussian initialization of new rank parameters is not specified \"\"\n\n9. **Multiple APT Adapters per Layer**: It's unclear if multiple APT adapters can exist in a single layer and how they're coordinated \"\"\n\n10. **Cross-Layer Dependencies**: How pruning decisions in one layer affect others isn't fully explained \"\"\n\nThis reproduction plan provides a comprehensive, step-by-step guide to implementing APT exactly as described in the paper, while clearly identifying areas where the original description lacks sufficient detail for perfect reproduction.", "refusal": null, "role": "assistant", "annotations": null, "audio": null, "function_call": null, "tool_calls": null}}], "created": 1764810306, "model": "qwen-plus", "object": "chat.completion", "service_tier": null, "system_fingerprint": null, "usage": {"completion_tokens": 3194, "prompt_tokens": 30641, "total_tokens": 33835, "completion_tokens_details": null, "prompt_tokens_details": {"audio_tokens": null, "cached_tokens": 0}}}, {"id": "chatcmpl-b62f9933-db62-41fc-b7a6-17a975f7de31", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "[EXAMPLE]\n{\n    \"file_list\": [\n        \"main.py\",\n        \"model/apt_adapter.py\",\n        \"model/base_model.py\",\n        \"pruning/adaptive_pruner.py\",\n        \"tuning/adaptive_tuner.py\",\n        \"distillation/self_distiller.py\",\n        \"train/trainer.py\",\n        \"eval/evaluator.py\",\n        \"data/dataloader.py\",\n        \"utils/salience.py\",\n        \"utils/mask_scheduler.py\",\n        \"config/hparams.py\"\n    ],\n    \"plan\": \"Step 1: Implement the APT adapter module with dynamic rank and pruning mask support. Step 2: Build base model integration for RoBERTa, T5, and LLaMA with APT adapters in MHA and FFN layers. Step 3: Implement outlier-aware salience scoring function using activation-gradient product and kurtosis. Step 4: Develop adaptive pruner that uses binary search over salience density to meet sparsity constraints. Step 5: Implement adaptive tuner that increases ranks in top-half salient adapters. Step 6: Build self-distillation framework with shared frozen parameters and tunable LoRA layers. Step 7: Create training loop with cubic sparsity scheduling and optimizer reset on shape change. Step 8: Implement data loaders for GLUE, SQuAD, CNN/DM, and Alpaca datasets. Step 9: Develop evaluation pipeline for all tasks and efficiency metrics. Step 10: Integrate all components in main execution script with proper configuration handling.\",\n    \"Code structure\": [\n        {\n            \"name\": \"model/apt_adapter\",\n            \"classes\": [\n                {\n                    \"name\": \"APTAdapter\",\n                    \"base_class\": \"nn.Module\",\n                    \"methods\": [\n                        {\n                            \"name\": \"__init__\",\n                            \"args\": [\"in_features: int\", \"out_features: int\", \"rank: int = 8\", \"scaling: float = 2.0\"],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"forward\",\n                            \"args\": [\"x: Tensor\", \"mask_in: Tensor = None\", \"mask_out: Tensor = None\"],\n                            \"returns\": \"Tensor\"\n                        },\n                        {\n                            \"name\": \"increase_rank\",\n                            \"args\": [\"new_rank: int\", \"init_type: str = 'lora'\"],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"merge_weights\",\n                            \"args\": [],\n                            \"returns\": \"None\"\n                        }\n                    ]\n                }\n            ]\n        },\n        {\n            \"name\": \"pruning/adaptive_pruner\",\n            \"classes\": [\n                {\n                    \"name\": \"AdaptivePruner\",\n                    \"methods\": [\n                        {\n                            \"name\": \"__init__\",\n                            \"args\": [\"model: nn.Module\", \"sparsity_scheduler: SparsityScheduler\"],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"compute_salience\",\n                            \"args\": [\"activations: Dict\", \"gradients: Dict\"],\n                            \"returns\": \"Dict[str, Tensor]\"\n                        },\n                        {\n                            \"name\": \"compute_outlier_score\",\n                            \"args\": [\"activations: Tensor\"],\n                            \"returns\": \"Tensor\"\n                        },\n                        {\n                            \"name\": \"generate_mask\",\n                            \"args\": [\"salience_scores: Dict\", \"current_sparsity: float\"],\n                            \"returns\": \"Dict[str, Tensor]\"\n                        },\n                        {\n                            \"name\": \"apply_mask\",\n                            \"args\": [\"masks: Dict\"],\n                            \"returns\": \"None\"\n                        }\n                    ]\n                }\n            ]\n        },\n        {\n            \"name\": \"tuning/adaptive_tuner\",\n            \"classes\": [\n                {\n                    \"name\": \"AdaptiveTuner\",\n                    \"methods\": [\n                        {\n                            \"name\": \"__init__\",\n                            \"args\": [\"model: nn.Module\", \"max_params: int\"],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"compute_adapter_salience\",\n                            \"args\": [\"named_parameters: Iterator\"],\n                            \"returns\": \"Dict[str, float]\"\n                        },\n                        {\n                            \"name\": \"adjust_ranks\",\n                            \"args\": [\"salience_dict: Dict\", \"target_params: int\"],\n                            \"returns\": \"int\"\n                        }\n                    ]\n                }\n            ]\n        },\n        {\n            \"name\": \"distillation/self_distiller\",\n            \"classes\": [\n                {\n                    \"name\": \"SelfDistiller\",\n                    \"methods\": [\n                        {\n                            \"name\": \"__init__\",\n                            \"args\": [\"student_model: nn.Module\", \"layer_mapping: Callable\"],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"compute_distill_loss\",\n                            \"args\": [\"student_outputs: List[Tensor]\", \"teacher_outputs: List[Tensor]\"],\n                            \"returns\": \"Tensor\"\n                        },\n                        {\n                            \"name\": \"forward_teacher\",\n                            \"args\": [\"x: Tensor\"],\n                            \"returns\": \"List[Tensor]\"\n                        }\n                    ]\n                }\n            ]\n        },\n        {\n            \"name\": \"train/trainer\",\n            \"classes\": [\n                {\n                    \"name\": \"APTrainer\",\n                    \"methods\": [\n                        {\n                            \"name\": \"__init__\",\n                            \"args\": [\"model: nn.Module\", \"train_dataloader: DataLoader\", \"val_dataloader: DataLoader\", \"hparams: dict\"],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"train_step\",\n                            \"args\": [\"batch: Tuple\"],\n                            \"returns\": \"Dict[str, float]\"\n                        },\n                        {\n                            \"name\": \"pruning_step\",\n                            \"args\": [],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"tuning_step\",\n                            \"args\": [],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"reset_optimizer\",\n                            \"args\": [],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"train\",\n                            \"args\": [],\n                            \"returns\": \"None\"\n                        }\n                    ]\n                }\n            ]\n        },\n        {\n            \"name\": \"eval/evaluator\",\n            \"classes\": [\n                {\n                    \"name\": \"Evaluator\",\n                    \"methods\": [\n                        {\n                            \"name\": \"__init__\",\n                            \"args\": [\"model: nn.Module\", \"test_dataloader: DataLoader\", \"task: str\"],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"evaluate\",\n                            \"args\": [],\n                            \"returns\": \"Dict[str, float]\"\n                        },\n                        {\n                            \"name\": \"measure_efficiency\",\n                            \"args\": [],\n                            \"returns\": \"Dict[str, float]\"\n                        }\n                    ]\n                }\n            ]\n        },\n        {\n            \"name\": \"data/dataloader\",\n            \"classes\": [\n                {\n                    \"name\": \"DatasetLoader\",\n                    \"methods\": [\n                        {\n                            \"name\": \"__init__\",\n                            \"args\": [\"dataset_name: str\", \"tokenizer: AutoTokenizer\", \"max_length: int\"],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"load_glue_dataset\",\n                            \"args\": [\"task_name: str\", \"split: str\"],\n                            \"returns\": \"Dataset\"\n                        },\n                        {\n                            \"name\": \"load_squad_dataset\",\n                            \"args\": [\"split: str\"],\n                            \"returns\": \"Dataset\"\n                        },\n                        {\n                            \"name\": \"load_cnndm_dataset\",\n                            \"args\": [\"split: str\"],\n                            \"returns\": \"Dataset\"\n                        },\n                        {\n                            \"name\": \"load_alpaca_dataset\",\n                            \"args\": [\"split: str\"],\n                            \"returns\": \"Dataset\"\n                        }\n                    ]\n                }\n            ]\n        },\n        {\n            \"name\": \"utils/salience\",\n            \"functions\": [\n                {\n                    \"name\": \"compute_activation_gradient_product\",\n                    \"args\": [\"activations: Tensor\", \"gradients: Tensor\"],\n                    \"returns\": \"Tensor\"\n                },\n                {\n                    \"name\": \"compute_kurtosis\",\n                    \"args\": [\"tensor: Tensor\"],\n                    \"returns\": \"Tensor\"\n                },\n                {\n                    \"name\": \"normalize_scores\",\n                    \"args\": [\"scores: Dict\", \"param_counts: Dict\"],\n                    \"returns\": \"Dict\"\n                }\n            ]\n        },\n        {\n            \"name\": \"utils/mask_scheduler\",\n            \"classes\": [\n                {\n                    \"name\": \"SparsityScheduler\",\n                    \"methods\": [\n                        {\n                            \"name\": \"__init__\",\n                            \"args\": [\"total_steps: int\", \"target_sparsity: float\", \"schedule_type: str = 'cubic'\"],\n                            \"returns\": \"None\"\n                        },\n                        {\n                            \"name\": \"get_current_sparsity\",\n                            \"args\": [\"step: int\"],\n                            \"returns\": \"float\"\n                        }\n                    ]\n                }\n            ]\n        },\n        {\n            \"name\": \"config/hparams\",\n            \"variables\": [\n                {\n                    \"name\": \"GLUE_HPARAMS\",\n                    \"type\": \"Dict\",\n                    \"description\": \"Hyperparameters for GLUE tasks\"\n                },\n                {\n                    \"name\": \"SQUAD_HPARAMS\",\n                    \"type\": \"Dict\",\n                    \"description\": \"Hyperparameters for SQuAD task\"\n                },\n                {\n                    \"name\": \"CNN_DM_HPARAMS\",\n                    \"type\": \"Dict\",\n                    \"description\": \"Hyperparameters for CNN/DM task\"\n                },\n                {\n                    \"name\": \"ALPACA_HPARAMS\",\n                    \"type\": \"Dict\",\n                    \"description\": \"Hyperparameters for Alpaca task\"\n                }\n            ]\n        }\n    ],\n    \"relationships\": [\n        {\"from\": \"APTrainer\", \"to\": \"APTAdapter\", \"type\": \"uses\"},\n        {\"from\": \"APTrainer\", \"to\": \"AdaptivePruner\", \"type\": \"uses\"},\n        {\"from\": \"APTrainer\", \"to\": \"AdaptiveTuner\", \"type\": \"uses\"},\n        {\"from\": \"APTrainer\", \"to\": \"SelfDistiller\", \"type\": \"uses\"},\n        {\"from\": \"AdaptivePruner\", \"to\": \"SparsityScheduler\", \"type\": \"uses\"},\n        {\"from\": \"AdaptivePruner\", \"to\": \"compute_activation_gradient_product\", \"type\": \"uses\"},\n        {\"from\": \"AdaptivePruner\", \"to\": \"compute_kurtosis\", \"type\": \"uses\"},\n        {\"from\": \"AdaptiveTuner\", \"to\": \"APTAdapter\", \"type\": \"uses\"},\n        {\"from\": \"SelfDistiller\", \"to\": \"APTAdapter\", \"type\": \"uses\"},\n        {\"from\": \"Evaluator\", \"to\": \"APTAdapter\", \"type\": \"uses\"},\n        {\"from\": \"DatasetLoader\", \"to\": \"APTAdapter\", \"type\": \"provides data to\"}\n    ],\n    \"pipeline or workflow\": \"The pipeline begins with loading pretrained models (RoBERTa, T5, LLaMA) and integrating APT adapters into designated layers. During training, the AdaptivePruner computes outlier-aware salience scores from activations and gradients, then generates pruning masks via binary search to meet scheduled sparsity constraints. Simultaneously, the AdaptiveTuner calculates adapter importance and increases ranks in top-salient layers. The SelfDistiller performs knowledge distillation using shared parameters between teacher and student. The APTrainer orchestrates these components with a main loop that includes forward pass, salience computation, pruning, tuning, and parameter updates, resetting the optimizer when shapes change. Evaluation measures both task performance and efficiency metrics (memory, speed). All experiments run on single A100 GPU with specified batch sizes and hyperparameters.\"\n}\n[/EXAMPLE]", "refusal": null, "role": "assistant", "annotations": null, "audio": null, "function_call": null, "tool_calls": null}}], "created": 1764810393, "model": "qwen-plus", "object": "chat.completion", "service_tier": null, "system_fingerprint": null, "usage": {"completion_tokens": 2450, "prompt_tokens": 36088, "total_tokens": 38538, "completion_tokens_details": null, "prompt_tokens_details": {"audio_tokens": null, "cached_tokens": 0}}}, {"id": "chatcmpl-501678e7-dcb3-4493-81c5-4a0dd5697c71", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "[CONTENT]\n{\n    \"Required packages\": [\n        \"torch==2.0.1\",\n        \"transformers==4.35.0\",\n        \"datasets==2.14.6\",\n        \"accelerate==0.27.2\",\n        \"numpy==1.24.3\",\n        \"tqdm==4.66.1\"\n    ],\n    \"Required Other language third-party packages\": [\n        \"No third-party dependencies required\"\n    ],\n    \"Logic Analysis\": [\n        [\n            \"config/hparams.py\",\n            \"Contains global hyperparameters for all experiments as specified in Table 6 of the paper: learning rates, batch sizes, epochs, distillation epochs for GLUE-small, GLUE-big, SQuAD, CNN/DM, and Alpaca tasks. This file is foundational and imported by nearly all other modules to ensure consistent training settings across components.\"\n        ],\n        [\n            \"model/base_model.py\",\n            \"Implements base model loading using Hugging Face Transformers. Loads RoBERTa, T5, and LLaMA architectures with frozen pretrained weights. Exposes interfaces to inject APT adapters into specific layers (MHA query/value projections and FFN). Depends on hparams for model-specific configurations and serves as the backbone for all downstream modifications.\"\n        ],\n        [\n            \"model/apt_adapter.py\",\n            \"Defines the core APTAdapter class that extends LoRA with dynamic pruning and tuning capabilities. Implements forward pass with input/output masks (m_i, m_o), low-rank update via Wa and Wb, and rank adjustment logic. Must support merging weights post-training for inference efficiency. Imports from base_model to integrate with transformer layers. Critical dependency for pruner, tuner, and trainer modules.\"\n        ],\n        [\n            \"utils/salience.py\",\n            \"Implements outlier-aware salience scoring functions: compute_activation_gradient_product computes |\u2202L/\u2202H|\u00b7|H| summed over batches; compute_kurtosis calculates kurtosis of activation tensors O=W\u2218X^T to capture outlier importance. normalize_scores adjusts salience by parameter count for density-based ranking. These utilities are used by both AdaptivePruner and AdaptiveTuner for decision-making.\"\n        ],\n        [\n            \"pruning/adaptive_pruner.py\",\n            \"Implements AdaptivePruner class that uses salience scores to generate binary pruning masks. Key methods: compute_salience aggregates activation-gradient products and kurtosis; generate_mask sorts blocks by salience density and applies binary search to meet sparsity constraint \u03b3_t; apply_mask gradually updates masks (with \u03b1=0.01 decay) for stability. Depends on apt_adapter for mask application and salience utils for scoring. Outputs W_B pruning matrices.\"\n        ],\n        [\n            \"tuning/adaptive_tuner.py\",\n            \"Implements AdaptiveTuner class that dynamically increases adapter ranks. compute_adapter_salience sums parameter-level salience S(W_Bi,j) within each adapter to get layer importance \ud835\udcaf(H_apt); adjust_ranks identifies top-half most important adapters and scales their r_apt proportionally to budget \u0394_t. On expansion, initializes new Wa rows with N(0,\u03c3\u00b2) and new Wb columns with zeros to preserve output. Depends on apt_adapter and salience utils.\"\n        ],\n        [\n            \"utils/mask_scheduler.py\",\n            \"Implements SparsityScheduler with cubic scheduling: \u03b3_t = \u03b3_T + (1\u2212\u03b3_T)(1\u2212t/T)^3. Provides get_current_sparsity(step) method called by AdaptivePruner at each step. Configured via hparams (target_sparsity, total_steps). Ensures smooth transition to target sparsity without abrupt performance drops.\"\n        ],\n        [\n            \"distillation/self_distiller.py\",\n            \"Implements SelfDistiller using shared parameters between teacher and student. Uses tunable LoRA layers (Tr) initialized as identity for transformation. Computes MSE loss between teacher Tr(H_s^\u03c6(i)) and student H_t^i outputs across \u03c4 sampled layers. \u03c6(\u00b7) maps teacher to closest non-pruned student layer. \u03bc coefficient linearly increases from 0 to 1 during training. Shares frozen parameters with student model to reduce memory overhead.\"\n        ],\n        [\n            \"data/dataloader.py\",\n            \"Implements DatasetLoader supporting multiple datasets: GLUE tasks (SST-2, MNLI), SQuAD v2.0, CNN/DM, and Alpaca instruction-following data. Handles tokenization, batching (sizes defined in paper: 128 for small models, 32/4 for LLaMA), and formatting. Returns PyTorch-compatible datasets used by trainer and evaluator. Requires tokenizer from base_model.\"\n        ],\n        [\n            \"train/trainer.py\",\n            \"Implements APTrainer orchestrating full training loop (Algorithm 1). At each step: performs forward/backward passes, caches activations/gradients, calls AdaptivePruner.pruning_step() and AdaptiveTuner.tuning_step(), applies changes, updates parameters. Resets optimizer when parameter shapes change. Integrates SelfDistiller for distillation loss (\u03bc scheduling). Manages SparsityScheduler for \u03b3_t control. Main driver module depending on all others.\"\n        ],\n        [\n            \"eval/evaluator.py\",\n            \"Implements Evaluator measuring both task performance and efficiency metrics. evaluate() computes accuracy/F1/ROUGE/MMLU etc. measure_efficiency() records peak memory (via torch.cuda.max_memory_allocated), inference time (ms), and throughput. Metrics normalized to baselines (FT, LoRA) as in Tables 2\u20133. Used post-training to generate results matching paper tables.\"\n        ],\n        [\n            \"main.py\",\n            \"Entry point executing full pipeline: loads config \u2192 initializes model with APT adapters \u2192 sets up dataloaders \u2192 instantiates pruner/tuner/distiller \u2192 launches APTrainer.train() \u2192 runs final evaluation. Coordinates experiment flow across all components. Accepts CLI args for model type, dataset, sparsity level to reproduce different ablations.\"\n        ]\n    ],\n    \"Task list\": [\n        \"config/hparams.py\",\n        \"model/base_model.py\",\n        \"model/apt_adapter.py\",\n        \"utils/salience.py\",\n        \"utils/mask_scheduler.py\",\n        \"pruning/adaptive_pruner.py\",\n        \"tuning/adaptive_tuner.py\",\n        \"distillation/self_distiller.py\",\n        \"data/dataloader.py\",\n        \"train/trainer.py\",\n        \"eval/evaluator.py\",\n        \"main.py\"\n    ],\n    \"Full API spec\": \"\",\n    \"Shared Knowledge\": \"All modules share access to hparams.py for consistent hyperparameter usage. The APTAdapter class is central\u2014both AdaptivePruner and AdaptiveTuner modify its state (masks and ranks). Salience computation functions are reused across pruning and tuning decisions. Trainer manages shared state including current step t, which drives sparsity scheduling and distillation coefficient \u03bc. Memory efficiency is maintained through shared frozen parameters in self-distillation and compressed gradient/activation storage.\",\n    \"Anything UNCLEAR\": \"Clarification needed on: (1) exact variance \u03c3\u00b2 for Gaussian initialization of new adapter weights; (2) whether gradient accumulation is used for larger effective batch sizes; (3) specific Adam optimizer variants (AdamW?) and weight decay values; (4) random seed settings for reproducibility; (5) precise implementation of layer mapping function \u03c6(\u00b7) when layers are pruned; (6) handling of gated FFNs in T5/LLaMA during block-wise pruning; (7) whether APT adapters are applied to all MHA layers uniformly or selectively.\"\n}\n[/CONTENT]", "refusal": null, "role": "assistant", "annotations": null, "audio": null, "function_call": null, "tool_calls": null}}], "created": 1764810441, "model": "qwen-plus", "object": "chat.completion", "service_tier": null, "system_fingerprint": null, "usage": {"completion_tokens": 1583, "prompt_tokens": 39226, "total_tokens": 40809, "completion_tokens_details": null, "prompt_tokens_details": {"audio_tokens": null, "cached_tokens": 0}}}, {"id": "chatcmpl-9db351ce-fb3a-4a10-bef9-4c52a5a3099d", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "## Code: config.yaml\n```yaml\n## config.yaml\ntraining:\n  learning_rate:\n    glue_small: 0.0002\n    glue_big: 0.0002\n    squad: 0.0002\n    cnn_dm: 0.0001\n    alpaca: 0.0001\n  batch_size:\n    glue_small: 32\n    glue_big: 32\n    squad: 32\n    cnn_dm: 16\n    alpaca: 32\n  epochs:\n    glue_small: 40\n    glue_big: 40\n    squad: 40\n    cnn_dm: 16\n    alpaca: 15\n  distill_epochs:\n    glue_small: 20\n    glue_big: 20\n    squad: 20\n    cnn_dm: 6\n    alpaca: null\n  target_sparsity: 0.6\n  initial_rank: 8\n  scaling_factor: 2.0\n  mask_decay_rate: 0.01\n  momentum_salience: 0.9\n  warmup_steps: null\n  optimizer: \"Adam\"\n  weight_decay: 0.0\n  max_grad_norm: 1.0\n\nmodel:\n  architectures:\n    - roberta-base\n    - t5-base\n    - llama-2-7b\n    - llama-2-13b\n  adapter:\n    apply_to_mha: true\n    apply_to_ffn: true\n    mha_components:\n      - q_proj\n      - v_proj\n    ffn_components:\n      - intermediate_dense\n      - output_dense\n\ndata:\n  datasets:\n    - sst2\n    - mnli\n    - qnli\n    - qqp\n    - mrpc\n    - cola\n    - rte\n    - stsb\n    - squad_v2\n    - cnn_dm\n    - alpaca\n  task_type:\n    classification: [sst2, mnli, qnli, qqp, mrpc, cola, rte]\n    qa: [squad_v2]\n    summarization: [cnn_dm]\n    instruction_following: [alpaca]\n  num_labels:\n    sst2: 2\n    mnli: 3\n    qnli: 2\n    qqp: 2\n    mrpc: 2\n    cola: 2\n    rte: 2\n    stsb: 1\n  max_length:\n    text: 512\n    question: 64\n    answer: 192\n    summary: 128\n    instruction: 2048\n\nevaluation:\n  inference_batch_size:\n    small_model: 128\n    llama_7b: 32\n    llama_13b: 4\n  metrics:\n    classification: accuracy\n    qa: f1\n    summarization: rouge\n    instruction_following: lm_eval_harness\n  eval_tasks:\n    open_llm_leaderboard:\n      - arc: 25-shot\n      - hellaswag: 10-shot\n      - mmlu: 5-shot\n      - truthfulqa: 0-shot\n  normalize_metrics: true\n  baseline_ft: true\n  baseline_lora: true\n\npruning:\n  scheduler: cubic\n  salience_type: outlier-aware\n  use_kurtosis: true\n  block_types:\n    - mha_head\n    - ffn_neuron\n    - hidden_dimension\n  binary_search: true\n  update_frequency: 100\n  min_sparsity: 0.0\n  target_sparsity: 0.6\n  gradual_mask_update: true\n\ntuning:\n  adaptive_rank_update: true\n  rank_increase_strategy: top_half\n  max_tuning_params_ratio: 0.1\n  init_std: 0.02\n\ndistillation:\n  use_self_distillation: true\n  share_frozen_params: true\n  teacher_layer_mapping: closest_non_pruned\n  num_teacher_layers: 6\n  distill_loss_weight_start: 0.0\n  distill_loss_weight_end: 1.0\n  distill_layers_sampled: 6\n  tr_layer_init: identity\n\nhardware:\n  gpu_type: A100\n  num_gpus: 1\n  distributed_training: false\n  precision: fp16\n```", "refusal": null, "role": "assistant", "annotations": null, "audio": null, "function_call": null, "tool_calls": null}}], "created": 1764810464, "model": "qwen-plus", "object": "chat.completion", "service_tier": null, "system_fingerprint": null, "usage": {"completion_tokens": 969, "prompt_tokens": 40986, "total_tokens": 41955, "completion_tokens_details": null, "prompt_tokens_details": {"audio_tokens": null, "cached_tokens": 0}}}]