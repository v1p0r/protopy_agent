### **Logic Analysis: rl/verl_wrapper.py — VERLWrapper Class**

---

#### **1. Purpose and Role in the System**

The `VERLWrapper` class serves as the **bridge between the RL training framework (`verl`) and the compositional machine design environment**. Its sole responsibility is to **generate multiple rollouts (candidate machine designs) for a given task prompt**, using the finetuned LLM (Qwen2.5-14B-Instruct), simulate each candidate in BesiegeField, compute the reward, and return a list of `(ConstructionTree, reward)` tuples.

This class is **critical for Pass@k evaluation and GRPO training**, as it enables the RL algorithm to:
- Sample diverse candidate designs per prompt (k=64),
- Obtain verifiable, physics-based rewards from simulation,
- Feed these rollouts back to the GRPO optimizer for policy updates.

It abstracts away the complexity of interacting with `verl`’s internal rollout mechanism and aligns it with our domain-specific data structures: `ConstructionTree` and reward computation via `SimulationEngine`.

---

#### **2. Core Method: `rollout(prompt: str, num_rollouts: int) -> list[tuple[ConstructionTree, float]]`**

##### **Input:**
- `prompt`: A natural language task description (e.g., *“Build a machine to throw a boulder as far as possible”*).
- `num_rollouts`: The number of candidate designs to generate (k=64 for Pass@64, k=1 for Pass@1).

##### **Output:**
- A list of `k` tuples: `(machine, reward)`, where:
  - `machine`: A validated `ConstructionTree` object (not raw JSON),
  - `reward`: A scalar float computed as `R = R_valid * R_task` (from `RewardCalculator`).

##### **Workflow Steps:**

1. **LLM Prompt Generation via `verl` Framework**  
   - Use `verl`’s `rollout()` API to generate `num_rollouts` text completions from the finetuned Qwen model.
   - Each completion is a **JSON-formatted string** representing a construction tree, following the schema defined in `ConstructionTree`.
   - **Prompt Template**: The prompt must be formatted identically to the cold-start dataset:
     ```
     [SYSTEM] You are an expert mechanical designer. Given the following task, generate a machine using only the 27 blocks listed below. Follow the construction rules. Output only a valid JSON list of blocks in construction order. Do not include explanations.
     
     [TASK] {prompt}
     
     [BLOCKS] {list of 27 block names}
     
     [RULES] 
     - Start with "Starting Block" (id=0).
     - Each subsequent block must have a "parent" (ID of previous block) and "face_id" (0–5, face index on parent).
     - For Spring: use "parent_a", "parent_b", "face_id_a", "face_id_b".
     - No scaling or rotation after attachment.
     - No self-collisions allowed.
     
     [OUTPUT FORMAT] 
     [{"type": "Starting Block", "id": 0, "parent": null, "face_id": null}, ...]
     ```
   - This ensures consistency with cold-start dataset format and avoids LLM hallucination of non-standard syntax.

2. **Parse and Validate Each Output**  
   For each generated JSON string:
   - **Step 2.1: Parse JSON**  
     Use `json.loads()` to convert string → list of dicts.
   - **Step 2.2: Validate Structure**  
     Use `JSONValidator.validate_construction_tree()` to check:
     - Required fields (`type`, `id`, `parent`/`parent_a`, `face_id`/`face_id_a`) are present.
     - `id` is unique and sequential from 0.
     - Parent IDs refer to valid earlier blocks (no forward references).
     - For Spring blocks: exactly two parents, no `parent` field.
     - No cycles (via DFS on parent graph).
   - **Step 2.3: Construct ConstructionTree**  
     If valid, instantiate `ConstructionTree(json_data)` object.  
     If invalid, **skip this rollout** (do not penalize; treat as failed rollout).

3. **Simulate and Compute Reward**  
   For each valid `ConstructionTree`:
   - **Step 3.1: Initialize Simulator**  
     Use `BesiegeFieldSimulator` with `block_registry` and `physics_config` from `config.yaml` (gravity=9.81, etc.).
   - **Step 3.2: Build Machine**  
     Call `simulator.build_from_tree(tree)` → returns `bool` (success/failure).
   - **Step 3.3: Check Pre-Simulation Validity**  
     Call `simulator.check_self_collision()` → if `True`, discard (R_valid=0).
   - **Step 3.4: Run Simulation**  
     Call `simulator.simulate()` → logs state every 0.2s (5s total).
   - **Step 3.5: Compute Reward**  
     Use `RewardCalculator`:
     - Extract `state_log` from simulator.
     - Compute `R_valid`:  
       - `True` iff:  
         - JSON parsed successfully,  
         - No self-collision,  
         - All blocks intact after 5s (`integrity == 1` for all).  
       - For catapult: **additional constraint** → `max_boulder_height > 3.0` (from `config.yaml`).  
     - Compute `R_task`:  
       - Car: `distance = |final_root_position - initial_root_position|` (along designated direction).  
       - Catapult: `R_task = max_height * max_distance` (both along designated direction).  
     - Final reward: `R = R_valid * R_task` → `float` (0 if invalid, scalar if valid).
   - **Step 3.6: Store Result**  
     Append `(tree, R)` to output list.

4. **Handle Invalid Rollouts**  
   - **Do not pad** the output list with dummy values.
   - Instead, **generate additional rollouts** until `num_rollouts` valid candidates are obtained.
   - Example: If only 58/64 are valid, generate 6 more until 64 valid are collected.
   - **Rationale**: The paper emphasizes *discovering promising designs* — invalid ones provide no signal. Pass@k is about the *best among valid candidates*.  
   - **Implementation**: Use a while loop:  
     ```python
     results = []
     attempts = 0
     max_attempts = num_rollouts * 3  # Prevent infinite loops
     while len(results) < num_rollouts and attempts < max_attempts:
         json_str = verl_rollout(prompt)
         tree, reward = self._parse_and_simulate(json_str)
         if tree is not None and reward is not None:
             results.append((tree, reward))
         attempts += 1
     ```
   - If `max_attempts` exceeded, log warning and return partial results (rare, expected in early RL).

5. **Parallelization Consideration**  
   - `verl` internally may parallelize rollouts across GPUs.
   - However, **simulation is CPU/GPU-bound and must be sequential** due to Unity3D plugin constraints (non-thread-safe).
   - Therefore:
     - Use `verl`’s built-in parallelism for **LLM generation** (fast, token-level).
     - Use **sequential processing** for **simulation and reward calculation** (slow, stateful).
   - This is acceptable because:
     - LLM generation is ~10x faster than simulation.
     - Total time per rollout: ~0.5–2s (simulation) vs. ~0.05s (generation).
     - 64 rollouts → ~32–128s total, which is acceptable per GRPO update step.

6. **Integration with GRPO and RLTrainer**  
   - The `VERLWrapper` is called by `RLTrainer.evaluate_pass_k()` and `RLTrainer.rl_finetune()`.
   - In training:
     - For each prompt in batch, `rollout()` generates `k=64` rollouts.
     - `GRPO.update()` selects the best `n` (e.g., top 16) based on reward to compute advantage.
     - Advantage is relative to the **mean reward of the k rollouts** for that prompt (Group Relative Policy Optimization).
   - In evaluation:
     - `evaluate_pass_k()` calls `rollout()` once per test prompt → returns top reward among k=64.
     - Used to compute **Pass@64 score** (max reward per prompt).

7. **Error Handling and Logging**  
   - All parsing/simulation failures are logged via `Logger.debug()` with:
     - Prompt ID,
     - Invalid JSON snippet,
     - Validation error message,
     - Simulation failure reason (e.g., “boulder height 2.1m < 3.0m”).
   - Critical failures (e.g., Unity crash, invalid block type) are logged as `Logger.error()` and trigger early termination.
   - **No exceptions are raised** to avoid crashing training loop — instead, rollouts are silently skipped.

8. **Configuration Dependencies**  
   The class must access the following from `config.yaml`:
   - `simulation.duration_seconds` → 5
   - `simulation.state_log_interval` → 0.2
   - `simulation.catapult_height_threshold` → 3.0
   - `agent.temperature` → 1.0 (for LLM sampling)
   - `agent.top_p` → 0.95
   - `model.max_output_length` → 1168 (to avoid truncation)
   - `tasks.car.reward_metric`, `tasks.catapult.reward_metric` → used in `RewardCalculator`

   → These are injected via constructor from `RLTrainer`, which loads `Config`.

9. **Dependencies and Interface Contract**  
   - **Inputs**:  
     - `prompt`: str (from `DatasetLoader` test set or training batch)
     - `num_rollouts`: int (from `config.training.rl_finetune.pass_k`)
   - **Outputs**:  
     - List of `(ConstructionTree, float)` — **never raw JSON or XML**
   - **External Dependencies**:  
     - `verl`: for LLM rollout generation (assumed installed and configured)
     - `construction_tree.ConstructionTree`: for object creation and validation
     - `dataset.loader.DatasetLoader`: to retrieve block list and task type (if needed for prompt templating)
     - `env.besiegefield.BesiegeFieldSimulator`: for physics simulation
     - `reward.calculator.RewardCalculator`: for reward logic
     - `utils.validator.JSONValidator`: for schema validation
     - `utils.config.Config`: for hyperparameters
     - `utils.logger.Logger`: for debugging

10. **Key Design Decisions and Justifications**

| Decision | Justification |
|--------|---------------|
| **Simulate only valid trees** | Invalid machines (file/spatial) provide zero reward signal. Filtering early avoids wasted simulation. |
| **Generate until k valid rollouts** | Ensures Pass@k is computed over *meaningful candidates*, not padded with zeros. Matches paper’s emphasis on “best performing designs”. |
| **Use `ConstructionTree` object, not JSON** | Ensures type safety and reuse of validation logic across agent, simulation, and evaluation modules. |
| **Sequential simulation, parallel LLM** | Unity3D is not thread-safe. LLM generation is cheap and parallelizable. Optimal trade-off. |
| **No entropy regularization in rollout** | Paper explicitly disables entropy regularization; we follow. Reward is the only signal. |
| **Hardcoded thresholds from config** | Ensures reproducibility and alignment with paper (e.g., 3m for catapult). Avoids magic numbers. |
| **No caching of simulations** | Each rollout is stochastic (due to physics noise, LLM sampling). Caching would bias training. |

11. **Edge Cases and Mitigations**

| Edge Case | Mitigation |
|----------|------------|
| **LLM outputs malformed JSON (e.g., missing commas)** | Use `json.loads()` with try-except; log and skip. |
| **LLM outputs non-JSON text (e.g., “Here is my design:”)** | Use regex to extract first valid JSON array: `r'\[.*\]'` (greedy). Fallback to `json.loads()` on extracted substring. |
| **Unity3D simulation crashes** | Wrap `simulate()` in `try-except`; mark as invalid, log crash, continue. |
| **Boulder not present in catapult design** | `RewardCalculator` checks for “Boulder” block existence. If absent, `R_valid=False`. |
| **Spring attached to non-attachable face** | `ConstructionTree.validate()` catches this during initialization. |
| **Too many invalid rollouts (>90%)** | Log warning and notify trainer. May indicate model collapse or misalignment. |
| **Prompt contains ambiguous terms (e.g., “fast car”)** | Prompt template is fixed and matches cold-start dataset. No interpretation — strict adherence. |

12. **Alignment with Paper Requirements**

| Paper Requirement | VERLWrapper Fulfillment |
|------------------|-------------------------|
| “Generate k=64 rollouts per prompt” | ✅ `num_rollouts=64` passed in. |
| “Use Pass@k advantage estimator” | ✅ Returns k candidates; GRPO selects top-k for advantage. |
| “Rollout temperature=1.0, top_p=0.95” | ✅ Configured via `config.yaml` and passed to `verl`. |
| “Return valid machines with verifiable rewards” | ✅ Only valid `ConstructionTree` + `R_valid * R_task` returned. |
| “Used for Pass@k evaluation” | ✅ Called by `RLTrainer.evaluate_pass_k()` on 100 held-out prompts. |
| “Integrate with verl framework” | ✅ Uses `verl.rollout()` for LLM generation. |
| “Avoids hallucinated or invalid designs” | ✅ JSON + spatial + physics validation filters >90% of failures. |

---

#### **13. Summary: VERLWrapper as a Reliable, Domain-Aware Rollout Engine**

The `VERLWrapper` is not a simple LLM wrapper — it is a **domain-aware, physics-grounded rollout pipeline** that ensures:

- **Faithful translation** of LLM outputs into valid mechanical designs,
- **Consistent reward computation** aligned with paper’s reward function,
- **Robust filtering** of invalid or non-functional machines,
- **Seamless integration** with `verl`, `GRPO`, and `ConstructionTree` ecosystem.

It transforms abstract text generation into **concrete, executable, and evaluable mechanical designs**, making it the **critical enabler** of RLVR in the compositional machine design task. Without this class, the LLM’s outputs would remain unverifiable text — but with it, they become **testable, simulative, and trainable artifacts**.

This implementation ensures **reproducibility, fidelity, and scalability** — exactly as required by the paper’s methodology.