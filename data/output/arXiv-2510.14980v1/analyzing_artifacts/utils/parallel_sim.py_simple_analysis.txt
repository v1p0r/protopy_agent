### **Logic Analysis: utils/parallel_sim.py â€” ParallelSimulator Class**

This analysis precisely derives the implementation logic for the `ParallelSimulator` class in `utils/parallel_sim.py`, grounded strictly in the **paper**, **design**, **task**, and **config.yaml**. No assumptions are made beyond what is explicitly stated or logically implied.

---

#### **1. Core Purpose and Context**

The `ParallelSimulator` is a critical component for **scalable evaluation and reinforcement learning** in BesiegeField. Its purpose is to:

> **Spawn 8 independent, isolated instances of the BesiegeField simulation environment** to concurrently simulate multiple machine designs (represented as `ConstructionTree` objects), thereby accelerating the RL training loop and agent search workflows (MCTS, hierarchical design, Pass@k rollouts).

This is **not** a simple multithreaded wrapper â€” it requires **true process-level isolation** because:
- Each simulation must run its own Unity3D physics engine instance (non-thread-safe).
- The environment must be stateful and independent (no shared memory between simulations to avoid race conditions).
- The paper mandates **8 A100 GPUs** for RL training, implying **one simulation process per GPU** (or at least per dedicated resource slot).
- Parallelization is required for **batched rollouts** (Pass@k = 64) and **multi-agent search nodes** (5 candidates Ã— 10 rounds = 50+ simulations per prompt).

Thus, `multiprocessing.Pool` is the **only viable choice** â€” threading would not isolate the Unity3D engine, and asyncio is unsuitable for CPU/GPU-bound physics simulation.

---

#### **2. Dependencies and Interface Constraints**

- **Dependencies**:
  - `multiprocessing` (standard library) â€” for process spawning and inter-process communication.
  - `env/besiegefield.py` â€” specifically, the `BesiegeFieldSimulator` class, which must be **picklable** (i.e., serializable via `pickle`) to be passed across process boundaries.
  
  > âœ… **Critical Constraint**: `BesiegeFieldSimulator` must not hold non-picklable resources (e.g., Unity3D native DLL handles, GPU context pointers) at the time of process spawn.  
  > âœ… **Solution**: `BesiegeFieldSimulator` must initialize its Unity3D connection **inside the worker process**, not in the main process. This is non-negotiable.

- **Input**: List of `ConstructionTree` objects (immutable, serializable JSON-like structures).
- **Output**: List of simulation result dictionaries (same order as input), each containing:
  ```python
  {
    "state_log": list[dict],  # per 0.2s, 25 timesteps for 5s sim
    "is_valid": bool,         # R_valid: file + spatial + intact
    "reward": float,          # R_task (distance or heightÃ—distance)
    "broken_blocks": list[int],  # optional: IDs of blocks that broke
    "root_trajectory": list[tuple],  # (x,y,z) at each step
    "boulder_trajectory": list[tuple]  # for catapult only
  }
  ```

  > ðŸ“Œ **Derived from**: `env/simulation.py` and `reward/calculator.py`. The `ParallelSimulator` does **not** compute reward â€” it returns raw simulation logs. Reward calculation is deferred to `RewardCalculator` in the main process (to avoid duplicating logic).

- **Configuration Source**: `config.yaml` â†’ `training.hardware.parallel_sim_workers` (default: 8).

---

#### **3. Workflow Logic: simulate_batch()**

The `simulate_batch()` method must handle **asynchronous, fault-tolerant, batched simulation** with strict contract adherence.

##### **Step-by-Step Execution Logic**

1. **Input Validation**:
   - Accept `trees: list[ConstructionTree]`.
   - Validate that all items are instances of `ConstructionTree`.
   - Log warning if list is empty â†’ return empty list immediately.
   - **Do not** validate JSON structure here â€” that is the job of `JSONValidator` in `ConstructionTree.validate()`.

2. **Worker Process Initialization**:
   - Use `multiprocessing.Pool` with `processes=config.get("training.hardware.parallel_sim_workers")`.
   - **Crucial**: The `BesiegeFieldSimulator` **must be instantiated inside each worker**, not passed from the main process.
     - Why? Unity3D engine initialization (via DLL/IPC) is not serializable and is process-local.
     - Therefore, each worker must:
       - Import `env.besiegefield.BesiegeFieldSimulator`
       - Load `block_registry` (must be available in worker namespace)
       - Initialize `BesiegeFieldSimulator` with `block_list` and `physics_config` from config.yaml
       - Keep this instance alive for the duration of the workerâ€™s lifetime (pool reuses workers)

3. **Batch Processing**:
   - For each `ConstructionTree` in the input list:
     - Serialize the tree to JSON string (using `tree.to_json()`) â€” this is picklable.
     - Send to worker via `pool.apply_async()` or `pool.map()`.

4. **Worker Function (Internal)**:
   - Each worker runs a **local function** (defined within `ParallelSimulator.__init__` or as a top-level module function) that:
     ```python
     def _simulate_single(tree_json: list[dict]) -> dict:
         # Reconstruct ConstructionTree from JSON
         tree = ConstructionTree(tree_json)
         
         # Initialize simulator (only here, per worker)
         simulator = BesiegeFieldSimulator(
             block_list=config.get("simulation.block_list"),  # loaded from config
             physics_config={
                 "gravity": config.get("simulation.gravity"),
                 "collision_threshold": config.get("simulation.collision_threshold")
             }
         )
         
         # Build machine
         if not simulator.build_from_tree(tree):
             return {
                 "state_log": [],
                 "is_valid": False,
                 "reward": 0.0,
                 "broken_blocks": [],
                 "root_trajectory": [],
                 "boulder_trajectory": []
             }
         
         # Simulate
         simulator.simulate()
         
         # Extract state log
         state_log = simulator.get_state_log()
         
         # Check self-collision (pre-simulation) â€” already done by build_from_tree, but re-check for safety
         if simulator.check_self_collision():
             return {
                 "state_log": state_log,
                 "is_valid": False,
                 "reward": 0.0,
                 "broken_blocks": [],
                 "root_trajectory": [],
                 "boulder_trajectory": []
             }
         
         # Extract trajectories for reward calculation later
         root_trajectory = [block_state["position"] for block_state in state_log if block_state["type"] == "Starting Block"]
         boulder_trajectory = [block_state["position"] for block_state in state_log if block_state["type"] == "Boulder"]
         
         # Return raw state + metadata â€” reward computed later
         return {
             "state_log": state_log,
             "is_valid": True,  # provisional â€” will be refined by RewardCalculator
             "reward": 0.0,     # placeholder
             "broken_blocks": [i for i, s in enumerate(state_log) if s.get("integrity", 1) == 0],
             "root_trajectory": root_trajectory,
             "boulder_trajectory": boulder_trajectory
         }
     ```
   - **Important**: The worker **does not compute `R_valid` or `R_task`**. It only returns:
     - `state_log` (full 0.2s intervals)
     - `broken_blocks` (block IDs that lost integrity)
     - Trajectories (for downstream reward computation)
     - `is_valid` is set to `True` *only if* `build_from_tree()` succeeded and `check_self_collision()` returned `False`.  
       â†’ **This is a *preliminary* validity flag**. Final `R_valid` will be computed by `RewardCalculator` using the full `state_log` (e.g., checking if machine broke during simulation).

5. **Error Handling and Fault Tolerance**:
   - If a worker crashes (e.g., Unity3D segfault), the entire pool may hang.
   - **Mitigation**:
     - Wrap `_simulate_single` in a `try-except` block.
     - On exception, return a **failure sentinel**:
       ```python
       return {
           "state_log": [],
           "is_valid": False,
           "reward": 0.0,
           "broken_blocks": [],
           "root_trajectory": [],
           "boulder_trajectory": []
       }
       ```
   - Use `pool.map()` with timeout (e.g., 30s per simulation) to prevent hanging:
     ```python
     results = pool.map(_simulate_single, json_trees, chunksize=1)
     ```
     > âš ï¸ Note: `chunksize=1` ensures each tree is processed individually â€” critical for load balancing across 8 workers.

6. **Output Ordering**:
   - `pool.map()` preserves input order â†’ output list is guaranteed to match input `ConstructionTree` list order.
   - This is **essential** for RL: each rollout must be paired with its prompt and reward.

7. **Memory and Resource Management**:
   - Each worker process loads `BesiegeFieldSimulator` once and reuses it for multiple simulations (pool keeps workers alive).
   - After `pool.map()` completes, **close and join** the pool to release resources:
     ```python
     pool.close()
     pool.join()
     ```
   - Avoid memory leaks: `BesiegeFieldSimulator` must clean up Unity3D resources on `__del__` or explicit `shutdown()`.

---

#### **4. Integration with Downstream Modules**

| Module | Interaction with ParallelSimulator |
|--------|-----------------------------------|
| **RLTrainer** | Uses `simulate_batch()` to generate 64 rollouts per prompt during Pass@k evaluation. |
| **IterativeEditing** | Uses `simulate_batch()` to evaluate 5 candidate machines per MCTS node. |
| **HierarchicalDesign** | Uses `simulate_batch()` to validate 8 builder outputs per stage before propagation. |
| **RewardCalculator** | Receives `state_log` from `ParallelSimulator`, then computes `R_valid` and `R_task` using `config.simulation.catapult_height_threshold` and task-specific rules. |
| **EvaluationMetrics** | Aggregates results from `ParallelSimulator` + `RewardCalculator` to compute validity rates and scores. |

> âœ… **Key Design Principle**: `ParallelSimulator` is **stateless and purely computational**. It does **not** know about tasks (car/catapult), rewards, or agent logic. It is a **universal physics executor**.

---

#### **5. Configuration Integration**

All parameters must be sourced from `config.yaml`:

| Parameter | Source | Use |
|----------|--------|-----|
| `parallel_sim_workers` | `training.hardware.parallel_sim_workers` | Number of worker processes (default: 8) |
| `gravity` | `simulation.gravity` | Physics engine setting |
| `collision_threshold` | `simulation.collision_threshold` | Minimum distance to detect self-collision |
| `duration_seconds` | `simulation.duration_seconds` | Simulation duration (5s) â€” used internally by `BesiegeFieldSimulator` |
| `state_log_interval` | `simulation.state_log_interval` | 0.2s â€” used by `BesiegeFieldSimulator` to determine logging frequency |

> ðŸ“Œ **Critical**: The `BesiegeFieldSimulator` class (in `env/besiegefield.py`) must be **configured via the same config.yaml** â€” this ensures consistency between main process and workers.

---

#### **6. Failure Modes and Robustness**

| Risk | Mitigation Strategy |
|------|---------------------|
| **Unity3D engine crashes** | Worker returns failure sentinel; main process logs error and continues. |
| **JSON serialization fails** | `ConstructionTree.to_json()` must be robust; use `json.dumps()` with `ensure_ascii=False` and `default=str`. |
| **Memory bloat from 8 Unity instances** | Use `config.simulation.duration_seconds = 5` â€” short sims reduce memory footprint. |
| **GPU memory overload** | Paper implies 8 A100s â†’ 1 simulation per GPU. If running on fewer GPUs, use `parallel_sim_workers = min(8, available_gpus)`. |
| **Worker initialization delay** | Use `pool.map()` with `chunksize=1` â€” avoids blocking on slow initializations. |

---

#### **7. Performance Optimization Notes**

- **Avoid copying large objects**: Only pass `tree.to_json()` (list of dicts) to workers â€” not the full `ConstructionTree` object.
- **Use `chunksize=1`** for even load balancing â€” some machines may take longer to simulate (e.g., complex catapults).
- **Do not use shared memory** â€” no `multiprocessing.Manager()` or `Value`/`Array` â€” it introduces overhead and complexity.
- **Logging**: Each worker should log to a per-process file (e.g., `logs/worker_0.log`) if debug is enabled â€” but main process logs only summary.

---

#### **8. Final Output Contract**

The `simulate_batch()` method **must** return:

```python
List[Dict] where each dict has:
{
  "state_log": List[Dict],  # 25 entries (5s / 0.2s), each with:
    # "type": str, "id": int, "position": [x,y,z], "orientation": [qx,qy,qz,qw], 
    # "velocity": [vx,vy,vz], "angular_velocity": [wx,wy,wz], "integrity": 0/1
  "is_valid": bool,         # True iff build_from_tree succeeded AND no self-collision
  "reward": float,          # placeholder (0.0) â€” computed later by RewardCalculator
  "broken_blocks": List[int],  # list of block IDs that lost integrity during sim
  "root_trajectory": List[Tuple[float, float, float]],  # 25 positions
  "boulder_trajectory": List[Tuple[float, float, float]]  # 25 positions, empty if no boulder
}
```

> ðŸ” **Why no reward here?**  
> Because `RewardCalculator` must be **single-source-of-truth** for reward logic (to avoid duplication and ensure consistency between cold-start, RL, and evaluation).  
> `ParallelSimulator` is a **physics engine wrapper**, not a reward engine.

---

#### **9. Summary: Implementation Blueprint**

| Component | Implementation Detail |
|---------|------------------------|
| **Class** | `ParallelSimulator` |
| **Constructor** | `__init__(self, num_workers: int = config.get("training.hardware.parallel_sim_workers"))`<br>â†’ Stores `num_workers`, loads config |
| **Method** | `simulate_batch(self, trees: List[ConstructionTree]) -> List[Dict]` |
| **Worker Function** | `_simulate_single(tree_json: List[Dict]) -> Dict` (defined inside method) |
| **Worker Initialization** | `BesiegeFieldSimulator` instantiated **per worker**, using config values |
| **Communication** | JSON serialization of `ConstructionTree` â†’ `pool.map()` |
| **Error Handling** | Try-except â†’ return failure sentinel |
| **Timeout** | Use `pool.map()` with timeout=30s per item |
| **Resource Cleanup** | `pool.close()`, `pool.join()` after batch |
| **Order Preservation** | `pool.map()` ensures output order matches input order |
| **No Shared State** | All state is isolated per process |
| **Config Dependency** | All parameters pulled from `config.yaml` via global config loader |

---

#### **10. Alignment with Paper and Design**

| Requirement | Satisfied? | Evidence |
|-----------|------------|----------|
| Supports 8 parallel simulations | âœ… | `parallel_sim_workers=8` from config |
| Uses multiprocessing.Pool | âœ… | Only viable method for Unity3D isolation |
| Returns raw state logs for reward calculation | âœ… | Explicitly avoids reward computation |
| Integrates with BesiegeFieldSimulator | âœ… | Worker spawns simulator internally |
| Used by RLTrainer and hierarchical/iterative agents | âœ… | Explicitly stated in task and design |
| No external dependencies beyond multiprocessing | âœ… | Only stdlib + env/besiegefield.py |
| No assumption about Unity3D API | âœ… | Abstracts behind `BesiegeFieldSimulator` interface |
| Follows config.yaml | âœ… | All values pulled from config |

---

### âœ… **Conclusion: Implementation Ready**

The `ParallelSimulator` class is **well-constrained**, **robust**, and **fully aligned** with the paperâ€™s requirements. It abstracts away the complexity of parallel physics simulation while ensuring:

- **Correctness** via process isolation,
- **Scalability** via 8-way parallelism,
- **Consistency** via centralized config,
- **Maintainability** via clean interface and separation of concerns.

It is the **foundational engine** enabling RL training and agentic search at scale. No further ambiguity remains.

**Next Step**: Implement `BesiegeFieldSimulator` in `env/besiegefield.py` to satisfy the picklability and initialization contract.