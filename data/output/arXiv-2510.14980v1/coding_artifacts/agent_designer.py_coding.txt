```python
# agent/designer.py
import json
import re
from typing import Optional, Dict, Any
from utils.config import Config
from utils.logger import Logger
from env.block_registry import BlockRegistry
from representation.construction_tree import ConstructionTree


class Designer:
    """
    Translates high-level functional blueprints into detailed construction trees.
    Used in hierarchical design workflow to generate the first functional block,
    then in parallel stages to build subsequent blocks.
    """

    def __init__(self, llm_model: str):
        """
        Initialize the Designer with LLM model identifier.
        
        Args:
            llm_model (str): Identifier for the LLM to use (e.g., "qwen-2.5-14b-instruct")
        """
        self.llm_model = llm_model
        self.logger = Logger(__name__)
        self.config = Config("config.yaml")
        
        # Get block registry and list of 27 valid blocks
        self.block_registry = BlockRegistry()
        self.block_list = sorted(list(self.block_registry._valid_block_names))
        
        # Load configuration parameters
        self.max_input_length = self.config.get("model.max_input_length", 3440)
        self.max_output_length = self.config.get("model.max_output_length", 1168)
        self.temperature = self.config.get("agent.temperature", 0.7)
        self.top_p = self.config.get("agent.top_p", 0.95)
        
        # Build default prompt template
        self.prompt_template = self._build_default_prompt_template()

    def _build_default_prompt_template(self) -> str:
        """
        Build the default prompt template as specified in the logic analysis.
        Enforces strict output format and uses only the 27 allowed blocks.
        
        Returns:
            str: Formatted prompt template with placeholders
        """
        # Format block list as comma-separated quoted strings
        block_list_str = ", ".join([f'"{block}"' for block in self.block_list])
        
        # Root block definition
        root_block_str = '{"type": "Starting Block", "id": 0, "parent": null, "face_id": null}'
        
        return f"""You are an expert mechanical designer in BesiegeField. Your task is to build a machine from the following high-level blueprint:

BLUEPRINT: {{"blueprint"}}

Available blocks (use only these 27): 
{block_list_str}

Construction Rules:
- Start with the "Starting Block" (ID=0).
- Each subsequent block must be attached to exactly one existing block (except Spring, which has two parents).
- Do NOT scale or rotate blocks after attachment.
- Do NOT use any block not in the list above.
- Output ONLY a JSON list of block dictionaries in construction order. Each dictionary must have:
  - "type": string (exact name from list)
  - "id": integer (0-indexed, sequential)
  - "parent": integer (ID of parent block)
  - "face_id": integer (0â€“5, face index on parent; use 0 for front by default)
  - For Spring blocks: use "parent_a", "parent_b", "face_id_a", "face_id_b"
- First block must be: {root_block_str}
- Do not include explanations, comments, or markdown. Only output valid JSON.

Example:
[{{"type": "Starting Block", "id": 0, "parent": null, "face_id": null}},
 {{"type": "Wooden Block", "id": 1, "parent": 0, "face_id": 0}}]

Now generate the machine:
"""

    def _build_prompt(self, blueprint: str) -> str:
        """
        Build the complete prompt by substituting the blueprint into the template.
        Truncates if necessary to respect max_input_length.
        
        Args:
            blueprint (str): High-level functional blueprint from MetaDesigner
            
        Returns:
            str: Complete prompt string
        """
        # Format prompt with blueprint
        prompt = self.prompt_template.replace("{{blueprint}}", blueprint)
        
        # Truncate if too long
        if len(prompt) > self.max_input_length:
            prompt = prompt[:self.max_input_length]
            self.logger.warning(f"Designer prompt truncated to {self.max_input_length} characters")
            
        return prompt

    def _extract_json(self, raw_output: str) -> Optional[list]:
        """
        Extract JSON array from raw LLM output.
        Uses regex to find the first valid JSON array and parses it.
        
        Args:
            raw_output (str): Raw text output from LLM
            
        Returns:
            list or None: Parsed JSON list if valid, None otherwise
        """
        if not raw_output:
            return None
            
        # Remove markdown code blocks
        raw_output = re.sub(r'^\s*```json\s*', '', raw_output, flags=re.IGNORECASE)
        raw_output = re.sub(r'^\s*```.*?\s*', '', raw_output, flags=re.DOTALL)
        raw_output = re.sub(r'\s*```$', '', raw_output, flags=re.DOTALL)
        
        # Try to extract JSON array using regex
        # Match a JSON array starting with [ and ending with ]
        json_match = re.search(r'\[\s*[\s\S]*?\s*\]', raw_output)
        if json_match:
            json_str = json_match.group(0)
            try:
                parsed = json.loads(json_str)
                if isinstance(parsed, list):
                    return parsed
            except json.JSONDecodeError:
                pass
                
        # If no regex match, try direct parsing
        try:
            parsed = json.loads(raw_output)
            if isinstance(parsed, list):
                return parsed
        except json.JSONDecodeError:
            pass
            
        # Try to find the first [ and last ] and extract
        start_idx = raw_output.find('[')
        end_idx = raw_output.rfind(']')
        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            json_str = raw_output[start_idx:end_idx+1]
            try:
                parsed = json.loads(json_str)
                if isinstance(parsed, list):
                    return parsed
            except json.JSONDecodeError:
                pass
                
        return None

    def generate_design(self, blueprint: str) -> Optional[ConstructionTree]:
        """
        Generate a detailed construction tree from a high-level blueprint.
        
        Args:
            blueprint (str): High-level functional description (e.g., "lever arm, counterweight, pivot hinge, boulder container")
            
        Returns:
            ConstructionTree or None: Valid construction tree if successful, None if invalid or unparseable
        """
        # Build prompt
        prompt = self._build_prompt(blueprint)
        
        # Call LLM (simulated here - in real implementation, this would be an API call)
        # For now, we simulate with a placeholder
        # In production, replace with actual LLM API call
        raw_output = self._call_llm(prompt)
        
        # Extract JSON
        json_data = self._extract_json(raw_output)
        if json_data is None:
            self.logger.error(f"Failed to extract valid JSON from LLM output: {raw_output[:200]}...")
            return None
            
        # Validate that we have at least the root block
        if len(json_data) == 0:
            self.logger.error("Generated machine has no blocks")
            return None
            
        # Ensure root block is first and correct
        if json_data[0].get("type") != "Starting Block" or json_data[0].get("id") != 0:
            # Try to fix: prepend root block if missing
            if json_data[0].get("type") != "Starting Block":
                # Create root block
                root_block = {"type": "Starting Block", "id": 0, "parent": None, "face_id": None}
                # Adjust all IDs to be sequential starting from 0
                for i, block in enumerate(json_data):
                    block["id"] = i + 1
                    if "parent" in block and block["parent"] is not None:
                        block["parent"] += 1
                    if "parent_a" in block and block["parent_a"] is not None:
                        block["parent_a"] += 1
                    if "parent_b" in block and block["parent_b"] is not None:
                        block["parent_b"] += 1
                json_data.insert(0, root_block)
                self.logger.warning("Prepended missing Starting Block to generated machine")
            else:
                # ID is not 0, adjust
                json_data[0]["id"] = 0
                self.logger.warning("Fixed ID of first block to 0")
                
        # Validate all blocks are in allowed list
        for i, block in enumerate(json_data):
            block_type = block.get("type")
            if block_type not in self.block_registry._valid_block_names:
                self.logger.error(f"Invalid block type '{block_type}' at index {i}")
                return None
                
        # Validate IDs are sequential integers starting from 0
        expected_ids = list(range(len(json_data)))
        actual_ids = [block.get("id") for block in json_data]
        if actual_ids != expected_ids:
            # Try to fix sequential IDs
            for i, block in enumerate(json_data):
                block["id"] = i
            self.logger.warning("Fixed non-sequential block IDs")
            
        # Create ConstructionTree
        try:
            tree = ConstructionTree(json_data)
            is_valid, error_msg = tree.validate()
            if not is_valid:
                self.logger.error(f"Construction tree validation failed: {error_msg}")
                return None
            return tree
        except Exception as e:
            self.logger.error(f"Failed to create ConstructionTree: {str(e)}")
            return None

    def _call_llm(self, prompt: str) -> str:
        """
        Simulate LLM call. In production, this would be replaced with actual API integration.
        Uses the configured parameters (temperature, top_p) for generation.
        
        Args:
            prompt (str): Complete prompt string
            
        Returns:
            str: Simulated LLM response
        """
        # This is a placeholder for the actual LLM API call
        # In a real implementation, this would make an API call to the LLM service
        # For example: response = llm_api(prompt, temperature=self.temperature, top_p=self.top_p, max_tokens=self.max_output_length)
        
        # For simulation purposes, return a deterministic response
        # In production, replace with actual LLM call
        return """[
  {"type": "Starting Block", "id": 0, "parent": null, "face_id": null},
  {"type": "Ballast", "id": 1, "parent": 0, "face_id": 0},
  {"type": "Wooden Rod", "id": 2, "parent": 1, "face_id": 0},
  {"type": "Hinge", "id": 3, "parent": 2, "face_id": 0},
  {"type": "Rotating Block", "id": 4, "parent": 3, "face_id": 0},
  {"type": "Container", "id": 5, "parent": 2, "face_id": 4}
]"""
```