{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from utils import print_response\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b31729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser for .py version\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# parser.add_argument('--paper_name',type=str)\n",
    "\n",
    "# parser.add_argument('--model_name',type=str, default=\"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\") \n",
    "# parser.add_argument('--tp_size',type=int, default=2)\n",
    "# parser.add_argument('--temperature',type=float, default=1.0)\n",
    "# parser.add_argument('--max_model_len',type=int, default=128000)\n",
    "\n",
    "# parser.add_argument('--paper_format',type=str, default=\"JSON\", choices=[\"JSON\", \"LaTeX\"])\n",
    "# parser.add_argument('--pdf_json_path', type=str) # json format\n",
    "# parser.add_argument('--pdf_latex_path', type=str) # latex format\n",
    "\n",
    "# parser.add_argument('--output_dir',type=str, default=\"\")\n",
    "\n",
    "# args    = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\"\n",
    "tp_size = 2\n",
    "temperature = 1.0\n",
    "max_model_len = 128000\n",
    "\n",
    "paper_format = \"json\"\n",
    "pdf_json_path = None\n",
    "pdf_latex_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9225981",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_msg = [\n",
    "        {\"role\": \"user\", \"content\": \"\"\"Your goal is to create a concise, usable, and complete software system design for reproducing the paper's method. Use appropriate open-source libraries and keep the overall architecture simple.\n",
    "             \n",
    "Based on the plan for reproducing the paper’s main method, please design a concise, usable, and complete software system. \n",
    "Keep the architecture simple and make effective use of open-source libraries.\n",
    "\n",
    "-----\n",
    "\n",
    "## Format Example\n",
    "[CONTENT]\n",
    "{\n",
    "    \"Implementation approach\": \"We will ... ,\n",
    "    \"File list\": [\n",
    "        \"main.py\",  \n",
    "        \"dataset_loader.py\", \n",
    "        \"model.py\",  \n",
    "        \"trainer.py\",\n",
    "        \"evaluation.py\" \n",
    "    ],\n",
    "    \"Data structures and interfaces\": \"\\nclassDiagram\\n    class Main {\\n        +__init__()\\n        +run_experiment()\\n    }\\n    class DatasetLoader {\\n        +__init__(config: dict)\\n        +load_data() -> Any\\n    }\\n    class Model {\\n        +__init__(params: dict)\\n        +forward(x: Tensor) -> Tensor\\n    }\\n    class Trainer {\\n        +__init__(model: Model, data: Any)\\n        +train() -> None\\n    }\\n    class Evaluation {\\n        +__init__(model: Model, data: Any)\\n        +evaluate() -> dict\\n    }\\n    Main --> DatasetLoader\\n    Main --> Trainer\\n    Main --> Evaluation\\n    Trainer --> Model\\n\",\n",
    "    \"Program call flow\": \"\\nsequenceDiagram\\n    participant M as Main\\n    participant DL as DatasetLoader\\n    participant MD as Model\\n    participant TR as Trainer\\n    participant EV as Evaluation\\n    M->>DL: load_data()\\n    DL-->>M: return dataset\\n    M->>MD: initialize model()\\n    M->>TR: train(model, dataset)\\n    TR->>MD: forward(x)\\n    MD-->>TR: predictions\\n    TR-->>M: training complete\\n    M->>EV: evaluate(model, dataset)\\n    EV->>MD: forward(x)\\n    MD-->>EV: predictions\\n    EV-->>M: metrics\\n\",\n",
    "    \"Anything UNCLEAR\": \"Need clarification on the exact dataset format and any specialized hyperparameters.\"\n",
    "}\n",
    "[/CONTENT]\n",
    "\n",
    "## Nodes: \"<node>: <type>  # <instruction>\"\n",
    "- Implementation approach: <class 'str'>  # Summarize the chosen solution strategy.\n",
    "- File list: typing.List[str]  # Only need relative paths. ALWAYS write a main.py or app.py here.\n",
    "- Data structures and interfaces: typing.Optional[str]  # Use mermaid classDiagram code syntax, including classes, method(__init__ etc.) and functions with type annotations, CLEARLY MARK the RELATIONSHIPS between classes, and comply with PEP8 standards. The data structures SHOULD BE VERY DETAILED and the API should be comprehensive with a complete design.\n",
    "- Program call flow: typing.Optional[str] # Use sequenceDiagram code syntax, COMPLETE and VERY DETAILED, using CLASSES AND API DEFINED ABOVE accurately, covering the CRUD AND INIT of each object, SYNTAX MUST BE CORRECT.\n",
    "- Anything UNCLEAR: <class 'str'>  # Mention ambiguities and ask for clarifications.\n",
    "\n",
    "## Constraint\n",
    "Format: output wrapped inside [CONTENT][/CONTENT] like the format example, nothing else.\n",
    "\n",
    "## Action\n",
    "Follow the instructions for the nodes, generate the output, and ensure it follows the format example.\"\"\"}\n",
    "    ]\n",
    "\n",
    "task_list_msg = [\n",
    "        {'role': 'user', 'content': \"\"\"Your goal is break down tasks according to PRD/technical design, generate a task list, and analyze task dependencies. \n",
    "You will break down tasks, analyze dependencies.\n",
    "             \n",
    "You outline a clear PRD/technical design for reproducing the paper’s method and experiments. \n",
    "\n",
    "Now, let's break down tasks according to PRD/technical design, generate a task list, and analyze task dependencies.\n",
    "The Logic Analysis should not only consider the dependencies between files but also provide detailed descriptions to assist in writing the code needed to reproduce the paper.\n",
    "\n",
    "-----\n",
    "\n",
    "## Format Example\n",
    "[CONTENT]\n",
    "{\n",
    "    \"Required packages\": [\n",
    "        \"numpy==1.21.0\",\n",
    "        \"torch==1.9.0\"  \n",
    "    ],\n",
    "    \"Required Other language third-party packages\": [\n",
    "        \"No third-party dependencies required\"\n",
    "    ],\n",
    "    \"Logic Analysis\": [\n",
    "        [\n",
    "            \"data_preprocessing.py\",\n",
    "            \"DataPreprocessing class ........\"\n",
    "        ],\n",
    "        [\n",
    "            \"trainer.py\",\n",
    "            \"Trainer ....... \"\n",
    "        ],\n",
    "        [\n",
    "            \"dataset_loader.py\",\n",
    "            \"Handles loading and ........\"\n",
    "        ],\n",
    "        [\n",
    "            \"model.py\",\n",
    "            \"Defines the model .......\"\n",
    "        ],\n",
    "        [\n",
    "            \"evaluation.py\",\n",
    "            \"Evaluation class ........ \"\n",
    "        ],\n",
    "        [\n",
    "            \"main.py\",\n",
    "            \"Entry point  .......\"\n",
    "        ]\n",
    "    ],\n",
    "    \"Task list\": [\n",
    "        \"dataset_loader.py\", \n",
    "        \"model.py\",  \n",
    "        \"trainer.py\", \n",
    "        \"evaluation.py\",\n",
    "        \"main.py\"  \n",
    "    ],\n",
    "    \"Full API spec\": \"openapi: 3.0.0 ...\",\n",
    "    \"Shared Knowledge\": \"Both data_preprocessing.py and trainer.py share ........\",\n",
    "    \"Anything UNCLEAR\": \"Clarification needed on recommended hardware configuration for large-scale experiments.\"\n",
    "}\n",
    "\n",
    "[/CONTENT]\n",
    "\n",
    "## Nodes: \"<node>: <type>  # <instruction>\"\n",
    "- Required packages: typing.Optional[typing.List[str]]  # Provide required third-party packages in requirements.txt format.(e.g., 'numpy==1.21.0').\n",
    "- Required Other language third-party packages: typing.List[str]  # List down packages required for non-Python languages. If none, specify \"No third-party dependencies required\".\n",
    "- Logic Analysis: typing.List[typing.List[str]]  # Provide a list of files with the classes/methods/functions to be implemented, including dependency analysis and imports. Include as much detailed description as possible.\n",
    "- Task list: typing.List[str]  # Break down the tasks into a list of filenames, prioritized based on dependency order. The task list must include the previously generated file list.\n",
    "- Full API spec: <class 'str'>  # Describe all APIs using OpenAPI 3.0 spec that may be used by both frontend and backend. If front-end and back-end communication is not required, leave it blank.\n",
    "- Shared Knowledge: <class 'str'>  # Detail any shared knowledge, like common utility functions or configuration variables.\n",
    "- Anything UNCLEAR: <class 'str'>  # Mention any unresolved questions or clarifications needed from the paper or project scope.\n",
    "\n",
    "## Constraint\n",
    "Format: output wrapped inside [CONTENT][/CONTENT] like the format example, nothing else.\n",
    "\n",
    "## Action\n",
    "Follow the node instructions above, generate your output accordingly, and ensure it follows the given format example.\"\"\"}]\n",
    "\n",
    "# config\n",
    "config_msg = [\n",
    "        {'role': 'user', 'content': \"\"\"You write elegant, modular, and maintainable code. Adhere to Google-style guidelines.\n",
    "\n",
    "Based on the paper, plan, design specified previously, follow the \"Format Example\" and generate the code. \n",
    "Extract the training details from the above paper (e.g., learning rate, batch size, epochs, etc.), follow the \"Format example\" and generate the code. \n",
    "DO NOT FABRICATE DETAILS — only use what the paper provides.\n",
    "\n",
    "You must write `config.yaml`.\n",
    "\n",
    "ATTENTION: Use '##' to SPLIT SECTIONS, not '#'. Your output format must follow the example below exactly.\n",
    "\n",
    "-----\n",
    "\n",
    "# Format Example\n",
    "## Code: config.yaml\n",
    "```yaml\n",
    "## config.yaml\n",
    "training:\n",
    "  learning_rate: ...\n",
    "  batch_size: ...\n",
    "  epochs: ...\n",
    "...\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "## Code: config.yaml\n",
    "\"\"\"\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = args.model_name\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "if \"Qwen\" in model_name:\n",
    "    llm = LLM(model=model_name, \n",
    "            tensor_parallel_size=tp_size, \n",
    "            max_model_len=max_model_len,\n",
    "            gpu_memory_utilization=0.95,\n",
    "            trust_remote_code=True, enforce_eager=True, \n",
    "            rope_scaling={\"factor\": 4.0, \"original_max_position_embeddings\": 32768, \"type\": \"yarn\"})\n",
    "    sampling_params = SamplingParams(temperature=temperature, max_tokens=131072)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llm(msg):\n",
    "    # vllm\n",
    "    prompt_token_ids = [tokenizer.apply_chat_template(messages, add_generation_prompt=True) for messages in [msg]]\n",
    "\n",
    "    outputs = llm.generate(prompt_token_ids=prompt_token_ids, sampling_params=sampling_params)\n",
    "\n",
    "    completion = [output.outputs[0].text for output in outputs]\n",
    "    \n",
    "    return completion[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "trajectories = []\n",
    "total_accumulated_cost = 0\n",
    "output_dir = \"./image_agent_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776151af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, instruction_msg in enumerate([caption_msg, image_msg]):\n",
    "    current_stage = \"\"\n",
    "    if idx == 0 :\n",
    "        current_stage = f\"[image_agent] Caption extraction\"\n",
    "    elif idx == 1:\n",
    "        current_stage = f\"[image_agent] extract \"\n",
    "    print(current_stage)\n",
    "\n",
    "    trajectories.extend(instruction_msg)\n",
    "\n",
    "    completion = run_llm(trajectories)\n",
    "    \n",
    "    # response\n",
    "    completion_json = {\n",
    "        'text': completion\n",
    "    }\n",
    "\n",
    "    # print and logging\n",
    "    print_response(completion_json, is_llm=True)\n",
    "\n",
    "    responses.append(completion_json)\n",
    "\n",
    "    # trajectories\n",
    "    trajectories.append({'role': 'assistant', 'content': completion})\n",
    "\n",
    "\n",
    "# save\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(f'{output_dir}/planning_response.json', 'w') as f:\n",
    "    json.dump(responses, f)\n",
    "\n",
    "with open(f'{output_dir}/planning_trajectories.json', 'w') as f:\n",
    "    json.dump(trajectories, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9ef933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
