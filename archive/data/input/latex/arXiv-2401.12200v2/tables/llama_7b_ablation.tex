% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[htbp]
\centering
\resizebox{1.0\linewidth}{!}{
\begin{tabular}{@{}lrr|rrrrr@{}}
\toprule
                            & Sparsity & T.M.   & ARC  & HellaSwag & MMLU & TruthfulQA & Avg. \\ \midrule
APT                         & 30\%    & 75.8\% & 45.4 & 71.1      & 36.9 & 46.6       & 50.0 \\ \midrule
\tableindent w/o $\mathcal{A}_{\text{P}}$     & 100\%    & 102.4\% & 53.8 & 79.1      & 46.9 & 48.4       & 57.1 \\
\tableindent w/o kurtosis   & 30\%    & 75.9\% & 47.2 & 39.7    & 23.0 & 42.3       & 38.1 \\
\tableindent w/o $\mathcal{A}_{\text{T}}$ & 30\%    & 76.1\% & 44.2 & 70.1      & 40.8 & 45.1       & 50.0 \\ \midrule
% \tableindent + $\mathcal{D}_{\text{S}}$ & 30\%    & 105.9\%  & 41.9  & 67.2 &  39.7    & 48.0 & 49.2 \\ \midrule
APT                         & 50\%    & 60.2\% & 29.8 & 48.9      & 26.7 & 47.6       & 38.2 \\
\tableindent w/o $\mathcal{A}_{\text{T}}$ & 50\%    & 60.1\% & 27.9 & 46.2      & 24.5 & 44.7       & 35.8 \\ \bottomrule
\end{tabular}
}
\caption{LLaMA 2 7B model ablation results under 30\% and 50\% sparsity settings. T.M. denotes relative training memory compare to LoRA-tuning.}
\label{tab:llama-ablation}
\vspace{-5pt}
\end{table}