## config.yaml
training:
  cold_start:
    learning_rate: 1e-6
    epochs: 12
    batch_size: 1
    gradient_accumulation_steps: 1
    warmup_ratio: 0.03
    quantization: "QOFT"
    offt_block_size: 64
    optimizer: "8bit_AdamW"
  rl_finetune:
    learning_rate: 5e-6
    steps: 400
    batch_size_per_gpu: 1
    gradient_accumulation_steps: 8
    lora_rank: 64
    kl_penalty_weight: 0.001
    advantage_clip_ratio: 0.2
    rollout_temperature: 1.0
    rollout_top_p: 0.95
    advantage_estimator: "Pass@k"
    pass_k: 64
    gradient_clipping: 0.5
    use_mixed_precision: true
  hardware:
    gpus: 8
    device: "cuda"
    parallel_sim_workers: 8

model:
  base_model_name: "Qwen2.5-14B-Instruct"
  max_input_length: 3440
  max_output_length: 1168

simulation:
  duration_seconds: 5
  state_log_interval: 0.2
  gravity: 9.81
  collision_threshold: 0.01
  catapult_height_threshold: 3.0

agent:
  search_rounds: 10
  candidates_per_round: 5
  max_retries_per_node: 5
  temperature: 0.7
  top_p: 0.95

dataset:
  prompt_file: "data/prompts.jsonl"
  cold_start_dataset_path: "data/cold_start_9984.jsonl"
  test_prompts_path: "data/test_prompts_100.jsonl"
  num_test_prompts: 100

tasks:
  car:
    reward_metric: "distance"
    validity_constraints:
      - "no_self_collision"
      - "intact_after_simulation"
  catapult:
    reward_metric: "height_distance_product"
    validity_constraints:
      - "no_self_collision"
      - "intact_after_simulation"
      - "boulder_max_height_gt_3m"

logging:
  log_file: "logs/experiment.log"
  level: "INFO"

output:
  results_dir: "results"
  visualizations_dir: "visualizations"
  model_checkpoints_dir: "checkpoints"