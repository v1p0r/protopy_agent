# Logic Analysis: `agent/iterative_editing.py` — `IterativeEditing` Class

This analysis provides a precise, step-by-step logical breakdown of the `IterativeEditing` class, strictly aligned with the paper, design, task, and configuration. All components, data flows, constraints, and decision points are derived exclusively from the provided materials. No assumptions are introduced beyond what is explicitly stated or logically implied.

---

## **1. Core Objective**

The `IterativeEditing` class implements a **Monte Carlo Tree Search (MCTS)**-based agentic workflow to iteratively refine machine designs for compositional machine design tasks (car or catapult). It orchestrates a closed-loop process of generation, critique, simulation, and revision over a fixed number of search rounds, with the goal of discovering the highest-rewarding valid machine design.

**Key constraints from paper and config**:
- **10 search rounds** (config: `agent.search_rounds`)
- **5 candidate machines per round** (config: `agent.candidates_per_round`)
- **Up to 5 retries per node** if no valid machine is generated (paper: “each search node is allowed up to five retries”)
- **MCTS structure**: Selection → Expansion → Simulation → Backpropagation
- **Output**: The single best machine (highest reward) found over all rounds and nodes.

---

## **2. High-Level Workflow (Per Search Round)**

Each search round follows this deterministic sequence:

1. **Start with a root node** (initial draft from Designer).
2. For each of the 10 rounds:
   - **Selection**: Traverse the MCTS tree using UCB1 to select a leaf node (design to refine).
   - **Expansion**: If the selected node has not been expanded (i.e., no children generated), generate 5 candidate revisions via Refiner.
   - **Simulation**: Simulate all 5 candidates in parallel using `ParallelSimulator`.
   - **Backpropagation**: Update the MCTS node statistics (visit count, total reward) along the path from the leaf back to the root.
3. After 10 rounds, return the machine with the **highest reward** encountered in the entire tree.

> **Note**: Unlike classical MCTS, which expands one child per node per visit, this implementation expands **all 5 candidates at once** upon first expansion of a node. This is a batched expansion strategy to leverage parallel simulation and avoid sparse statistics.

---

## **3. Component Interactions & Dependencies**

| Component | Role | Interaction with `IterativeEditing` |
|---------|------|-------------------------------------|
| **Designer** | Generates initial draft | Called once per search round to produce the root design (or a new draft if node is unvisited). Uses prompt from task + block list. |
| **InspectorRefiner** | Abstract critique + triggers refinement | Called *after* simulation to critique the design and *before* Refiner generates revisions. Uses feedback from ActiveEnvQuerier. |
| **ActiveEnvQuerier** | Runs simulation + extracts feedback | Called after each draft is built. Returns minimal feedback (e.g., boulder height/distance) and selective queries (e.g., “query Container if boulder didn’t move”). |
| **Refiner** | Generates multiple revisions | Called by InspectorRefiner. Generates ≥5 candidate designs via LLM sampling (temperature=0.7, top_p=0.95 — config: `agent.temperature`, `agent.top_p`). |
| **ParallelSimulator** | Runs physics simulations in parallel | Called to simulate all 5 candidate machines simultaneously. Returns list of simulation results (state logs) for reward calculation. |

> **Critical Dependency Chain**:  
> `Designer` → `ActiveEnvQuerier` → `InspectorRefiner` → `Refiner` → `ParallelSimulator` → Reward → `MCTS Node Update`

All components are initialized externally and injected into `IterativeEditing` via constructor. This ensures modularity and testability.

---

## **4. MCTS Node Structure**

Each node in the MCTS tree is represented as a dictionary or a lightweight object with the following fields:

```python
class MCTSNode:
    def __init__(self, design: ConstructionTree, parent=None):
        self.design = design  # The machine design at this node
        self.parent = parent  # Parent node (None for root)
        self.children = []    # List of child nodes (each with a revised design)
        self.visit_count = 0  # Number of times this node has been visited
        self.total_reward = 0.0  # Sum of rewards from all simulations through this node
        self.is_expanded = False  # Whether 5 children have been generated
        self.is_valid = False   # Whether the design passed file + spatial validity
```

> **Rationale**: The `design` field is a `ConstructionTree` object, ensuring consistency with the shared data structure. The `is_valid` flag is critical: only valid designs are considered for expansion or backpropagation. Invalid designs are discarded and retried (up to 5 times).

---

## **5. Step-by-Step Algorithm Logic**

### **5.1 Initialization**
- **Input**: 
  - `designer`: `Designer` instance
  - `inspector_refiner`: `InspectorRefiner` instance
  - `querier`: `ActiveEnvQuerier` instance
  - `refiner`: `Refiner` instance
  - `parallel_sim`: `ParallelSimulator` instance
  - `reward_calc`: `RewardCalculator` instance (from `reward/calculator.py`)
  - `task`: `"car"` or `"catapult"` (from config or prompt)
  - `search_rounds`: 10 (from `config.agent.search_rounds`)
  - `candidates_per_round`: 5 (from `config.agent.candidates_per_round`)
  - `max_retries`: 5 (from `config.agent.max_retries_per_node`)
- **Output**: Best `ConstructionTree` found.

### **5.2 MCTS Main Loop: 10 Rounds**

For `round in range(search_rounds)`:

#### **Step 1: Selection (UCB1-based Tree Traversal)**
- Start at root node (initial draft from Designer).
- While current node has children and is expanded:
  - Compute UCB1 score for each child:
    ```
    UCB1(child) = (child.total_reward / child.visit_count) + c * sqrt(ln(parent.visit_count) / child.visit_count)
    ```
    - `c = 1.41` (standard exploration constant, not specified in paper → assumed from MCTS literature)
  - Select child with highest UCB1.
- Stop when reaching a leaf node (unexpanded or no children).

> **Why UCB1?** Balances exploitation (high-reward designs) and exploration (low-visited designs). Paper implies search over diverse candidates — UCB1 enables this.

#### **Step 2: Expansion**
- If leaf node is **not expanded** (`is_expanded == False`):
  - **Retry loop (up to 5 times)**:
    - Call `inspector_refiner.critique(design=leaf.design, feedback=querier.get_minimal_feedback(...))`
      - This returns a list of candidate designs (≥5, but may return fewer if LLM fails).
    - If ≥5 valid candidates returned → proceed.
    - Else → retry (up to 5 times), re-calling `critique` with same feedback.
  - If after 5 retries, still <5 valid candidates:
    - Use the best available (even if <5) and mark as partial expansion.
  - For each candidate design:
    - Validate file + spatial validity using `JSONValidator` and `BesiegeFieldSimulator.check_self_collision()`
    - If valid → create new `MCTSNode` → append to `leaf.children`
  - Set `leaf.is_expanded = True`
- If leaf is already expanded → skip expansion (already has children).

> **Critical Constraint**: Only **valid** designs become children. Invalid ones are discarded and counted toward retry limit. This ensures the tree only grows with physically plausible machines.

#### **Step 3: Simulation**
- For each child node in `leaf.children`:
  - Run `parallel_sim.simulate_batch([child.design])` → returns list of state logs.
  - Compute reward for each: `reward, is_valid = reward_calc.compute(state_log)`
    - For catapult: `is_valid` requires `max_height > 3.0` (config: `simulation.catapult_height_threshold`)
  - Store reward and validity in child node.

> **Note**: Simulation is **parallelized** across 8 workers (config: `training.hardware.parallel_sim_workers`). This is essential for efficiency — 5 candidates × 10 rounds = 50 simulations per run.

#### **Step 4: Backpropagation**
- Traverse from each child node back to root:
  - Update `node.visit_count += 1`
  - Update `node.total_reward += reward` (only if child was valid; invalid = 0 reward)
- **Important**: Even if a child is invalid (reward=0), it still counts as a visit. This penalizes unproductive refinement paths.

> **Rationale**: Invalid designs are not ignored — they are part of the search space and inform the agent that certain refinements lead to failure.

#### **Step 5: Track Best Design**
- After each round, compare the reward of all nodes in the tree.
- Maintain a global `best_design` variable, updated whenever a higher reward is found.

> **Why track globally?** Paper emphasizes “maximum simulation score” as key metric (Fig. FIGREF102, FIGREF104). MCTS finds best *in tree*, not just best *in last round*.

---

## **6. Handling Edge Cases and Failures**

| Scenario | Handling |
|--------|----------|
| **All 5 candidates fail validation** | Retry up to 5 times. If still no valid candidate → use parent’s design as “fallback” child (paper: “if fewer than 5 are found, the parent node’s machine is used as a candidate”). |
| **LLM returns malformed JSON** | Use `JSONValidator.validate_construction_tree()` → if invalid → count as retry. |
| **Simulation crashes (e.g., Unity process dies)** | Wrap `parallel_sim.simulate_batch()` in try-except → return reward=0, is_valid=False. Log error. |
| **No valid root design from Designer** | Abort entire search round. Log warning. Use fallback: generate new root via Designer. |
| **Memory/timeout in LLM calls** | Use timeout decorator (e.g., 30s per LLM call). On timeout → count as retry. |
| **Duplicate designs** | Compare `ConstructionTree.to_json()` strings. If duplicate → discard and retry. |

> **Note**: The paper does not specify duplicate handling, but in practice, LLMs may regenerate the same design. Preventing duplicates avoids wasted simulations.

---

## **7. Reward and Validity Logic (Aligned with Config)**

The `RewardCalculator` is used directly. Its logic is **hardcoded per task**:

| Task | `R_valid` Conditions | `R_task` Formula |
|------|----------------------|------------------|
| **Car** | 1. File valid<br>2. No self-collision<br>3. Machine intact after 5s | `max_distance` of root block |
| **Catapult** | 1. File valid<br>2. No self-collision<br>3. Machine intact after 5s<br>4. **Boulder max height > 3.0m** | `max_height × max_distance` |

> **Critical**: The `catapult_height_threshold` is read from `config.simulation.catapult_height_threshold` (default: 3.0). This must be **exactly 3.0**, not 3.1 or 2.9 — paper specifies “>3m” as a hard cutoff.

---

## **8. Configuration Integration**

All parameters are **not hardcoded** — they are pulled from `config.yaml` via a `Config` object:

| Parameter | Source | Usage |
|----------|--------|-------|
| `search_rounds` | `agent.search_rounds` | Outer loop (10 rounds) |
| `candidates_per_round` | `agent.candidates_per_round` | Number of children per expansion (5) |
| `max_retries_per_node` | `agent.max_retries_per_node` | Retry limit per expansion (5) |
| `temperature` | `agent.temperature` | Used by Refiner for sampling (0.7) |
| `top_p` | `agent.top_p` | Used by Refiner for sampling (0.95) |
| `parallel_sim_workers` | `training.hardware.parallel_sim_workers` | Number of parallel Unity instances (8) |
| `catapult_height_threshold` | `simulation.catapult_height_threshold` | Hard cutoff for validity (3.0) |

> **Design Principle**: Configuration is the **single source of truth**. Changing `search_rounds` from 10 to 20 requires no code change — only YAML edit.

---

## **9. Output and Final Selection**

- After 10 rounds, the algorithm returns the **single best design** (highest reward) observed in the entire MCTS tree.
- **Not** the root, not the last round — the global best.
- This aligns with the paper’s emphasis on **maximum simulation score** (Fig. FIGREF102, FIGREF104) and **Pass@k**-style evaluation — we are not returning an average, but the *best possible outcome*.

> **Note**: The paper uses Pass@k during RL finetuning to evaluate the best of k rollouts. Here, MCTS is the **inference-time search** that performs the same function: finding the best among multiple candidates.

---

## **10. Key Design Decisions Justified by Paper**

| Decision | Justification from Paper |
|--------|--------------------------|
| **Use MCTS over Best-of-N or Random** | Paper explicitly uses MCTS as default (Fig. FIGREF75, Algorithm SECREF11). Best-of-N and Random are ablations. |
| **5 retries per node** | Paper: “each search node is allowed up to five retries to prevent child statistics from being too sparse.” |
| **5 candidates per round** | Paper: “each search node [...] aiming to obtain 5 valid candidate machines.” |
| **Hierarchical feedback: minimal + selective** | Paper: “querier [...] selectively reports feedback on specific blocks”. InspectorRefiner uses this to guide critique. |
| **No entropy regularization** | Paper: “we do not introduce any entropy regularization” in RL. MCTS implicitly encourages diversity via UCB1. |
| **No post-construction scaling/rotation** | Paper: “exclude them from our experiments”. ConstructionTree assumes default scale/orientation. |
| **Only valid designs propagate** | Paper: “valid designs from this stage are evenly distributed” in hierarchical design → same logic applies here. |
| **Reward = R_valid × R_task** | Paper: “Our reward is in the form of R = R_valid * R_task”. |

---

## **11. Failure Mode Mitigations**

| Failure | Mitigation |
|--------|------------|
| **LLM generates invalid JSON** | `JSONValidator` catches before simulation. Counts as retry. |
| **Unity simulation crashes** | Try-except + fallback to 0 reward. Logs error. |
| **Too many invalid designs → tree stagnates** | Use parent design as fallback candidate. Prevents dead ends. |
| **MCTS converges too early** | UCB1 exploration term (c=1.41) ensures low-visited nodes are explored. |
| **Memory bloat from large tree** | Do not store full state logs in nodes — only store `design` and `reward`. Logs are discarded after reward calc. |

---

## **12. Summary: IterativeEditing as a System**

The `IterativeEditing` class is a **closed-loop, search-driven, reward-optimized agent system** that:

1. **Starts** with a single draft from the Designer.
2. **Iteratively refines** it using a multi-agent pipeline (critique → simulate → revise).
3. **Uses MCTS** to guide exploration of the vast design space, balancing known good designs with novel alternatives.
4. **Leverages parallel simulation** to evaluate 5 candidates per round efficiently.
5. **Returns the best design found** over 10 rounds, not the last one — maximizing the chance of discovering high-performing, non-obvious solutions.
6. **Is fully configurable**, decoupled from LLM implementation, and robust to failures via retries and fallbacks.

This design directly implements the **iterative editing workflow** described in the paper as the primary agentic strategy, with MCTS as the core search engine — making it the most sophisticated and effective agent architecture evaluated.

---

## **13. Next Steps (Implementation Checklist)**

Before coding:

- ✅ Confirm `ConstructionTree` has `.to_json()` for duplicate detection.
- ✅ Confirm `RewardCalculator` is injected and returns `(float, bool)` as tuple.
- ✅ Confirm `ParallelSimulator` returns list of state logs in same order as input designs.
- ✅ Confirm `InspectorRefiner.critique()` returns list of `ConstructionTree` objects.
- ✅ Confirm `Refiner.refine()` uses `temperature=0.7`, `top_p=0.95` from config.
- ✅ Confirm `JSONValidator` checks for required fields: `"type"`, `"id"`, `"parent"`, `"face_id"` (and `_a/_b` for Spring).
- ✅ Confirm config.yaml values are loaded into class via `Config.get(key)`.

All components are now logically aligned. The implementation of `IterativeEditing` will be a faithful, production-ready reproduction of the paper’s core agentic workflow.