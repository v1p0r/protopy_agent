{
    "paper_id": "arXiv-2510.14980v1.tar",
    "header": {
        "generated_with": "S2ORC 1.0.0",
        "date_generated": "2025-11-29T06:01:09.573323Z"
    },
    "title": "\nAgentic Design of Compositional Machines\n",
    "authors": [
        {
            "first": "",
            "middle": [],
            "last": "Wenqian Zhang, 1, Weiyang Liu, 2,*, Zhen Liu, 1,*,\u2020, 1, The Chinese University of Hong Kong (Shenzhen), 2, The Chinese University of Hong Kong, *, Equal Advising, \u2020, Corresponding Author, besiegefield.github.io",
            "suffix": "",
            "affiliation": {},
            "email": ""
        }
    ],
    "year": "",
    "venue": "",
    "identifiers": {
        "arxiv_id": "arXiv-2510.14980v1.tar"
    },
    "abstract": " The design of complex machines stands as both a marker of human intelligence and a foundation of engineering practice. Given recent advances in large language models (LLMs), we ask whether they, too, can learn to create. We approach this question through the lens of compositional machine design: a task in which machines are assembled from standardized components to meet functional demands like locomotion or manipulation in a simulated physical environment. To support this investigation, we introduce BesiegeField , a testbed built on the machine-building game Besiege, which enables part-based construction, physical simulation and reward-driven evaluation. Using BesiegeField , we benchmark state-of-the-art LLMs with agentic workflows and identify key capabilities required for success, including spatial reasoning, strategic assembly, and instruction-following. As current open-source models fall short, we explore reinforcement learning (RL) as a path to improvement: we curate a cold-start dataset, conduct RL finetuning experiments, and highlight open challenges at the intersection of language, machine design, and physical reasoning.\n\n\n",
    "latex_parse": {
        "paper_id": "arXiv-2510.14980v1.tar",
        "_pdf_hash": "",
        "abstract": [
            {
                "text": " The design of complex machines stands as both a marker of human intelligence and a foundation of engineering practice. Given recent advances in large language models (LLMs), we ask whether they, too, can learn to create. We approach this question through the lens of compositional machine design: a task in which machines are assembled from standardized components to meet functional demands like locomotion or manipulation in a simulated physical environment. To support this investigation, we introduce BesiegeField , a testbed built on the machine-building game Besiege, which enables part-based construction, physical simulation and reward-driven evaluation. Using BesiegeField , we benchmark state-of-the-art LLMs with agentic workflows and identify key capabilities required for success, including spatial reasoning, strategic assembly, and instruction-following. As current open-source models fall short, we explore reinforcement learning (RL) as a path to improvement: we curate a cold-start dataset, conduct RL finetuning experiments, and highlight open challenges at the intersection of language, machine design, and physical reasoning.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            },
            {
                "text": "",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            },
            {
                "text": "",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            },
            {
                "text": "",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Abstract",
                "sec_num": null
            }
        ],
        "body_text": [
            {
                "text": "The history of human progress is, at its core, the history of machines, just as the ancient Greeks built the Antikythera mechanism to predict eclipses and Leonardo da Vinci envisioned machines to fly. Today, as large language models (LLMs) begin to approximate\u2014and in some domains, surpass\u2014human cognitive abilities, a natural question arises:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": " [leftmargin=1em, rightmargin=1em] Can computational models, like humans, conceive and create complex machines to achieve purposeful goals? ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": " ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "At the heart of this question lie two tightly coupled concepts: compositionality , how parts are put together into assemblies, and functionality , the tasks these assemblies perform as they interact with external forces or inputs. While foundation models are already capable of synthesizing 3D shapes and building mechanical parts with computer-aided design (CAD) models, it is the complex compositional structures, in which very different parts and components are orchestrated to smoothly move together, that realize a vast array of demands. Just as a clock emerges from the composition of simple and standardized mechanical elements such as gears and flywheels, these same elements, when combined differently, can give rise to entirely different machines, such as a sewing machine. On the other hand, the same functionality may be realized by different part compositions, just as both cars and bicycles can transport a person from place to place. Put it concisely: composition is shaped by functionality, and functionality is realized through composition . Since such compositional machines can be expressed programmatically, with types, placements and articulations of parts represented in structured code that LLMs can generate and manipulate, we formalize the above question as:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": " [leftmargin=1em, rightmargin=1em] Can LLMs, given standardized mechanical parts and a reward function for the desired functionality, discover diverse spatial part compositions that maximize the reward and complete the task? ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": " ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "The question is not only about the pursuit of intelligence but also about the practice of engineering. Modern design pipelines are often long and costly, especially in large-scale projects where each iteration demands substantial resources. These projects accumulate vast collections of documents and blueprints, making it difficult to trace, retrieve, or reuse past design efforts. Much essential know-how is passed informally across teams and generations, and in many cases, never fully recorded and since forgotten. An automated machine design system could directly address these challenges.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Rather than merely mimicking patterns from historical designs, such a system should be agentic: capable of exploring the exponentially large design space, leveraging prior knowledge to create novel designs for new demands and constraints, and improving them through feedback. To investigate this concretely, we introduce BesiegeField , an interactive environment built on the machine-design game of Besiege FOOTREF2 . The environment allows for construction of simple mechanical machines with standardized and semantic parts such as gears and wheels, and supports customized physical scenarios in which LLM agents can test constructed machines and evaluate their dynamics and interactions.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 407,
                        "end": 415,
                        "text": "1",
                        "ref_id": "FOOTREF2"
                    }
                ],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Building on BesiegeField , we benchmark state-of-the-art LLMs with different agent designs and strategies for selecting and placing basic mechanical elements to build machines for representative functional demands, a task we term compositional machine design . Through these experiments, we empirically identify key capabilities required for this task: accurate spatial reasoning, high-level knowledge of design strategies, and instruction-following in spatial domains. Since only a few proprietary LLMs achieve satisfactory results, we further investigate how reinforcement learning (RL) can improve the performance of open-source LLMs. To this end, we curate a small machine design dataset to cold-start RL finetuning, perform exploratory RL experiments, and highlight key challenges that chart directions for future research. In summary, our contributions are listed below:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "1. We introduce and formalize the task of compositional machine design , where machines are assembled from standardized parts to achieve functional goals. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "2. We present BesiegeField , an interactive environment that enables LLM agents to construct, simulate, and evaluate compositional machines in customized physical scenarios. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "3. We systematically benchmark state-of-the-art LLMs and different agentic workflow designs on representative machine-design tasks. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "4. We explore RL finetuning of LLMs on this task, for which we curate a cold-start dataset, conduct experiments, and highlight the key challenges. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Introduction",
                "sec_num": "1"
            },
            {
                "text": "Full machine design involves many coupled elements: geometry, statics and dynamics, demand analysis, failure modes, safety, and even legal constraints BIBREF0 , BIBREF1 . To isolate a tractable subproblem, we focus on the structural composition of machines: how standardized parts are spatially arranged and mechanically linked to produce functional behavior. We refer to this task, introduced in the previous section, as compositional machine design . It captures two essential components: (i) the static geometry of a machine as a part-based assembly, and (ii) its compatibility with functional demands, typically assessed through physical simulation. This abstraction omits considerations such as manufacturing constraints, material properties, or domain-specific regulations, but retains the core spatial and behavioral reasoning challenges relevant to design.",
                "cite_spans": [
                    {
                        "start": 151,
                        "end": 158,
                        "text": 2,
                        "ref_id": "BIBREF0"
                    },
                    {
                        "start": 161,
                        "end": 168,
                        "text": 60,
                        "ref_id": "BIBREF1"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Compositional Machine Design",
                "sec_num": "2"
            },
            {
                "text": "This special task of compositional machine design mirrors challenges found in other exploration domains. For example, automatic theorem proving involves a compositional and exponentially large action space, while electronic design automation (EDA) for chip layouts requires spatial reasoning to place components of varying shapes under spatial constraints (albeit in a more regular and grid-constrained fashion than mechanical parts in machines). A unique challenge in machine design, however, is its dependence on diverse long-horizon behaviors, both autonomous and non-autonomous, within an environment. Specifically, a machine may behave differently when operated in different ways ( e.g. , a bicycle when pedaled versus when braking) or under different external conditions ( e.g. , driving a car in sunny versus rainy weather). Similarly, many sophisticated machines cannot function without appropriate control policies, as exemplified by aircraft that rely on fly-by-wire systems to stabilize their inherently unstable aerodynamic configurations (which would otherwise be unflyable by a human pilot alone). A key open problem is therefore how to account for the interplay among physics, control policy, and compositional structure in machine design.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Compositional Machine Design",
                "sec_num": "2"
            },
            {
                "text": "It is worth noting that, unlike in math theorem proving where one valid proof often suffices (even though multiple proofs may still be valued), design domains typically require generating a diverse set of candidate solutions. This diversity is essential to (i) differentiate products, (ii) adapt to unpredictable market demands, and (iii) account for uncertainty in real-world testing and deployment. Consequently, the task places greater emphasis on diversity, and a model for compositional machine design should function more like a generative model than a simple reward maximizer.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Compositional Machine Design",
                "sec_num": "2"
            },
            {
                "text": "Studying the full problem of compositional machine design is challenging, as it involves the coupling of many interacting factors. We therefore focus on a minimalist, component-level setting in which machines are constructed primarily from cuboid primitives with clear functional semantics, together with a small set of specialized exceptions, and operate under a shared control policy in an environment governed by rigid-body and elastic mechanics. This abstraction allows us to properly benchmark the capabilities of existing LLMs and to assess the upper bounds, potential, and challenges of agentic systems and RL algorithms.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "BesiegeField : Playground for Compositional Machine Design",
                "sec_num": "3"
            },
            {
                "text": "To this end, we create BesiegeField , an interactive environment adapted from the machine-building game Besiege, in which players design medieval machines to complete tasks such as destroying castles. Powered by the built-in physics engine, BesiegeField supports physical simulation of mechanical systems such as vehicles and catapults in user-customized environments with terrains, obstacles, external forces ( e.g. , wind and gravity), and co-existing agents. The environment provides nearly 80 types of building blocks (examples illustrated in Fig. FIGREF29 ), including passive ones like drills and logs, and powered ones like powered cogs and wheels. Machines are constructed by sequentially attaching new parts to vacant and attachable faces of existing blocks, starting from a root block and thus forming a \u201cconstruction tree\u201d (indeed a directly acyclic graph (DAG), in the sense of operation orders; one block can has two parents in the DAG; the actual structures may contain loops). Powered blocks can receive control commands, allowing machines to be operated precisely. During simulation, complete state information (e.g., the position and velocity of each block in the constructed machine) can be recorded for model feedback. Finally, the environment supports custom modifications and can be extended with additional block types and richer physics ( e.g. , simple fluid simulation). Further details are explained in Appendix SECREF10 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 552,
                        "end": 560,
                        "text": "10",
                        "ref_id": "FIGREF29"
                    },
                    {
                        "start": 1437,
                        "end": 1445,
                        "text": "B",
                        "ref_id": "SECREF10"
                    }
                ],
                "eq_spans": [],
                "section": "BesiegeField : Playground for Compositional Machine Design",
                "sec_num": "3"
            },
            {
                "text": " BesiegeField is unique in balancing real-world geometry and physics, part-level semantics, and simple compositional rules. Block-stacking environments like LEGO BIBREF2 and Minecraft BIBREF2 , BIBREF3 allow intuitive combinatorial assembly but do not natively provide realistic physical simulation and rely on generic blocks with limited semantic meaning. CAD modeling BIBREF4 captures fine-grained geometry and interactions, but its complexity makes rules cumbersome and sequences prohibitively long. By contrast, BesiegeField uses semantically meaningful parts with cuboid-like construction rules\u2014supporting realistic physics while remaining abstract enough for tractable composition. This calibrated balance enables the study of compositional creativity and geometric reasoning at a level of difficulty that both differentiates algorithms and permits rapid experimentation. Moreover, unlike prior environments, BesiegeField supports machine destruction, adding durability and failure analysis to the design space.",
                "cite_spans": [
                    {
                        "start": 162,
                        "end": 169,
                        "text": 14,
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 184,
                        "end": 191,
                        "text": 14,
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 194,
                        "end": 201,
                        "text": 38,
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 370,
                        "end": 377,
                        "text": 28,
                        "ref_id": "BIBREF4"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "BesiegeField : Playground for Compositional Machine Design",
                "sec_num": "3"
            },
            {
                "text": " Representative target machines and tasks. To benchmark and characterize the performance of different LLMs for agentic compositional machine design, we consider two conceptually simple yet representative target machines to build: car and catapult as shown in Fig. FIGREF8 . While success in both requires understanding part semantics and structural syntax, car building primarily tests static relational reasoning, such as enforcing correct part orientations, symmetry, and stability; in contrast, catapult building challenges models with dynamic relational reasoning, where parts must coordinate over time to produce causal mechanical effects. Moreover, the two tasks are simple enough to be constructed with only a few blocks so that they fit within the LLM\u2019s context window, yet complex enough to require explicit reasoning about construction strategies and causal dependencies. We evaluate the performance of cars and catapults by their moving distance and their throwing distance ( i.e. , the moving distance of the stone), respectively, towards a fixed and given direction. During each simulation, the generated machine will be placed at a designated position, and the active parts will be powered after a few seconds. As there can be reward hacking issues, for catapults experiments we surround the designated machine placement position with moderate-height walls. More details about the target machines, rewards, and environments can be found in Appendix SECREF10 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 264,
                        "end": 271,
                        "text": "2",
                        "ref_id": "FIGREF8"
                    },
                    {
                        "start": 1463,
                        "end": 1471,
                        "text": "B",
                        "ref_id": "SECREF10"
                    }
                ],
                "eq_spans": [],
                "section": "::Benchmark Settings",
                "sec_num": "4.1"
            },
            {
                "text": " Machine representations. In BesiegeField , the default XML representation records all blocks with global 3D positions and uses a built-in algorithm to recover connections. Such a representation, however, does not well encode machine structures. Instead, we propose a parsimonious representation aligned with the game\u2019s building logic, based on pairwise relative attachment relationships (i.e., how one part is rotated and attached to another). Details are explained in Appendix SECREFU78 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 479,
                        "end": 488,
                        "text": "D.3",
                        "ref_id": "SECREFU78"
                    }
                ],
                "eq_spans": [],
                "section": "::Benchmark Settings",
                "sec_num": "4.1"
            },
            {
                "text": " Performance metrics. We evaluate our agentic systems using the following quantitative metrics: 1) file validity rate , the proportion of generated JSON files that can be successfully parsed into machine construction trees; 2) spatial validity rate , the proportion of generated machines that are free from self-collisions; 3) machine validity rate , the proportion of machines that satisfy both file and spatial validity; 4) mean and maximum simulation scores , the average and highest rewards achieved by generated machines in the environment.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Benchmark Settings",
                "sec_num": "4.1"
            },
            {
                "text": " Environment feedback. For the simple target machines car and catapult , we consider environment feedback within a time window of 5 seconds that is long enough to characterize their designated functionalities. Specifically, for car we consider maximum speed and driving distance; for catapult , we consider boulder throwing distance and maximum height. We also record the machines' global orientation and broken parts information (if any). Details are elaborated in Appendix SECREFU80 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 475,
                        "end": 484,
                        "text": "D.5",
                        "ref_id": "SECREFU80"
                    }
                ],
                "eq_spans": [],
                "section": "::Benchmark Settings",
                "sec_num": "4.1"
            },
            {
                "text": " Single-agent setting. We first benchmark if a single LLM agent alone is capable of completing the task. Specifically, one LLM agent is provided with the environment description, the available machine components, the assembly syntax, and the functional requirements ( e.g. , moving an object forward). The agent generates a chain-of-thought (CoT; BIBREF5 ) to reason about what is needed and why, and then derives an abstract plan (e.g., connecting a lever to a container with a boulder). This plan is later translated into the construction tree representation.",
                "cite_spans": [
                    {
                        "start": 347,
                        "end": 354,
                        "text": 59,
                        "ref_id": "BIBREF5"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Agentic Workflow Design",
                "sec_num": "4.2"
            },
            {
                "text": " Iterative editing. Because compositional machine design requires both low-level spatial reasoning and high-level ideation, a single agent rarely produces satisfactory machines. We therefore also design an iterative editing workflow that involves three major agents: 1) designer , which produces an initial plan from the environment description, the available machine components, the assembly syntax, and the functional requirements; 2) refiner , a self-critic agent that which evaluates a draft against requirements and constraints and proposes multiple candidate revisions at each step; 3) environment querier , an agent that runs machine simulation and summarizes the environment feedback, in the way that it always provides global information such as machine orientation throughout the trajectory but selectively reports the feedback on specific blocks ( e.g. , position and speed) for further machine refinement. The workflow begins with a draft from the designer that is later critiqued by an inspector , which assess the designed machine in an abstract fashion, then polished once by a refiner. The design then undergoes a fixed number of iterations, each consisting of one querier and one refiner step. At refiner stages, multiple candidates are generated for running Monte Carlo tree search (MCTS; BIBREF6 ). The best design found in this search process is selected as output.",
                "cite_spans": [
                    {
                        "start": 1307,
                        "end": 1314,
                        "text": 9,
                        "ref_id": "BIBREF6"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Agentic Workflow Design",
                "sec_num": "4.2"
            },
            {
                "text": " Hierarchical construction. Inspired by typical human design processes as well as recent designs of agentic systems BIBREF7 , BIBREF8 , BIBREF9 , we introduce a meta-designer agent that first analyzes the requirements and constraints, and then constructs a high-level blueprint of the major functional blocks ( e.g. , the suspension system) and their interconnections. With this blueprint in place, we adopt an autoregressive strategy to build the machine block by block: 1) we begin with the first functional block and dispatch the job to eight parallel builder agents; 2) the valid designs from this stage are evenly distributed to another eight builder agents to construct the second block; and 3) the process iterates in this manner until the entire machine is assembled. Empirically, we find that the meta-designer typically decomposes a machine into three to four functional blocks.",
                "cite_spans": [
                    {
                        "start": 116,
                        "end": 123,
                        "text": 62,
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 126,
                        "end": 133,
                        "text": 56,
                        "ref_id": "BIBREF8"
                    },
                    {
                        "start": 136,
                        "end": 143,
                        "text": 68,
                        "ref_id": "BIBREF9"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Agentic Workflow Design",
                "sec_num": "4.2"
            },
            {
                "text": " General observations. We find compositional machine design to be a challenging task for LLMs (Fig. FIGREF14 and Table TABREF15 ), though not intractable: Gemini 2.5 Pro can consistently construct visually sensible machines with non-trivial performance. We find no evidence that reasoning models outperform non-reasoning ones, suggesting the main bottleneck lies in LLMs\u2019 limited 3D understanding and/or in-context learning. We also find that LLMs, especially reasoning models, still exhibit some spatial and physical reasoning as exemplified by the CoT from Gemini Pro 2.5 (Fig. FIGREF10 ), much like a world model in text space.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 100,
                        "end": 108,
                        "text": "7",
                        "ref_id": "FIGREF14"
                    },
                    {
                        "start": 580,
                        "end": 588,
                        "text": "4",
                        "ref_id": "FIGREF10"
                    },
                    {
                        "start": 119,
                        "end": 127,
                        "text": "1",
                        "ref_id": "TABREF15"
                    }
                ],
                "eq_spans": [],
                "section": "::Key Empirical Observations",
                "sec_num": "4.3"
            },
            {
                "text": " Failure patterns. We identified common failure patterns in LLM-generated machines (Fig. FIGREF89 ): 1) incorrect part orientations ; 2) incorrect part placements , where parts attach to wrong parents; 3) instruction-following failures , where elements of the high-level blueprint are not strictly observed; 4) flawed high-level reasoning , where LLMs fail to recognize correct physics or essential components.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 89,
                        "end": 97,
                        "text": "18",
                        "ref_id": "FIGREF89"
                    }
                ],
                "eq_spans": [],
                "section": "::Key Empirical Observations",
                "sec_num": "4.3"
            },
            {
                "text": " Effect of environment feedback. It is unsurprising that with the more environment feedback the agents receive, the better performance of generated machines improve in general (Table TABREF101 ).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 183,
                        "end": 192,
                        "text": "12",
                        "ref_id": "TABREF101"
                    }
                ],
                "eq_spans": [],
                "section": "::Key Empirical Observations",
                "sec_num": "4.3"
            },
            {
                "text": " Effect of edit history. We find that edit histories are generally helpful in decreasing the number of failure attempts in creating valid machines (Table TABREF24 ), which underscores the importance of longer context window of base models for efficient exploration.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 154,
                        "end": 162,
                        "text": "6",
                        "ref_id": "TABREF24"
                    }
                ],
                "eq_spans": [],
                "section": "::Key Empirical Observations",
                "sec_num": "4.3"
            },
            {
                "text": " Hierarchical design. We observe the mean performance improves with hierarchical design only when the abstract-level reasoning on blueprints is reliable, as shown by the performance of Gemini 2.5 Pro. In the meantime, consistent with the intuition that hierarchical design is more structured and principled, it generally yields lower variance in obtained scores.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Key Empirical Observations",
                "sec_num": "4.3"
            },
            {
                "text": " Effect of CoT reasoning. As shown in Fig. FIGREF89 , LLMs often fail to faithfully translate high-level machine design plans in their CoT into semantically and geometrically consistent machine construction trees. To better assess the impact of CoT reasoning on high-level design, we feed the CoT generated by Gemini 2.5 Pro (the best-performing model) to other LLMs, prompting them to directly output construction trees. The resulting machines generally show improved performance (Fig. FIGREF112 ) and highlight the critical role of high-level semantic reasoning in machine design.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 43,
                        "end": 51,
                        "text": "18",
                        "ref_id": "FIGREF89"
                    },
                    {
                        "start": 487,
                        "end": 496,
                        "text": "31",
                        "ref_id": "FIGREF112"
                    }
                ],
                "eq_spans": [],
                "section": "::Key Empirical Observations",
                "sec_num": "4.3"
            },
            {
                "text": " CoT-machine correspondence. Though the CoT often provides a reasonably high-level blueprint, agents may still generate machines that deviate from the intended structure (Fig. FIGREF89 ). We hypothesize that this misalignment is a key reason many LLMs struggle to build better machines.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 176,
                        "end": 184,
                        "text": "18",
                        "ref_id": "FIGREF89"
                    }
                ],
                "eq_spans": [],
                "section": "::Key Empirical Observations",
                "sec_num": "4.3"
            },
            {
                "text": " Machine representation. We experiment with a coordinate-only representation derived from the default XML (Appendix SECREFU76 ) and our construction tree representation. Results show that the coordinate-only representation performs significantly worse (Table TABREF25 ), implying that explicit structural information is necessary for LLM understanding.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 259,
                        "end": 267,
                        "text": "7",
                        "ref_id": "TABREF25"
                    },
                    {
                        "start": 116,
                        "end": 125,
                        "text": "D.1",
                        "ref_id": "SECREFU76"
                    }
                ],
                "eq_spans": [],
                "section": "::Key Empirical Observations",
                "sec_num": "4.3"
            },
            {
                "text": " 3D information. We observe that (Table TABREF23 ) the performance generally improves when we also feed parsed 3D information into the context of LLMs, which implies that LLMs are less capable of understanding relative spatial relationship ( e.g. , construction trees).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 40,
                        "end": 48,
                        "text": "5",
                        "ref_id": "TABREF23"
                    }
                ],
                "eq_spans": [],
                "section": "::Key Empirical Observations",
                "sec_num": "4.3"
            },
            {
                "text": "Although agentic systems show promise in compositional machine design, simply scaling system size is unlikely to be economical, as errors compound rapidly. Like humans who internalize experience, LLM agents should consolidate new knowledge into weights. We thus explore reinforcement learning with verifiable rewards (RLVR) in BesiegeField to develop machine-design capabilities.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "",
                "sec_num": "5"
            },
            {
                "text": " Cold-start finetuning and dataset curation. Following recent RLVR practices BIBREF10 , BIBREF11 , BIBREF12 , we curated a small dataset to cold-start LLMs by aligning their reasoning process with expert CoT. Specifically, we collected textual descriptions of machine functionalities from Besiege player communities and prompted Gemini 2.5 Pro to generate corresponding machines. After filtering out invalid generations, we obtained 9,984 valid machine\u2013CoT pairs. We then used this dataset to perform supervised finetuning on Qwen-2.5-14B-Instruct for 12 epochs. Additional training details are provided in Appendix SECREFU96 .",
                "cite_spans": [
                    {
                        "start": 77,
                        "end": 85,
                        "text": 26,
                        "ref_id": "BIBREF10"
                    },
                    {
                        "start": 88,
                        "end": 96,
                        "text": 67,
                        "ref_id": "BIBREF11"
                    },
                    {
                        "start": 99,
                        "end": 107,
                        "text": 69,
                        "ref_id": "BIBREF12"
                    }
                ],
                "ref_spans": [
                    {
                        "start": 616,
                        "end": 625,
                        "text": "F.2",
                        "ref_id": "SECREFU96"
                    }
                ],
                "eq_spans": [],
                "section": "::Experimental Settings",
                "sec_num": "5.1"
            },
            {
                "text": " Reward design. We use the reward INLINEFORM0 where INLINEFORM1 indicates whether constraints are satisfied (Appendix SECREFU79 ). For car , INLINEFORM2 is the maximum travel distance; for catapult , it is the product of the boulder\u2019s maximum height and distance, penalizing solutions that are extreme in only one dimension.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 118,
                        "end": 127,
                        "text": "D.4",
                        "ref_id": "SECREFU79"
                    }
                ],
                "eq_spans": [
                    {
                        "start": 34,
                        "end": 45,
                        "text": "R=\ud835\ude92\ud835\ude9c_\ud835\ude9f\ud835\ude8a\ud835\ude95\ud835\ude92\ud835\ude8d\u00d7\ud835\ude99\ud835\ude8e\ud835\ude9b\ud835\ude8f\ud835\ude98\ud835\ude9b\ud835\ude96\ud835\ude8a\ud835\ude97\ud835\ude8c\ud835\ude8e",
                        "latex": "R = \\texttt {is\\_valid} \\times \\texttt {performance}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>R</mi><mo>&#x0003D;</mo><mi>\\texttt</mi><mrow><mi>i</mi><mi>s</mi><mi>\\_valid</mi></mrow><mi>&#x000D7;</mi><mi>\\texttt</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    },
                    {
                        "start": 52,
                        "end": 63,
                        "text": "\ud835\ude92\ud835\ude9c_\ud835\ude9f\ud835\ude8a\ud835\ude95\ud835\ude92\ud835\ude8d",
                        "latex": "\\texttt {is\\_valid}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\texttt</mi><mrow><mi>i</mi><mi>s</mi><mi>\\_valid</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM1"
                    },
                    {
                        "start": 141,
                        "end": 152,
                        "text": "\ud835\ude99\ud835\ude8e\ud835\ude9b\ud835\ude8f\ud835\ude98\ud835\ude9b\ud835\ude96\ud835\ude8a\ud835\ude97\ud835\ude8c\ud835\ude8e",
                        "latex": "\\texttt {performance}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\texttt</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM2"
                    }
                ],
                "section": "::Experimental Settings",
                "sec_num": "5.1"
            },
            {
                "text": " RL finetuning settings. We finetune agents specialized in building a single type of machine (either car or catapult ), making our setup closely aligned with one-shot RLVR BIBREF13 where a single prompt is used throughout the RL process. We adopt group relative policy optimization (GRPO; BIBREF14 ) with LoRA parametrization BIBREF15 (rank 64) and mixed-precision training to finetune the cold-started model. We evaluate both the standard GRPO advantage estimator and the pass@k variant BIBREF16 . In the latter case, due to the implementation of the RLVR framework verl BIBREF17 , the number of rollouts is set equal to INLINEFORM0 . Each experiment is run for 400 iterations on 8 A100 GPUs with per-GPU batch size of 1 and gradient accumulation of 8. We apply KL regularization with strength 0.001 to encourage the model to remain close to its initialization.",
                "cite_spans": [
                    {
                        "start": 172,
                        "end": 180,
                        "text": 58,
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 289,
                        "end": 297,
                        "text": 50,
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 326,
                        "end": 334,
                        "text": 17,
                        "ref_id": "BIBREF15"
                    },
                    {
                        "start": 488,
                        "end": 496,
                        "text": 55,
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 572,
                        "end": 580,
                        "text": 51,
                        "ref_id": "BIBREF17"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 622,
                        "end": 633,
                        "text": "k",
                        "latex": "k",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>k</mi></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    }
                ],
                "section": "::Experimental Settings",
                "sec_num": "5.1"
            },
            {
                "text": " General results. As shown in Fig. FIGREF104 , RL finetuning can generally improve the mean performance, mostly by increasing the percentage that machines are valid (including file validity, machine validity and satisfaction of minimum performance threshold). In the meantime, we also find that the maximum reward increases in our best setting. Similar to observations in many other RLVR settings, the entropy of the output distribution quickly drops even with regularization.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 35,
                        "end": 44,
                        "text": "25",
                        "ref_id": "FIGREF104"
                    }
                ],
                "eq_spans": [],
                "section": "::Main Results and Observations",
                "sec_num": "5.2"
            },
            {
                "text": " Pass@k advantage vs. Pass@1 advantage. Since we eventually care about the best performing designs, especially given the low validity rate, our default setting adopts Pass@k advantage estimator. Indeed, Pass@k finetuning is more likely to discovery promising machine designs (Fig. FIGREF102 ).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 281,
                        "end": 290,
                        "text": "23",
                        "ref_id": "FIGREF102"
                    }
                ],
                "eq_spans": [],
                "section": "::Main Results and Observations",
                "sec_num": "5.2"
            },
            {
                "text": " Evolution of generated machines during finetuning. In Fig. FIGREF20 , we qualitatively examine how models refine their designs over the course of finetuning. We observe that models typically make detail-level adjustments, such as shifting part positions, while keeping the same high-level design strategy rather than exploring alternative strategies. Although these strategies are often reasonable, the models struggle to find precise configurations that enable smooth coordination among parts. This precision is especially critical for sophisticated mechanisms like catapults to function properly.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 60,
                        "end": 68,
                        "text": "8",
                        "ref_id": "FIGREF20"
                    }
                ],
                "eq_spans": [],
                "section": "::Main Results and Observations",
                "sec_num": "5.2"
            },
            {
                "text": " Cold-start. Not surprisingly, we find that cold-start alone does not enable models to produce satisfactory designs, and that finetuning on the cold-start model is better than on the base model (Table TABREF18 ).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 201,
                        "end": 209,
                        "text": "2",
                        "ref_id": "TABREF18"
                    }
                ],
                "eq_spans": [],
                "section": "::Main Results and Observations",
                "sec_num": "5.2"
            },
            {
                "text": " Capabilities for compositional machine design. Although tasks such as visual understanding and generation also depend on spatial, physical, and semantic reasoning, compositional machine design introduces unique requirements for LLM capabilities. Without precise spatial placement of machine parts, a design may fail to function correctly; a gear train, for example, will not transmit rotation if the gears are misaligned. Since the design process is typically hierarchical, successful LLMs must be able to accurately translate high-level blueprints into detailed geometric designs. In addition, machine design spans both concept-level reasoning and detailed specification. This dual demand often leads to large design documents and calls for a form of \u201cvisual reasoning\u201d expressed through text, similar to what has been studied in LLMs applied to scalable vector graphics (SVG) and CAD models BIBREF18 , BIBREF19 . Multimodal reasoning is also important because effective machine design typically relies on integrating textual descriptions with visual or schematic representations. In this work, however, we focus only on pure LLM-based reasoning to isolate and analyze its capabilities for compositional machine design.",
                "cite_spans": [
                    {
                        "start": 894,
                        "end": 902,
                        "text": 43,
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 905,
                        "end": 913,
                        "text": 0,
                        "ref_id": "BIBREF19"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussions and Intriguing Insights",
                "sec_num": "6"
            },
            {
                "text": " Challenges in agentic machine design systems. The task of machine design faces similar challenges found in agentic systems in domains such as legal services and other knowledge-intensive fields. A key difficulty is the highly varied requirements and domain knowledge of different customers. To address this, LLMs need to acquire task-specific knowledge through in-context learning or finetuning. In addition, the complexity of design tasks often requires multiple agents to coordinate, and such pipelines can suffer error accumulation when the base LLM lacks sufficient capability.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussions and Intriguing Insights",
                "sec_num": "6"
            },
            {
                "text": " Exploration in machine design space. Different from tasks such as theorem proving, the goal of compositional machine design is to discover structures that more effectively achieve desired functionalities. Rather than reusing existing solutions, a practical design agent should be able to propose novel strategies, structural layouts, and part specifications as machine complexity increases. Meeting this requirement calls for RL finetuning methods that prevent models from collapsing into a narrow set of strategies and structures, which recent methods aim to alleviate BIBREF20 , BIBREF21 , BIBREF22 , BIBREF23 , BIBREF24 . This demand is closely related to continual RL BIBREF25 , since finetuned LLMs must avoid catastrophic forgetting, maintain its reasoning ability, and consolidate learned strategies, which is particularly important because large-scale machine design datasets are rare and commercially infeasible to collect.",
                "cite_spans": [
                    {
                        "start": 571,
                        "end": 579,
                        "text": 70,
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 582,
                        "end": 590,
                        "text": 7,
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 593,
                        "end": 601,
                        "text": 10,
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 604,
                        "end": 612,
                        "text": 8,
                        "ref_id": "BIBREF23"
                    },
                    {
                        "start": 615,
                        "end": 623,
                        "text": 32,
                        "ref_id": "BIBREF24"
                    },
                    {
                        "start": 673,
                        "end": 681,
                        "text": 49,
                        "ref_id": "BIBREF25"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Discussions and Intriguing Insights",
                "sec_num": "6"
            },
            {
                "text": " 3D graphics codes for generative modeling. There is a long history in 3D asset generation and engineering design of representing the construction of a target instance as a program or sequence of operations in a domain-specific language BIBREF26 , BIBREF27 , BIBREF28 , which we refer to here as 3D graphics codes BIBREF18 , BIBREF29 . Unlike geometric representations such as point clouds or meshes, these codes describe objects at a higher semantic level, capturing part composition, design constraints, and user operations in modeling software. Similar to programming languages, 3D graphics codes are inherently discrete and are typically generated with autoregressive models trained from scratch BIBREF30 or with LLMs finetuned on curated datasets BIBREF31 , BIBREF32 . Much of the existing work centers on CAD scripts for individual parts BIBREF33 , BIBREF19 , BIBREF4 or Blender macros for single assets BIBREF34 . Whereas recent studies on LEGO assemblies BIBREF3 , Minecraft structures BIBREF2 , BIBREF35 , and procedural scene generation BIBREF27 , BIBREF29 , BIBREF36 , BIBREF30 introduce richer compositionality, they still fall short of the task of compositional machine design, which requires assemblies that both function under physical laws and exhibit the precise geometry of real objects.",
                "cite_spans": [
                    {
                        "start": 237,
                        "end": 245,
                        "text": 46,
                        "ref_id": "BIBREF26"
                    },
                    {
                        "start": 248,
                        "end": 256,
                        "text": 54,
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 259,
                        "end": 267,
                        "text": 11,
                        "ref_id": "BIBREF28"
                    },
                    {
                        "start": 314,
                        "end": 322,
                        "text": 43,
                        "ref_id": "BIBREF18"
                    },
                    {
                        "start": 325,
                        "end": 333,
                        "text": 5,
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 700,
                        "end": 708,
                        "text": 66,
                        "ref_id": "BIBREF30"
                    },
                    {
                        "start": 752,
                        "end": 760,
                        "text": 25,
                        "ref_id": "BIBREF31"
                    },
                    {
                        "start": 763,
                        "end": 771,
                        "text": 6,
                        "ref_id": "BIBREF32"
                    },
                    {
                        "start": 844,
                        "end": 852,
                        "text": 61,
                        "ref_id": "BIBREF33"
                    },
                    {
                        "start": 855,
                        "end": 863,
                        "text": 0,
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 866,
                        "end": 873,
                        "text": 28,
                        "ref_id": "BIBREF4"
                    },
                    {
                        "start": 910,
                        "end": 918,
                        "text": 21,
                        "ref_id": "BIBREF34"
                    },
                    {
                        "start": 963,
                        "end": 970,
                        "text": 38,
                        "ref_id": "BIBREF3"
                    },
                    {
                        "start": 994,
                        "end": 1001,
                        "text": 14,
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 1004,
                        "end": 1012,
                        "text": 29,
                        "ref_id": "BIBREF35"
                    },
                    {
                        "start": 1047,
                        "end": 1055,
                        "text": 54,
                        "ref_id": "BIBREF27"
                    },
                    {
                        "start": 1058,
                        "end": 1066,
                        "text": 5,
                        "ref_id": "BIBREF29"
                    },
                    {
                        "start": 1069,
                        "end": 1077,
                        "text": 22,
                        "ref_id": "BIBREF36"
                    },
                    {
                        "start": 1080,
                        "end": 1088,
                        "text": 66,
                        "ref_id": "BIBREF30"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work and Concluding Remarks",
                "sec_num": "7"
            },
            {
                "text": " LLM agents. LLM agents are language models organized to operate in iterative loops of perception and action BIBREF37 , BIBREF38 , BIBREF39 . They interact with external tools BIBREF40 , BIBREF41 , BIBREF42 , BIBREF43 , respond to signals from simulated or real environments BIBREF44 , BIBREF45 , incorporate self-reflection to refine their outputs BIBREF46 , BIBREF19 , BIBREF47 , BIBREF48 , and are commonly organized into multi-agent systems that coordinate roles and exchange information BIBREF49 , BIBREF50 , BIBREF9 . These designs move beyond one-shot text generation and establish LLMs as adaptive decision makers capable of long-horizon reasoning. Approaches that introduce search over possible solutions BIBREF51 , BIBREF52 , BIBREF53 or reflection on prior attempts BIBREF54 , BIBREF55 , BIBREF56 , BIBREF7 , BIBREF48 have enabled progress on increasingly complex tasks. LLM agents have already been used in design tasks such as code synthesis BIBREF57 , BIBREF58 , BIBREF59 , CAD design BIBREF19 and game environments BIBREF60 , BIBREF2 . Partially inspired by these developments, BIBREF61 proposed a prototypical agent-based design framework that generates mechanical structures from text prompts. Their system treats structure generation as a one-shot process and delegates the search for optimal geometric and physical parameters to external optimization tools. In contrast, our work with BesiegeField explores how LLM agents can directly and iteratively bridge compositional structures to functional goals, framing design as a process of reasoning and adaptation with both accurate simulation and intuitive physics.",
                "cite_spans": [
                    {
                        "start": 109,
                        "end": 117,
                        "text": 64,
                        "ref_id": "BIBREF37"
                    },
                    {
                        "start": 120,
                        "end": 128,
                        "text": 35,
                        "ref_id": "BIBREF38"
                    },
                    {
                        "start": 131,
                        "end": 139,
                        "text": 20,
                        "ref_id": "BIBREF39"
                    },
                    {
                        "start": 176,
                        "end": 184,
                        "text": 48,
                        "ref_id": "BIBREF40"
                    },
                    {
                        "start": 187,
                        "end": 195,
                        "text": 31,
                        "ref_id": "BIBREF41"
                    },
                    {
                        "start": 198,
                        "end": 206,
                        "text": 23,
                        "ref_id": "BIBREF42"
                    },
                    {
                        "start": 209,
                        "end": 217,
                        "text": 40,
                        "ref_id": "BIBREF43"
                    },
                    {
                        "start": 275,
                        "end": 283,
                        "text": 47,
                        "ref_id": "BIBREF44"
                    },
                    {
                        "start": 286,
                        "end": 294,
                        "text": 53,
                        "ref_id": "BIBREF45"
                    },
                    {
                        "start": 349,
                        "end": 357,
                        "text": 19,
                        "ref_id": "BIBREF46"
                    },
                    {
                        "start": 360,
                        "end": 368,
                        "text": 0,
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 371,
                        "end": 379,
                        "text": 52,
                        "ref_id": "BIBREF47"
                    },
                    {
                        "start": 382,
                        "end": 390,
                        "text": 65,
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 492,
                        "end": 500,
                        "text": 27,
                        "ref_id": "BIBREF49"
                    },
                    {
                        "start": 503,
                        "end": 511,
                        "text": 4,
                        "ref_id": "BIBREF50"
                    },
                    {
                        "start": 514,
                        "end": 521,
                        "text": 68,
                        "ref_id": "BIBREF9"
                    },
                    {
                        "start": 714,
                        "end": 722,
                        "text": 63,
                        "ref_id": "BIBREF51"
                    },
                    {
                        "start": 725,
                        "end": 733,
                        "text": 39,
                        "ref_id": "BIBREF52"
                    },
                    {
                        "start": 736,
                        "end": 744,
                        "text": 24,
                        "ref_id": "BIBREF53"
                    },
                    {
                        "start": 777,
                        "end": 785,
                        "text": 3,
                        "ref_id": "BIBREF54"
                    },
                    {
                        "start": 788,
                        "end": 796,
                        "text": 12,
                        "ref_id": "BIBREF55"
                    },
                    {
                        "start": 799,
                        "end": 807,
                        "text": 45,
                        "ref_id": "BIBREF56"
                    },
                    {
                        "start": 810,
                        "end": 817,
                        "text": 62,
                        "ref_id": "BIBREF7"
                    },
                    {
                        "start": 820,
                        "end": 828,
                        "text": 65,
                        "ref_id": "BIBREF48"
                    },
                    {
                        "start": 955,
                        "end": 963,
                        "text": 15,
                        "ref_id": "BIBREF57"
                    },
                    {
                        "start": 966,
                        "end": 974,
                        "text": 36,
                        "ref_id": "BIBREF58"
                    },
                    {
                        "start": 977,
                        "end": 985,
                        "text": 33,
                        "ref_id": "BIBREF59"
                    },
                    {
                        "start": 999,
                        "end": 1007,
                        "text": 0,
                        "ref_id": "BIBREF19"
                    },
                    {
                        "start": 1030,
                        "end": 1038,
                        "text": 57,
                        "ref_id": "BIBREF60"
                    },
                    {
                        "start": 1041,
                        "end": 1048,
                        "text": 14,
                        "ref_id": "BIBREF2"
                    },
                    {
                        "start": 1093,
                        "end": 1101,
                        "text": 34,
                        "ref_id": "BIBREF61"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work and Concluding Remarks",
                "sec_num": "7"
            },
            {
                "text": " Reinforcement learning with verifiable rewards (RLVR). Recent studies indicate that, by running RL finetuning with verifiable rewards from simulators or verifiers, reasoning abilities emerge BIBREF14 , BIBREF62 , BIBREF63 , even when single prompt is used during finetuning BIBREF13 . Yet, many methods exhibit loss of diversity as output entropy collapses during reinforcement learning and thus do not fully enable LLMs to explore novel solutions. Examples of mitigation methods include explicit entropy or KL regularization BIBREF22 , BIBREF64 , Pass@k training BIBREF16 , BIBREF21 , and distribution-matching objectives like generative flow networks BIBREF20 , BIBREF65 . BesiegeField provides verifiable rewards and thus enables direct application of RLVR to compositional machine design.",
                "cite_spans": [
                    {
                        "start": 192,
                        "end": 200,
                        "text": 50,
                        "ref_id": "BIBREF14"
                    },
                    {
                        "start": 203,
                        "end": 211,
                        "text": 16,
                        "ref_id": "BIBREF62"
                    },
                    {
                        "start": 214,
                        "end": 222,
                        "text": 1,
                        "ref_id": "BIBREF63"
                    },
                    {
                        "start": 275,
                        "end": 283,
                        "text": 58,
                        "ref_id": "BIBREF13"
                    },
                    {
                        "start": 527,
                        "end": 535,
                        "text": 10,
                        "ref_id": "BIBREF22"
                    },
                    {
                        "start": 538,
                        "end": 546,
                        "text": 37,
                        "ref_id": "BIBREF64"
                    },
                    {
                        "start": 565,
                        "end": 573,
                        "text": 55,
                        "ref_id": "BIBREF16"
                    },
                    {
                        "start": 576,
                        "end": 584,
                        "text": 7,
                        "ref_id": "BIBREF21"
                    },
                    {
                        "start": 654,
                        "end": 662,
                        "text": 70,
                        "ref_id": "BIBREF20"
                    },
                    {
                        "start": 665,
                        "end": 673,
                        "text": 18,
                        "ref_id": "BIBREF65"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work and Concluding Remarks",
                "sec_num": "7"
            },
            {
                "text": " Concluding remarks . We introduced compositional machine design , a simplified yet challenging task that reflects core aspects of real-world machine design. To evaluate LLM performance on this task, we developed BesiegeField , an interactive environment based on the game Besiege. Our results with agentic systems and reinforcement learning demonstrate that LLMs hold promise for solving this problem. While we did not exhaustively explore all designs or integrate multi-modal information, our findings underscore the need to advance fundamental LLM algorithms and capabilities, and point toward exciting future directions in machine design.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Related Work and Concluding Remarks",
                "sec_num": "7"
            },
            {
                "text": "We sincerely thank the developers of Besiege for creating the game and fostering an open and vibrant community, without which our exploration of this exciting idea would not have been possible.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgment",
                "sec_num": null
            },
            {
                "text": "tocsectionAppendix",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Acknowledgment",
                "sec_num": null
            },
            {
                "text": "We built BesiegeField by creating plug-in modules for the game Besiege that create interfaces to allow flexible composition of parts (once certain rules are obeyed), control policies on multiple powered parts ( e.g. . powered cogs), recording of state information of any block ( e.g. , position, orientation, part integrity, etc.) and settings of termination conditions ( e.g. , some part passing through a line). BesiegeField supports multi-process launching and thus allows for efficient parallel RL training. As the game natively supports multi-player gameplay, BesiegeField can naturally be applied to multi-agent RL settings. As the game Besiege (shown in Fig. FIGREF28 ) is built with the (mostly) open-sourced Unity3D game engine FOOTREF26 , BesiegeField is highly-customizable: the environment 1) natively supports modification of physical parameters, external forces, terrains and obstacles ( e.g. , stone buildings) and 2) allows for extension patches (known as mods FOOTREF27 ) to introduce other mechanisms, such as new block types, fluid simulation and many other components.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 666,
                        "end": 674,
                        "text": "9",
                        "ref_id": "FIGREF28"
                    },
                    {
                        "start": 737,
                        "end": 746,
                        "text": "2",
                        "ref_id": "FOOTREF26"
                    },
                    {
                        "start": 977,
                        "end": 986,
                        "text": "3",
                        "ref_id": "FOOTREF27"
                    }
                ],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment",
                "sec_num": "B"
            },
            {
                "text": "Each machine is built by attaching new blocks to the existing structure, starting from a special root block. For convenience, we describe each construction step as an \u201cattacher\u201d block (child) connected to an \u201cattachee\u201d block (parent). As an attacher, each block has exactly one face available for connection; as an attachee, each block has none to several attachable faces. Once a face is used, it is considered occupied and cannot be reused. If, after construction, the free end of a block happens to coincide with an attachable face of an existing block, the two blocks are automatically connected.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Construction Rule",
                "sec_num": "B.1"
            },
            {
                "text": "A few special blocks violate the rule described above, such as spring. These blocks have two ends and thus must have two parent blocks, do not have physical volume can be attached to either vacant or occupied faces of other blocks.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Construction Rule",
                "sec_num": "B.1"
            },
            {
                "text": "Finally, each block can be rescaled and rotated after construction. Since post-construction scaling and rotation introduce unnecessary complexity into our pipeline, we exclude them from our experiments and leave their handling to future work.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Construction Rule",
                "sec_num": "B.1"
            },
            {
                "text": "Once constructed, the machine will be placed at the designated pose indicated by the position and orientation of the starting block (not necessary near the ground, but there is a maximum height constraint). The machine will be subject to gravity and Newtonian physical laws (rigid and elastic ones) after placement.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Simulation",
                "sec_num": "B.2"
            },
            {
                "text": "Out of the 75 construction blocks provided by Besiege, we filter out a list of 27 blocks (shown in Fig. FIGREF29 ) that are most relevant to build machines with classical mechanical mechanisms such as levers and trusses.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 104,
                        "end": 112,
                        "text": "10",
                        "ref_id": "FIGREF29"
                    }
                ],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "1.  Starting Block : the root of any mechanism; initial orientation is along z+ axis. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "2.  Small Wooden Block : a cubic basic construction block. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "3.  Wooden Block : shaped like two small wooden blocks attached together. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "4.  Wooden Rod : a slender, fragile construction block. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "5.  Log : shaped like three small wooden blocks arranged in parallel. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "6.  Steering Hinge : powered; controls rotation of sub-blocks, swinging left or right along the axis perpendicular to its placement axis. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "7.  Steering Block : powered; rotates blocks along its placement axis. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "8.  Powered Wheel : radius 1m; provides ground movement. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "9.  Unpowered Wheel : identical to the powered wheel but requires external force to rotate. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "10.  Large Powered Wheel : larger version of the powered wheel (radius 3m). ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "11.  Large Unpowered Wheel : unpowered version of the large powered wheel. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "12.  Small Wheel : functions like a caster wheel (e.g., shopping cart), unpowered, 1.2m long. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "13.  Roller Wheel : similar to the small wheel, but shorter (0.8m). ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "14.  Universal Joint : freely rotates around its placement axis, unpowered. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "15.  Hinge : swings up and down along the axis perpendicular to its placement axis, unpowered. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "16.  Ball Joint : swings freely in all directions, unpowered. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "17.  Axle Connector : similar to a ball joint but allows unrestricted INLINEFORM0 rotation. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 70,
                        "end": 81,
                        "text": "360 \u2218 ",
                        "latex": "360^\\circ ",
                        "ref_id": "INLINEFORM0"
                    }
                ],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "18.  Suspension : shaped like a wooden block, it can buffer forces from all directions. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "19.  Rotating Block : powered; motor-like block that generates torque and rotates about its local y-axis. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "20.  Grabber : grabs objects on contact and can release them. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "21.  Boulder : a large rock, loosely attached; useful for throwing. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "22.  Grip Pad : block with the highest friction. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "23.  Elastic Pad : block with the highest elasticity. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "24.  Container : typically used to hold a boulder. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "25.  Spring : can contract; one of the special blocks that can have two parent attachments (without occupying attachable faces). ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "26.  Brace : reinforces structural strength. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "27.  Ballast : a heavy cubic block used as a counterweight. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Blocks",
                "sec_num": "B.3"
            },
            {
                "text": "We define a set of tasks in which the goal is to construct machines within a designated building area to accomplish specific objectives.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Tasks",
                "sec_num": "B.4"
            },
            {
                "text": "1.  Movement. Referred to as the car task in the main text, the objective is to build a machine capable of driving along tracks and traversing various terrains. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Tasks",
                "sec_num": "B.4"
            },
            {
                "text": "2.  Throw. Referred to as the catapult task in the main text, the goal is to construct a machine that can launch boulders over long distances. To prevent unintended strategies (e.g., carrying the boulder instead of throwing it, or letting it roll along the ground), the building area is enclosed by a medium-height wall. ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Tasks",
                "sec_num": "B.4"
            },
            {
                "text": "3.  Delivery. This task requires building a machine that can transport a large stone forward across different terrains (Fig. FIGREF70 ). ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 125,
                        "end": 133,
                        "text": "14"
                    }
                ],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Tasks",
                "sec_num": "B.4"
            },
            {
                "text": "4.  Pick. The objective here is to design a machine that can retrieve a stone located at the bottom of a deep well (Fig. FIGREF69 ). ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 121,
                        "end": 129,
                        "text": "13"
                    }
                ],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Tasks",
                "sec_num": "B.4"
            },
            {
                "text": "For many of these tasks, we introduce multiple difficulty levels (not used in the experiments reported in this paper) to encourage progressively more sophisticated designs:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Tasks",
                "sec_num": "B.4"
            },
            {
                "text": "1.  Movement and Delivery. We consider: (1) randomized terrains with stones and wooden rods ( e.g. , Fig. FIGREF67 ), (2) curved tracks (Fig. FIGREF72 ), and (3) obstacles such as height-limiting bars. ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 106,
                        "end": 114,
                        "text": "11"
                    },
                    {
                        "start": 142,
                        "end": 150,
                        "text": "16"
                    }
                ],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Tasks",
                "sec_num": "B.4"
            },
            {
                "text": "2.  Throw. We design: (1) varied objectives, such as requiring the boulder to pass through an aerial ring (Fig. FIGREF71 ) or land precisely within a small target zone, (2) environmental factors such as wind, and (3) obstacles, including height restrictions either within the building area or along the boulder\u2019s trajectory. ",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 112,
                        "end": 120,
                        "text": "15"
                    }
                ],
                "eq_spans": [],
                "section": "Details on the BesiegeField Environment::Tasks",
                "sec_num": "B.4"
            },
            {
                "text": "Apart from the MCTS strategy used in the main experiments, we also evaluate two alternatives: (i) best-of-N, where we select the best-performing machine out of N candidates, and (ii) random search, which mimics best-of-N but instead selects a random candidate. For clarity, we refer to one consecutive \u201cquerier\u2013refiner\u201d call as a search node (consistent with our MCTS setup). Unlike classical MCTS or best-of-N, here each search node is allowed up to five retries to prevent child statistics from being too sparse. We perform INLINEFORM0 search rounds, each aiming to obtain 5 valid candidate machines (though this may fail; if fewer than 5 are found, the parent node\u2019s machine is used as a candidate). Full algorithmic details are provided in Algorithm SECREF11 , Algorithm SECREF11 , and Algorithm SECREF11 . In Fig. TABREF74 we show the improvement of machine performance with respect to the number of search rounds used. In Fig. FIGREF75 we compare the efficiency of different search methods in our agentic compositional machine design setting.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 933,
                        "end": 941,
                        "text": "17",
                        "ref_id": "FIGREF75"
                    },
                    {
                        "start": 819,
                        "end": 827,
                        "text": "9",
                        "ref_id": "TABREF74"
                    },
                    {
                        "start": 754,
                        "end": 762,
                        "text": "C",
                        "ref_id": "SECREF11"
                    },
                    {
                        "start": 775,
                        "end": 783,
                        "text": "C",
                        "ref_id": "SECREF11"
                    },
                    {
                        "start": 800,
                        "end": 808,
                        "text": "C",
                        "ref_id": "SECREF11"
                    }
                ],
                "eq_spans": [
                    {
                        "start": 526,
                        "end": 537,
                        "text": "R",
                        "latex": "R",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>R</mi></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    }
                ],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "Random Search Algorithm",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "NN",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "SS",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "FF",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "RR",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "Input machine INLINEFORM0 INLINEFORM1 INLINEFORM2 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 14,
                        "end": 25,
                        "text": "ori_machine",
                        "latex": "ori\\_machine",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>o</mi><mi>r</mi><mi>i</mi><mi>\\_machine</mi></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    },
                    {
                        "start": 26,
                        "end": 37,
                        "text": "max_retry\u21905",
                        "latex": "max\\_retry \\leftarrow 5",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mi>\\_retry</mi><mo>&#x02190;</mo><mn>5</mn></mrow></math>",
                        "ref_id": "INLINEFORM1"
                    },
                    {
                        "start": 38,
                        "end": 49,
                        "text": "machine_last_round\u2190ori_machine",
                        "latex": "machine\\_last\\_round \\leftarrow ori\\_machine",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>\\_last</mi><mi>\\_round</mi><mo>&#x02190;</mo><mi>o</mi><mi>r</mi><mi>i</mi><mi>\\_machine</mi></mrow></math>",
                        "ref_id": "INLINEFORM2"
                    }
                ],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": " INLINEFORM0 to INLINEFORM1 INLINEFORM2 INLINEFORM3 INLINEFORM4 INLINEFORM5 INLINEFORM6 INLINEFORM7 break INLINEFORM8 INLINEFORM9 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 1,
                        "end": 12,
                        "text": "r=1",
                        "latex": "r=1",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mo>&#x0003D;</mo><mn>1</mn></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    },
                    {
                        "start": 16,
                        "end": 27,
                        "text": "R",
                        "latex": "R",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>R</mi></mrow></math>",
                        "ref_id": "INLINEFORM1"
                    },
                    {
                        "start": 28,
                        "end": 39,
                        "text": "best_score\u2190-\u221e",
                        "latex": "best\\_score \\leftarrow -\\infty ",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_score</mi><mo>&#x02190;</mo><mo>&#x02212;</mo><mo>&#x0221E;</mo></mrow></math>",
                        "ref_id": "INLINEFORM2"
                    },
                    {
                        "start": 40,
                        "end": 51,
                        "text": "retry\u21900",
                        "latex": "retry \\leftarrow 0",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&#x02190;</mo><mn>0</mn></mrow></math>",
                        "ref_id": "INLINEFORM3"
                    },
                    {
                        "start": 52,
                        "end": 63,
                        "text": "retry<max_retry",
                        "latex": "retry < max\\_retry",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&lt;</mo><mi>m</mi><mi>a</mi><mi>x</mi><mi>\\_retry</mi></mrow></math>",
                        "ref_id": "INLINEFORM4"
                    },
                    {
                        "start": 64,
                        "end": 75,
                        "text": "retry\u2190retry+1",
                        "latex": "retry \\leftarrow retry + 1",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&#x02190;</mo><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&#x0002B;</mo><mn>1</mn></mrow></math>",
                        "ref_id": "INLINEFORM5"
                    },
                    {
                        "start": 76,
                        "end": 87,
                        "text": "machine_next_round\u2190N.generate(machine_last_round)",
                        "latex": "machine\\_next\\_round \\leftarrow N.generate(machine\\_last\\_round)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>\\_next</mi><mi>\\_round</mi><mo>&#x02190;</mo><mi>N</mi><mi>.</mi><mi>g</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo stretchy=\"false\">&#x00028;</mo><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>\\_last</mi><mi>\\_round</mi><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM6"
                    },
                    {
                        "start": 88,
                        "end": 99,
                        "text": "F(machine_next_round)",
                        "latex": "F(machine\\_next\\_round)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>F</mi><mo stretchy=\"false\">&#x00028;</mo><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>\\_next</mi><mi>\\_round</mi><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM7"
                    },
                    {
                        "start": 106,
                        "end": 117,
                        "text": "score\u2190S(machine_next_round)",
                        "latex": "score \\leftarrow S(machine\\_next\\_round)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>&#x02190;</mo><mi>S</mi><mo stretchy=\"false\">&#x00028;</mo><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>\\_next</mi><mi>\\_round</mi><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM8"
                    },
                    {
                        "start": 118,
                        "end": 129,
                        "text": "machine_last_round\u2190machine_next_round",
                        "latex": "machine\\_last\\_round \\leftarrow machine\\_next\\_round",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>\\_last</mi><mi>\\_round</mi><mo>&#x02190;</mo><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>\\_next</mi><mi>\\_round</mi></mrow></math>",
                        "ref_id": "INLINEFORM9"
                    }
                ],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": " INLINEFORM0 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 1,
                        "end": 12,
                        "text": "(machine_last_round,score)",
                        "latex": "(machine\\_last\\_round, score)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mo stretchy=\"false\">&#x00028;</mo><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><mi>e</mi><mi>\\_last</mi><mi>\\_round</mi><mi>,</mi><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    }
                ],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "Best-of-N Algorithm",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "NN",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "SS",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "FF",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "RR",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "nn",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "Input machine INLINEFORM0 INLINEFORM1 INLINEFORM2 INLINEFORM3 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 14,
                        "end": 25,
                        "text": "ori_machine",
                        "latex": "ori\\_machine",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>o</mi><mi>r</mi><mi>i</mi><mi>\\_machine</mi></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    },
                    {
                        "start": 26,
                        "end": 37,
                        "text": "best_score\u2190-\u221e",
                        "latex": "best\\_score \\leftarrow -\\infty ",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_score</mi><mo>&#x02190;</mo><mo>&#x02212;</mo><mo>&#x0221E;</mo></mrow></math>",
                        "ref_id": "INLINEFORM1"
                    },
                    {
                        "start": 38,
                        "end": 49,
                        "text": "best_machine\u2190ori_machine",
                        "latex": "best\\_machine \\leftarrow ori\\_machine",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_machine</mi><mo>&#x02190;</mo><mi>o</mi><mi>r</mi><mi>i</mi><mi>\\_machine</mi></mrow></math>",
                        "ref_id": "INLINEFORM2"
                    },
                    {
                        "start": 50,
                        "end": 61,
                        "text": "max_retry\u21905",
                        "latex": "max\\_retry \\leftarrow 5",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mi>\\_retry</mi><mo>&#x02190;</mo><mn>5</mn></mrow></math>",
                        "ref_id": "INLINEFORM3"
                    }
                ],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": " INLINEFORM0 to INLINEFORM1 INLINEFORM2 INLINEFORM3 INLINEFORM4 to INLINEFORM5 INLINEFORM6 INLINEFORM7 INLINEFORM8 INLINEFORM9 INLINEFORM10 break INLINEFORM11 INLINEFORM12 INLINEFORM13 INLINEFORM14 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 1,
                        "end": 12,
                        "text": "r=1",
                        "latex": "r=1",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mo>&#x0003D;</mo><mn>1</mn></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    },
                    {
                        "start": 16,
                        "end": 27,
                        "text": "R",
                        "latex": "R",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>R</mi></mrow></math>",
                        "ref_id": "INLINEFORM1"
                    },
                    {
                        "start": 28,
                        "end": 39,
                        "text": "best_score\u2190-\u221e",
                        "latex": "best\\_score \\leftarrow -\\infty ",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_score</mi><mo>&#x02190;</mo><mo>&#x02212;</mo><mo>&#x0221E;</mo></mrow></math>",
                        "ref_id": "INLINEFORM2"
                    },
                    {
                        "start": 40,
                        "end": 51,
                        "text": "best_machine_this_round\u2190best_machine",
                        "latex": "best\\_machine\\_this\\_round \\leftarrow best\\_machine",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_machine</mi><mi>\\_this</mi><mi>\\_round</mi><mo>&#x02190;</mo><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_machine</mi></mrow></math>",
                        "ref_id": "INLINEFORM3"
                    },
                    {
                        "start": 52,
                        "end": 63,
                        "text": "i=1",
                        "latex": "i=1",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>i</mi><mo>&#x0003D;</mo><mn>1</mn></mrow></math>",
                        "ref_id": "INLINEFORM4"
                    },
                    {
                        "start": 67,
                        "end": 78,
                        "text": "n",
                        "latex": "n",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>n</mi></mrow></math>",
                        "ref_id": "INLINEFORM5"
                    },
                    {
                        "start": 79,
                        "end": 90,
                        "text": "retry\u21900",
                        "latex": "retry \\leftarrow 0",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&#x02190;</mo><mn>0</mn></mrow></math>",
                        "ref_id": "INLINEFORM6"
                    },
                    {
                        "start": 91,
                        "end": 102,
                        "text": "retry<max_retry",
                        "latex": "retry < max\\_retry",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&lt;</mo><mi>m</mi><mi>a</mi><mi>x</mi><mi>\\_retry</mi></mrow></math>",
                        "ref_id": "INLINEFORM7"
                    },
                    {
                        "start": 103,
                        "end": 114,
                        "text": "retry\u2190retry+1",
                        "latex": "retry \\leftarrow retry + 1",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&#x02190;</mo><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&#x0002B;</mo><mn>1</mn></mrow></math>",
                        "ref_id": "INLINEFORM8"
                    },
                    {
                        "start": 115,
                        "end": 126,
                        "text": "machine i \u2190N.generate(best_machine_this_round)",
                        "latex": "machine_i \\leftarrow N.generate(best\\_machine\\_this\\_round)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><msub><mi>e</mi><mi>i</mi></msub><mo>&#x02190;</mo><mi>N</mi><mi>.</mi><mi>g</mi><mi>e</mi><mi>n</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo stretchy=\"false\">&#x00028;</mo><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_machine</mi><mi>\\_this</mi><mi>\\_round</mi><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM9"
                    },
                    {
                        "start": 127,
                        "end": 139,
                        "text": "F(machine i )",
                        "latex": "F(machine_i)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>F</mi><mo stretchy=\"false\">&#x00028;</mo><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><msub><mi>e</mi><mi>i</mi></msub><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM10"
                    },
                    {
                        "start": 146,
                        "end": 158,
                        "text": "score i \u2190S(machine i )",
                        "latex": "score_i \\leftarrow S(machine_i)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mi>i</mi></msub><mo>&#x02190;</mo><mi>S</mi><mo stretchy=\"false\">&#x00028;</mo><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><msub><mi>e</mi><mi>i</mi></msub><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM11"
                    },
                    {
                        "start": 159,
                        "end": 171,
                        "text": "score i >best_score",
                        "latex": "score_i > best\\_score",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mi>i</mi></msub><mo>&gt;</mo><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_score</mi></mrow></math>",
                        "ref_id": "INLINEFORM12"
                    },
                    {
                        "start": 172,
                        "end": 184,
                        "text": "best_score\u2190score i ",
                        "latex": "best\\_score \\leftarrow score_i",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_score</mi><mo>&#x02190;</mo><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><msub><mi>e</mi><mi>i</mi></msub></mrow></math>",
                        "ref_id": "INLINEFORM13"
                    },
                    {
                        "start": 185,
                        "end": 197,
                        "text": "best_machine\u2190machine i ",
                        "latex": "best\\_machine \\leftarrow machine_i",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_machine</mi><mo>&#x02190;</mo><mi>m</mi><mi>a</mi><mi>c</mi><mi>h</mi><mi>i</mi><mi>n</mi><msub><mi>e</mi><mi>i</mi></msub></mrow></math>",
                        "ref_id": "INLINEFORM14"
                    }
                ],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": " INLINEFORM0 ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 1,
                        "end": 12,
                        "text": "(best_machine,best_score)",
                        "latex": "(best\\_machine, best\\_score)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mo stretchy=\"false\">&#x00028;</mo><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_machine</mi><mi>,</mi><mi>b</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>\\_score</mi><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    }
                ],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "Monte Carlo Tree Search (MCTS)",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "NN",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "rootroot",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "MAX_ITERMAX\\_ITER",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": " INLINEFORM0 INLINEFORM1 INLINEFORM2 to INLINEFORM3 INLINEFORM4 INLINEFORM5 Step 1: Selection INLINEFORM6 or INLINEFORM7 INLINEFORM8 not INLINEFORM9 INLINEFORM10 Unvisited leaf node ; no children yet INLINEFORM11 and not all child nodes are valid INLINEFORM12 INLINEFORM13 Step 2: Expansion INLINEFORM14 break INLINEFORM15 Step 3: Simulation INLINEFORM16 Step 4: Backpropagation return INLINEFORM17 Return best child",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 1,
                        "end": 12,
                        "text": "root\u2190s 0 ",
                        "latex": "root \\leftarrow s_0",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mi>o</mi><mi>o</mi><mi>t</mi><mo>&#x02190;</mo><msub><mi>s</mi><mn>0</mn></msub></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    },
                    {
                        "start": 13,
                        "end": 24,
                        "text": "max_retry\u21905",
                        "latex": "max\\_retry \\leftarrow 5",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mi>\\_retry</mi><mo>&#x02190;</mo><mn>5</mn></mrow></math>",
                        "ref_id": "INLINEFORM1"
                    },
                    {
                        "start": 25,
                        "end": 36,
                        "text": "i=1",
                        "latex": "i = 1",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>i</mi><mo>&#x0003D;</mo><mn>1</mn></mrow></math>",
                        "ref_id": "INLINEFORM2"
                    },
                    {
                        "start": 40,
                        "end": 51,
                        "text": "MAX_ITER",
                        "latex": "MAX\\_ITER",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>M</mi><mi>A</mi><mi>X</mi><mi>\\_ITER</mi></mrow></math>",
                        "ref_id": "INLINEFORM3"
                    },
                    {
                        "start": 52,
                        "end": 63,
                        "text": "retry\u21900",
                        "latex": "retry \\leftarrow 0",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&#x02190;</mo><mn>0</mn></mrow></math>",
                        "ref_id": "INLINEFORM4"
                    },
                    {
                        "start": 64,
                        "end": 75,
                        "text": "node\u2190Select(root)",
                        "latex": "node \\leftarrow \\text{Select}(root)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>n</mi><mi>o</mi><mi>d</mi><mi>e</mi><mo>&#x02190;</mo><mi>\\text</mi><mrow><mi>S</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>c</mi><mi>t</mi></mrow><mo stretchy=\"false\">&#x00028;</mo><mi>r</mi><mi>o</mi><mi>o</mi><mi>t</mi><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM5"
                    },
                    {
                        "start": 94,
                        "end": 105,
                        "text": "\ud835\udc5b\ud835\udc5c\ud835\udc51\ud835\udc52==\ud835\udc5f\ud835\udc5c\ud835\udc5c\ud835\udc61",
                        "latex": "\\textit {node} == \\textit {root}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\textit</mi><mrow><mi>n</mi><mi>o</mi><mi>d</mi><mi>e</mi></mrow><mo>&#x0003D;</mo><mo>&#x0003D;</mo><mi>\\textit</mi><mrow><mi>r</mi><mi>o</mi><mi>o</mi><mi>t</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM6"
                    },
                    {
                        "start": 109,
                        "end": 120,
                        "text": "\ud835\udc5b\ud835\udc5c\ud835\udc51\ud835\udc52.\ud835\udc63\ud835\udc56\ud835\udc60\ud835\udc56\ud835\udc61\ud835\udc52\ud835\udc51",
                        "latex": "\\textit {node}.\\textit {visited}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\textit</mi><mrow><mi>n</mi><mi>o</mi><mi>d</mi><mi>e</mi></mrow><mi>.</mi><mi>\\textit</mi><mrow><mi>v</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>e</mi><mi>d</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM7"
                    },
                    {
                        "start": 121,
                        "end": 132,
                        "text": "\ud835\udc60\u210e\ud835\udc5c\ud835\udc62\ud835\udc59\ud835\udc51_\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc4e\ud835\udc5b\ud835\udc51\u2190True",
                        "latex": "\\textit {should\\_expand} \\leftarrow True",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\textit</mi><mrow><mi>s</mi><mi>h</mi><mi>o</mi><mi>u</mi><mi>l</mi><mi>d</mi><mi>\\_expand</mi></mrow><mo>&#x02190;</mo><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></math>",
                        "ref_id": "INLINEFORM8"
                    },
                    {
                        "start": 137,
                        "end": 148,
                        "text": "\ud835\udc60\u210e\ud835\udc5c\ud835\udc62\ud835\udc59\ud835\udc51_\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc4e\ud835\udc5b\ud835\udc51",
                        "latex": "\\textit {should\\_expand}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\textit</mi><mrow><mi>s</mi><mi>h</mi><mi>o</mi><mi>u</mi><mi>l</mi><mi>d</mi><mi>\\_expand</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM9"
                    },
                    {
                        "start": 149,
                        "end": 161,
                        "text": "child\u2190node",
                        "latex": "child \\leftarrow node",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>c</mi><mi>h</mi><mi>i</mi><mi>l</mi><mi>d</mi><mo>&#x02190;</mo><mi>n</mi><mi>o</mi><mi>d</mi><mi>e</mi></mrow></math>",
                        "ref_id": "INLINEFORM10"
                    },
                    {
                        "start": 200,
                        "end": 212,
                        "text": "\ud835\udc60\u210e\ud835\udc5c\ud835\udc62\ud835\udc59\ud835\udc51_\ud835\udc52\ud835\udc65\ud835\udc5d\ud835\udc4e\ud835\udc5b\ud835\udc51",
                        "latex": "\\textit {should\\_expand}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\textit</mi><mrow><mi>s</mi><mi>h</mi><mi>o</mi><mi>u</mi><mi>l</mi><mi>d</mi><mi>\\_expand</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM11"
                    },
                    {
                        "start": 247,
                        "end": 259,
                        "text": "retry\u2190retry+1",
                        "latex": "retry \\leftarrow retry + 1",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&#x02190;</mo><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&#x0002B;</mo><mn>1</mn></mrow></math>",
                        "ref_id": "INLINEFORM12"
                    },
                    {
                        "start": 260,
                        "end": 272,
                        "text": "child\u2190Expand(node)",
                        "latex": "child \\leftarrow \\text{Expand}(node)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>c</mi><mi>h</mi><mi>i</mi><mi>l</mi><mi>d</mi><mo>&#x02190;</mo><mi>\\text</mi><mrow><mi>E</mi><mi>x</mi><mi>p</mi><mi>a</mi><mi>n</mi><mi>d</mi></mrow><mo stretchy=\"false\">&#x00028;</mo><mi>n</mi><mi>o</mi><mi>d</mi><mi>e</mi><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM13"
                    },
                    {
                        "start": 291,
                        "end": 303,
                        "text": "retry\u2265max_retry",
                        "latex": "retry \\ge max\\_retry",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>y</mi><mo>&#x02265;</mo><mi>m</mi><mi>a</mi><mi>x</mi><mi>\\_retry</mi></mrow></math>",
                        "ref_id": "INLINEFORM14"
                    },
                    {
                        "start": 310,
                        "end": 322,
                        "text": "reward\u2190Simulate(child)",
                        "latex": "reward \\leftarrow \\text{Simulate}(child)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>r</mi><mi>e</mi><mi>w</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo>&#x02190;</mo><mi>\\text</mi><mrow><mi>S</mi><mi>i</mi><mi>m</mi><mi>u</mi><mi>l</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow><mo stretchy=\"false\">&#x00028;</mo><mi>c</mi><mi>h</mi><mi>i</mi><mi>l</mi><mi>d</mi><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM15"
                    },
                    {
                        "start": 342,
                        "end": 354,
                        "text": "Backpropagate(child,reward)",
                        "latex": "\\text{Backpropagate}(child, reward)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\text</mi><mrow><mi>B</mi><mi>a</mi><mi>c</mi><mi>k</mi><mi>p</mi><mi>r</mi><mi>o</mi><mi>p</mi><mi>a</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>e</mi></mrow><mo stretchy=\"false\">&#x00028;</mo><mi>c</mi><mi>h</mi><mi>i</mi><mi>l</mi><mi>d</mi><mi>,</mi><mi>r</mi><mi>e</mi><mi>w</mi><mi>a</mi><mi>r</mi><mi>d</mi><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM16"
                    },
                    {
                        "start": 386,
                        "end": 398,
                        "text": "BestChild(root)",
                        "latex": "\\text{BestChild}(root)",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\text</mi><mrow><mi>B</mi><mi>e</mi><mi>s</mi><mi>t</mi><mi>C</mi><mi>h</mi><mi>i</mi><mi>l</mi><mi>d</mi></mrow><mo stretchy=\"false\">&#x00028;</mo><mi>r</mi><mi>o</mi><mi>o</mi><mi>t</mi><mo stretchy=\"false\">&#x00029;</mo></mrow></math>",
                        "ref_id": "INLINEFORM17"
                    }
                ],
                "section": "Search Strategies in Machine Modification Loops",
                "sec_num": "C"
            },
            {
                "text": "To reduce complexity in compositional machine design, our machine representation assumes all blocks remain at their default scale and are not further rotated after attachment (note: the attachment operation itself may rotate blocks).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Machine Representation",
                "sec_num": "D.1"
            },
            {
                "text": "By simplifying the default XML representation that BesiegeField receives, we obtain the global position-based representation. Below is a concrete example:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Global Position-based Representation",
                "sec_num": "D.2"
            },
            {
                "text": "Basically, each block in the machine is independently recorded without mentioning its adjacent blocks. For most of the block types, only the block type and its pose (position + orientation) are recorded. For special blocks that have two parents, the other end has to be specified, for which the corresponding dictionary has an additional entry of \u201cend-position\u201d.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Global Position-based Representation",
                "sec_num": "D.2"
            },
            {
                "text": "With our parsimonious construction tree representation, the example machine above is represented by the following the following JSON list:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Construction Tree Representation",
                "sec_num": "D.3"
            },
            {
                "text": "Specifically, the ordered list of dictionaries of the machine construction JSON file represents the construction order of blocks. Each dictionary contains the following information of corresponding block: 1) \u201ctype\u201d: block type; 2) \u201cid\u201d: the order ID of this block (the same as the order in the list), included so that LLMs do not have to parse it by itself; 3) \u201cparent\u201d, the ID of its parent block; 4) \u201cface_id\u201d, the face of the block's parent to which the block is attached. In cases that the block has two parents ( e.g. , a string that connects both parts), we use \u201cparent_a\u201d and \u201cparent_b\u201d to record both parents; similar for \u201cface_id\u201d.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Construction Tree Representation",
                "sec_num": "D.3"
            },
            {
                "text": "Note: the first block with \u201cid\u201d 0 is always the unique starting block, of which the local position and rotation are always zero.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Construction Tree Representation",
                "sec_num": "D.3"
            },
            {
                "text": "Here we elaborate on the reward design for RL experiments in Sec. SECREFU17 . Our reward is in the form of INLINEFORM0 where INLINEFORM1 is the boolean representing machine validity and INLINEFORM2 is the task-specific performance metric.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 66,
                        "end": 75,
                        "text": "5.1",
                        "ref_id": "SECREFU17"
                    }
                ],
                "eq_spans": [
                    {
                        "start": 107,
                        "end": 118,
                        "text": "R=\ud835\ude92\ud835\ude9c_\ud835\ude9f\ud835\ude8a\ud835\ude95\ud835\ude92\ud835\ude8d\u00d7\ud835\ude99\ud835\ude8e\ud835\ude9b\ud835\ude8f\ud835\ude98\ud835\ude9b\ud835\ude96\ud835\ude8a\ud835\ude97\ud835\ude8c\ud835\ude8e",
                        "latex": "R = \\texttt {is\\_valid} \\times \\texttt {performance}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>R</mi><mo>&#x0003D;</mo><mi>\\texttt</mi><mrow><mi>i</mi><mi>s</mi><mi>\\_valid</mi></mrow><mi>&#x000D7;</mi><mi>\\texttt</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    },
                    {
                        "start": 125,
                        "end": 136,
                        "text": "\ud835\ude92\ud835\ude9c_\ud835\ude9f\ud835\ude8a\ud835\ude95\ud835\ude92\ud835\ude8d",
                        "latex": "\\texttt {is\\_valid}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\texttt</mi><mrow><mi>i</mi><mi>s</mi><mi>\\_valid</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM1"
                    },
                    {
                        "start": 186,
                        "end": 197,
                        "text": "\ud835\ude99\ud835\ude8e\ud835\ude9b\ud835\ude8f\ud835\ude98\ud835\ude9b\ud835\ude96\ud835\ude8a\ud835\ude97\ud835\ude8c\ud835\ude8e",
                        "latex": "\\texttt {performance}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\texttt</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM2"
                    }
                ],
                "section": "::Reward Setting",
                "sec_num": "D.4"
            },
            {
                "text": " Car . We set INLINEFORM0 to 1 as long as the policy produces a machine that can be parsed from the generated construction tree and can be successfully placed into the environment without any self-collision; otherwise it is set to 0. INLINEFORM1 is set to the distance between the starting position and the end position of the root block.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 14,
                        "end": 25,
                        "text": "\ud835\ude92\ud835\ude9c_\ud835\ude9f\ud835\ude8a\ud835\ude95\ud835\ude92\ud835\ude8d",
                        "latex": "\\texttt {is\\_valid}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\texttt</mi><mrow><mi>i</mi><mi>s</mi><mi>\\_valid</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    },
                    {
                        "start": 234,
                        "end": 245,
                        "text": "\ud835\ude99\ud835\ude8e\ud835\ude9b\ud835\ude8f\ud835\ude98\ud835\ude9b\ud835\ude96\ud835\ude8a\ud835\ude97\ud835\ude8c\ud835\ude8e",
                        "latex": "\\texttt {performance}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\texttt</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM1"
                    }
                ],
                "section": "::Reward Setting",
                "sec_num": "D.4"
            },
            {
                "text": " Catapult . For INLINEFORM0 to be 1 in this task, the machine has to satisfy an additional constraint compared to the car task: the maximum height of the boulder position during simulation must be greater than a threshold of 3m. As explained in the main text, INLINEFORM1 for INLINEFORM2 is the product of the maximum height and maximum distance (towards some pre-defined direction) during simulation.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 16,
                        "end": 27,
                        "text": "\ud835\ude92\ud835\ude9c_\ud835\ude9f\ud835\ude8a\ud835\ude95\ud835\ude92\ud835\ude8d",
                        "latex": "\\texttt {is\\_valid}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\texttt</mi><mrow><mi>i</mi><mi>s</mi><mi>\\_valid</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    },
                    {
                        "start": 260,
                        "end": 271,
                        "text": "\ud835\ude99\ud835\ude8e\ud835\ude9b\ud835\ude8f\ud835\ude98\ud835\ude9b\ud835\ude96\ud835\ude8a\ud835\ude97\ud835\ude8c\ud835\ude8e",
                        "latex": "\\texttt {performance}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\texttt</mi><mrow><mi>p</mi><mi>e</mi><mi>r</mi><mi>f</mi><mi>o</mi><mi>r</mi><mi>m</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM1"
                    },
                    {
                        "start": 276,
                        "end": 287,
                        "text": "\ud835\udc50\ud835\udc4e\ud835\udc61\ud835\udc4e\ud835\udc5d\ud835\udc62\ud835\udc59\ud835\udc61",
                        "latex": "\\textit {catapult}",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>\\textit</mi><mrow><mi>c</mi><mi>a</mi><mi>t</mi><mi>a</mi><mi>p</mi><mi>u</mi><mi>l</mi><mi>t</mi></mrow></mrow></math>",
                        "ref_id": "INLINEFORM2"
                    }
                ],
                "section": "::Reward Setting",
                "sec_num": "D.4"
            },
            {
                "text": "In principle, we are able to obtain all state variables of each single part of a simulated machine. Due to the space complexity of the simulation results, not all information can be fed to LLM agents. Here we consider a minimal set of environment feedback information that the environment querier always gathers and returns to the refiner. Below are the minimal set of feedback information for each task:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": " Car. 1) machine orientation; 2) machine maximum moving distance (towards a designated direction); 3) machine max speed; 4) machine average speed per second; 5) machine position per 0.2 second (atomic time).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": " Catapult. 1) boulder maximum distance (horizontal, towards a designated distance); 2) boulder maximum height; 3) boulder position per 0.2 second (atomic time).",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": "Beyond these basic pieces of feedback, the querier, after seeing the candidate machine and its simulation results, in our default setting selectively extract a subset of environment feedback given its speculation on the issues of the simulated machine. For instance, parts during simulation may collide with each other and break. Such behavior carries important hints on why machines fail, and an LLM agent with sufficient capability in spatial and physics understanding can possibly identify the vulnerable blocks in the design.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": "Below we elaborate on the additional information that the querier may gather:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": "1. Block index to query; ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": "2. Time interval of interest (states outside this interval will not be considered); ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": "3. Feedback type of interest (one or more from the list) Position; Orientation; Velocity; Length (for spring only) ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": "3.1. Position; ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": "3.2. Orientation; ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": "3.3. Velocity; ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": "3.4. Length (for spring only) ",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "::Environment Feedback",
                "sec_num": "D.5"
            },
            {
                "text": "Generated machines often fail in systematic ways. As shown in Fig. FIGREF89 , we observe several recurring categories of errors, including flawed reasoning, structural attachment errors, incorrect part orientations and failures in instruction following. These diverse failure types highlight both the reasoning and execution challenges inherent in compositional machine design.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 67,
                        "end": 75,
                        "text": "18",
                        "ref_id": "FIGREF89"
                    }
                ],
                "eq_spans": [],
                "section": "Challenges in Compositional Machine Design::Failure Patterns",
                "sec_num": "E.1"
            },
            {
                "text": "In Fig. FIGREF91 we present a simple example to illustrate how the task of compositional machine design requires high precision in the spatial design of configurations of different parts. Even though the high-level design is feasible, the machine in the top row fails to throw the boulder out due to the incorrect position of the container.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 8,
                        "end": 16,
                        "text": "19",
                        "ref_id": "FIGREF91"
                    }
                ],
                "eq_spans": [],
                "section": "Challenges in Compositional Machine Design::Need for Precision",
                "sec_num": "E.2"
            },
            {
                "text": "As illustrated in Fig. FIGREF93 , a machine's appearance does not necessarily reflect its actual performance. A design that seems well-aligned with human intuition can fail dramatically, while one that looks awkward or unintuitive may achieve superior results. For LLMs to design machines that are both effective and visually intuitive to humans, reward functions must account not only for task performance but also for stability and other factors that shape human perception of functionality.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 23,
                        "end": 31,
                        "text": "20",
                        "ref_id": "FIGREF93"
                    }
                ],
                "eq_spans": [],
                "section": "Challenges in Compositional Machine Design::Appearance vs.\u00a0Performance",
                "sec_num": "E.3"
            },
            {
                "text": "Noticing that Gemini 2.5 Pro produces the most satisfactory machines with reasonable CoT, we adopt the single-agent generation setting and collect Gemini-generated machines along with their CoT. We curated 100 design objectives: 75 captions of machines created by Besiege players from the Internet and 25 authored by us. These 25 prompts are constructed by 1) first writing down simple design objectives that are realizable by BesiegeField and can emerge from some simple rewards, and 2) then introducing environment constraints and machine-specific requirements. Using this prompt dataset, we generate 250 machines per prompt, and after filtering out inappropriate ones (those that fail to parse, cannot be built in the environment, or do not have a specific physics-driven functionality, e.g. , a statue), we obtain 9,984 machines with their corresponding CoT. A sample gallery is shown in Fig. FIGREF95 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 897,
                        "end": 905,
                        "text": "21",
                        "ref_id": "FIGREF95"
                    }
                ],
                "eq_spans": [],
                "section": "Settings for RL Finetuning::Cold-Start Dataset Curation",
                "sec_num": "F.1"
            },
            {
                "text": "We present examples in the curated prompt set:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Settings for RL Finetuning::Cold-Start Dataset Curation",
                "sec_num": "F.1"
            },
            {
                "text": "Below we present the text prompts with our simple authoring strategy, which can possibly be scaled with LLMs:",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Settings for RL Finetuning::Cold-Start Dataset Curation",
                "sec_num": "F.1"
            },
            {
                "text": "In our experiment, we use Qwen2.5-14B-Instruct as the base model and train it on the Gemini synthesized dataset. To save GPU memory, we employ the parameter-efficient quantized OFT (QOFT) technique BIBREF70 , BIBREF68 , BIBREF67 , BIBREF69 for updating the model parameters, with OFT block size 64. We use 8-bit training with the 8-bit AdamW optimizer implmented with bitsandbytes BIBREF66 , a learning rate of 1e-6 and a linear warmup schedule (3% of the total training steps).",
                "cite_spans": [
                    {
                        "start": 198,
                        "end": 206,
                        "text": 44,
                        "ref_id": "BIBREF70"
                    },
                    {
                        "start": 209,
                        "end": 217,
                        "text": 41,
                        "ref_id": "BIBREF68"
                    },
                    {
                        "start": 220,
                        "end": 228,
                        "text": 30,
                        "ref_id": "BIBREF67"
                    },
                    {
                        "start": 231,
                        "end": 239,
                        "text": 42,
                        "ref_id": "BIBREF69"
                    },
                    {
                        "start": 381,
                        "end": 389,
                        "text": 13,
                        "ref_id": "BIBREF66"
                    }
                ],
                "ref_spans": [],
                "eq_spans": [],
                "section": "Settings for RL Finetuning::Cold-Start Details",
                "sec_num": "F.2"
            },
            {
                "text": "We use verl framework to implement our RL experiments. The LLM is finetuned from Qwen2.5-14B-Instruct (with LoRA of rank 64 on all linear layers) using the Gemini-synthesized dataset described above. We set learning rate to 5e-6 with gradient clipping threshold set to 0.5. The GRPO advantage estimator uses an advantage clipping ratio of 0.2. We add a KL penalty (weight 0.001) with respect to the pretrained LLM and do not introduce any entropy regularization. For rollouts, we use a temperature of INLINEFORM0 and top- INLINEFORM1 value of 0.95. Maximum input and output lengths are 3440 and 1168 tokens, respectively. We train each model for 400 update steps which take approximately 48 hours.",
                "cite_spans": [],
                "ref_spans": [],
                "eq_spans": [
                    {
                        "start": 501,
                        "end": 512,
                        "text": "1.0",
                        "latex": "1.0",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mn>1.0</mn></mrow></math>",
                        "ref_id": "INLINEFORM0"
                    },
                    {
                        "start": 522,
                        "end": 533,
                        "text": "p",
                        "latex": "p",
                        "mathml": "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\"><mrow><mi>p</mi></mrow></math>",
                        "ref_id": "INLINEFORM1"
                    }
                ],
                "section": "Settings for RL Finetuning::RL Experiment Details",
                "sec_num": "F.3"
            },
            {
                "text": " Meta-Designer in hierarchical design. In Table TABREF98 , we show that how a meta-designer for hierarchical design may benefit compositional machine design. Leveraging the knowledge on existing machines, meta-designers can identify the key macro-level mechanical components that are easier to design compared to the whole task, as shown in the results for Gemini 2.5 Pro, Kimi K2 and Llama 4 Scout. However, introducing an additional stage can introduce compounding error and, if the LLM agent is not capable of integrating different macro-level mechanical components, they may lead to lower scores, which we hypothesize is the reason for the failure of hierarchical design in models like Qwen3. Moreover, we examine if the meta-designer should provide step-by-step building instruction for the designer (Fig. FIGREF99 ), or simply provide high-level mechanical component descriptions. We find that a meta-designer that provides more detailed information is beneficial mostly when the base model is powerful enough ( e.g. , Gemini 2.5 Pro).",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 811,
                        "end": 819,
                        "text": "22",
                        "ref_id": "FIGREF99"
                    },
                    {
                        "start": 48,
                        "end": 56,
                        "text": "10",
                        "ref_id": "TABREF98"
                    }
                ],
                "eq_spans": [],
                "section": "Additional Ablation Studies",
                "sec_num": "G"
            },
            {
                "text": " Effect of feedback-free self-critic. In Table TABREF100 , we show that the inspector agent which does self-critic before running any environment simulation tend to improve performance for models like Gemini 2.5 Pro (the most powerful model for the task of compositional machine design in BesiegeField ) but can fail drastically for models like o3.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 47,
                        "end": 56,
                        "text": "11",
                        "ref_id": "TABREF100"
                    }
                ],
                "eq_spans": [],
                "section": "Additional Ablation Studies",
                "sec_num": "G"
            },
            {
                "text": " Effect of active feedback queries. In Table TABREF101 , we show that the active queries on the environment feedbacks help most of the models achieve better performance, compared to the setting with no environment feedback and that with only environment simulation final scores.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 45,
                        "end": 54,
                        "text": "12",
                        "ref_id": "TABREF101"
                    }
                ],
                "eq_spans": [],
                "section": "Additional Ablation Studies",
                "sec_num": "G"
            },
            {
                "text": " Additional RL results. In Fig. FIGREF102 and FIGREF104 and , we show the maximum scores achieved in the environments with different RL methods plus the validity rate of machines. We visualize the maximum score since, in the case when one is allowed to use inference-time scaling techniques, the best performing machines are the ones people care most about. We show that our settings with Pass@64 training achieves the best maximum score with two different random seeds. In additiona, in Fig. FIGREF106 , we visualize the corresponding Best@N metrics.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 32,
                        "end": 41,
                        "text": "23",
                        "ref_id": "FIGREF102"
                    },
                    {
                        "start": 46,
                        "end": 55,
                        "text": "25",
                        "ref_id": "FIGREF104"
                    },
                    {
                        "start": 493,
                        "end": 502,
                        "text": "27",
                        "ref_id": "FIGREF106"
                    }
                ],
                "eq_spans": [],
                "section": "Additional Ablation Studies",
                "sec_num": "G"
            },
            {
                "text": "For completeness, we also visualize the results with our default setting on the task car in Fig. FIGREF103 , FIGREF105 and FIGREF107 .",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 97,
                        "end": 106,
                        "text": "24",
                        "ref_id": "FIGREF103"
                    },
                    {
                        "start": 109,
                        "end": 118,
                        "text": "26",
                        "ref_id": "FIGREF105"
                    },
                    {
                        "start": 123,
                        "end": 132,
                        "text": "28",
                        "ref_id": "FIGREF107"
                    }
                ],
                "eq_spans": [],
                "section": "Additional Ablation Studies",
                "sec_num": "G"
            },
            {
                "text": "Here, we present some of the best RL samples from rollouts, as well as examples from the agentic workflow. Fig. FIGREF109 displays the RL rollout samples, while Fig. FIGREF111 illustrates the agentic workflow samples.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 112,
                        "end": 121,
                        "text": "29",
                        "ref_id": "FIGREF109"
                    },
                    {
                        "start": 166,
                        "end": 175,
                        "text": "30",
                        "ref_id": "FIGREF111"
                    }
                ],
                "eq_spans": [],
                "section": "Generated Samples::From RL-finetuned Models",
                "sec_num": "H.1"
            },
            {
                "text": "To further investigate if high-level machine blueprint or low-level part placement is more important, we experiment with machine generation of LLMs by generating machine details conditioned on Gemini-generated CoT (instead of on CoT produced by themselves). We find that with Gemini CoT, almost all LLMs design machines that are more visually similar to \"catapults\", as shown in Fig. FIGREF112 . We therefore hypothesize that the major gap between other LLMs, especially open-source ones, and Gemini 2.5 Pro is the abstract-level spatial and physics reasoning on machine designs.",
                "cite_spans": [],
                "ref_spans": [
                    {
                        "start": 384,
                        "end": 393,
                        "text": "31",
                        "ref_id": "FIGREF112"
                    }
                ],
                "eq_spans": [],
                "section": "Relations between CoT and Machines",
                "sec_num": "I"
            }
        ],
        "back_matter": [],
        "bib_entries": {
            "BIBREF19": {
                "ref_id": "BIBREF19",
                "title": "Generating CAD code with vision-language models for 3d designs",
                "authors": [
                    {
                        "first": "Pradyumna",
                        "middle": [],
                        "last": "Kamel Alrashedy",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Tambwekar",
                        "suffix": ""
                    },
                    {
                        "first": "Haider",
                        "middle": [],
                        "last": "Zulfiqar",
                        "suffix": ""
                    },
                    {
                        "first": "Megan",
                        "middle": [],
                        "last": "Zaidi",
                        "suffix": ""
                    },
                    {
                        "first": "Wei",
                        "middle": [],
                        "last": "Langwasser",
                        "suffix": ""
                    },
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Gombolay",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 0,
                "urls": [],
                "raw_text": "Kamel Alrashedy, Pradyumna Tambwekar, Zulfiqar Haider Zaidi, Megan Langwasser, Wei Xu, and Matthew Gombolay. Generating CAD code with vision-language models for 3d designs. In ICLR, 2025.",
                "links": null
            },
            "BIBREF63": {
                "ref_id": "BIBREF63",
                "title": "Constitutional ai: Harmlessness from ai feedback",
                "authors": [
                    {
                        "first": "Yuntao",
                        "middle": [],
                        "last": "Bai",
                        "suffix": ""
                    },
                    {
                        "first": "Saurav",
                        "middle": [],
                        "last": "Kadavath",
                        "suffix": ""
                    },
                    {
                        "first": "Sandipan",
                        "middle": [],
                        "last": "Kundu",
                        "suffix": ""
                    },
                    {
                        "first": "Amanda",
                        "middle": [],
                        "last": "Askell",
                        "suffix": ""
                    },
                    {
                        "first": "Jackson",
                        "middle": [],
                        "last": "Kernion",
                        "suffix": ""
                    },
                    {
                        "first": "Andy",
                        "middle": [],
                        "last": "Jones",
                        "suffix": ""
                    },
                    {
                        "first": "Anna",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Anna",
                        "middle": [],
                        "last": "Goldie",
                        "suffix": ""
                    },
                    {
                        "first": "Azalia",
                        "middle": [],
                        "last": "Mirhoseini",
                        "suffix": ""
                    },
                    {
                        "first": "Cameron",
                        "middle": [],
                        "last": "Mckinnon",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2212.08073"
                    ]
                },
                "num": 1,
                "urls": [],
                "raw_text": "Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness from ai feedback. arXiv preprint arXiv:2212.08073, 2022.",
                "links": null
            },
            "BIBREF0": {
                "ref_id": "BIBREF0",
                "title": "Engineering design: a systematic approach",
                "authors": [
                    {
                        "first": "",
                        "middle": [],
                        "last": "Beitz",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Pahl",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Grote",
                        "suffix": ""
                    }
                ],
                "year": 1996,
                "venue": "Mrs Bulletin",
                "volume": "71",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 2,
                "urls": [],
                "raw_text": "W Beitz, G Pahl, and K Grote. Engineering design: a systematic approach. Mrs Bulletin, 71:30, 1996.",
                "links": null
            },
            "BIBREF54": {
                "ref_id": "BIBREF54",
                "title": "Graph of thoughts: Solving elaborate problems with large language models",
                "authors": [
                    {
                        "first": "Maciej",
                        "middle": [],
                        "last": "Besta",
                        "suffix": ""
                    },
                    {
                        "first": "Nils",
                        "middle": [],
                        "last": "Blach",
                        "suffix": ""
                    },
                    {
                        "first": "Ales",
                        "middle": [],
                        "last": "Kubicek",
                        "suffix": ""
                    },
                    {
                        "first": "Robert",
                        "middle": [],
                        "last": "Gerstenberger",
                        "suffix": ""
                    },
                    {
                        "first": "Michal",
                        "middle": [],
                        "last": "Podstawski",
                        "suffix": ""
                    },
                    {
                        "first": "Lukas",
                        "middle": [],
                        "last": "Gianinazzi",
                        "suffix": ""
                    },
                    {
                        "first": "Joanna",
                        "middle": [],
                        "last": "Gajda",
                        "suffix": ""
                    },
                    {
                        "first": "Tomasz",
                        "middle": [],
                        "last": "Lehmann",
                        "suffix": ""
                    },
                    {
                        "first": "Hubert",
                        "middle": [],
                        "last": "Niewiadomski",
                        "suffix": ""
                    },
                    {
                        "first": "Piotr",
                        "middle": [],
                        "last": "Nyczyk",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "AAAI",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 3,
                "urls": [],
                "raw_text": "Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, et al. Graph of thoughts: Solving elaborate problems with large language models. In AAAI, 2024.",
                "links": null
            },
            "BIBREF50": {
                "ref_id": "BIBREF50",
                "title": "Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors",
                "authors": [
                    {
                        "first": "Weize",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Yusheng",
                        "middle": [],
                        "last": "Su",
                        "suffix": ""
                    },
                    {
                        "first": "Jingwei",
                        "middle": [],
                        "last": "Zuo",
                        "suffix": ""
                    },
                    {
                        "first": "Cheng",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Chenfei",
                        "middle": [],
                        "last": "Yuan",
                        "suffix": ""
                    },
                    {
                        "first": "Chi-Min",
                        "middle": [],
                        "last": "Chan",
                        "suffix": ""
                    },
                    {
                        "first": "Heyang",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Yaxi",
                        "middle": [],
                        "last": "Lu",
                        "suffix": ""
                    },
                    {
                        "first": "Yi-Hsin",
                        "middle": [],
                        "last": "Hung",
                        "suffix": ""
                    },
                    {
                        "first": "Chen",
                        "middle": [],
                        "last": "Qian",
                        "suffix": ""
                    },
                    {
                        "first": "Yujia",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "Xin",
                        "middle": [],
                        "last": "Cong",
                        "suffix": ""
                    },
                    {
                        "first": "Ruobing",
                        "middle": [],
                        "last": "Xie",
                        "suffix": ""
                    },
                    {
                        "first": "Zhiyuan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Maosong",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Jie",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 4,
                "urls": [],
                "raw_text": "Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, Yujia Qin, Xin Cong, Ruobing Xie, Zhiyuan Liu, Maosong Sun, and Jie Zhou. Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors. In ICLR, 2024.",
                "links": null
            },
            "BIBREF29": {
                "ref_id": "BIBREF29",
                "title": "Symbolic graphics programming with large language models",
                "authors": [
                    {
                        "first": "Yamei",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Haoquan",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Yangyi",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Zeju",
                        "middle": [],
                        "last": "Qiu",
                        "suffix": ""
                    },
                    {
                        "first": "Kaipeng",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Yandong",
                        "middle": [],
                        "last": "Wen",
                        "suffix": ""
                    },
                    {
                        "first": "Weiyang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2509.05208"
                    ]
                },
                "num": 5,
                "urls": [],
                "raw_text": "Yamei Chen, Haoquan Zhang, Yangyi Huang, Zeju Qiu, Kaipeng Zhang, Yandong Wen, and Weiyang Liu. Symbolic graphics programming with large language models. arXiv preprint arXiv:2509.05208, 2025a.",
                "links": null
            },
            "BIBREF32": {
                "ref_id": "BIBREF32",
                "title": "Sar3d: Autoregressive 3d object generation and understanding via multi-scale 3d vqvae",
                "authors": [
                    {
                        "first": "Yongwei",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Yushi",
                        "middle": [],
                        "last": "Lan",
                        "suffix": ""
                    },
                    {
                        "first": "Shangchen",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Tengfei",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Xingang",
                        "middle": [],
                        "last": "Pan",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "CVPR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 6,
                "urls": [],
                "raw_text": "Yongwei Chen, Yushi Lan, Shangchen Zhou, Tengfei Wang, and Xingang Pan. Sar3d: Autoregressive 3d object generation and understanding via multi-scale 3d vqvae. In CVPR, 2025b.",
                "links": null
            },
            "BIBREF21": {
                "ref_id": "BIBREF21",
                "title": "Pass@ k training for adaptively balancing exploration and exploitation of large reasoning models",
                "authors": [
                    {
                        "first": "Zhipeng",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaobo",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "Youbin",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Yue",
                        "middle": [],
                        "last": "Ling",
                        "suffix": ""
                    },
                    {
                        "first": "Qinghao",
                        "middle": [],
                        "last": "Ye",
                        "suffix": ""
                    },
                    {
                        "first": "Wayne",
                        "middle": [
                            "Xin"
                        ],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Guang",
                        "middle": [],
                        "last": "Shi",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2508.10751"
                    ]
                },
                "num": 7,
                "urls": [],
                "raw_text": "Zhipeng Chen, Xiaobo Qin, Youbin Wu, Yue Ling, Qinghao Ye, Wayne Xin Zhao, and Guang Shi. Pass@ k training for adaptively balancing exploration and exploitation of large reasoning models. arXiv preprint arXiv:2508.10751, 2025c.",
                "links": null
            },
            "BIBREF23": {
                "ref_id": "BIBREF23",
                "title": "Reasoning with exploration: An entropy perspective",
                "authors": [
                    {
                        "first": "Daixuan",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    },
                    {
                        "first": "Shaohan",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Xuekai",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Bo",
                        "middle": [],
                        "last": "Dai",
                        "suffix": ""
                    },
                    {
                        "first": "Wayne",
                        "middle": [
                            "Xin"
                        ],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Zhenliang",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Furu",
                        "middle": [],
                        "last": "Wei",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2506.14758"
                    ]
                },
                "num": 8,
                "urls": [],
                "raw_text": "Daixuan Cheng, Shaohan Huang, Xuekai Zhu, Bo Dai, Wayne Xin Zhao, Zhenliang Zhang, and Furu Wei. Reasoning with exploration: An entropy perspective. arXiv preprint arXiv:2506.14758, 2025.",
                "links": null
            },
            "BIBREF6": {
                "ref_id": "BIBREF6",
                "title": "Efficient selectivity and backup operators in monte-carlo tree search",
                "authors": [
                    {
                        "first": "R\u00e9mi",
                        "middle": [],
                        "last": "Coulom",
                        "suffix": ""
                    }
                ],
                "year": 2006,
                "venue": "International conference on computers and games",
                "volume": "",
                "issue": "",
                "pages": "72--83",
                "other_ids": {},
                "num": 9,
                "urls": [],
                "raw_text": "R\u00e9mi Coulom. Efficient selectivity and backup operators in monte-carlo tree search. In International conference on computers and games, pp. 72\u201383. Springer, 2006.",
                "links": null
            },
            "BIBREF22": {
                "ref_id": "BIBREF22",
                "title": "The entropy mechanism of reinforcement learning for reasoning language models",
                "authors": [
                    {
                        "first": "Ganqu",
                        "middle": [],
                        "last": "Cui",
                        "suffix": ""
                    },
                    {
                        "first": "Yuchen",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Jiacheng",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Lifan",
                        "middle": [],
                        "last": "Yuan",
                        "suffix": ""
                    },
                    {
                        "first": "Zhi",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yuxin",
                        "middle": [],
                        "last": "Zuo",
                        "suffix": ""
                    },
                    {
                        "first": "Haozhan",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Yuchen",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    },
                    {
                        "first": "Huayu",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Weize",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2505.22617"
                    ]
                },
                "num": 10,
                "urls": [],
                "raw_text": "Ganqu Cui, Yuchen Zhang, Jiacheng Chen, Lifan Yuan, Zhi Wang, Yuxin Zuo, Haozhan Li, Yuchen Fan, Huayu Chen, Weize Chen, et al. The entropy mechanism of reinforcement learning for reasoning language models. arXiv preprint arXiv:2505.22617, 2025.",
                "links": null
            },
            "BIBREF28": {
                "ref_id": "BIBREF28",
                "title": "Unsupervised learning of shape programs with repeatable implicit parts",
                "authors": [
                    {
                        "first": "Boyang",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "Sumith",
                        "middle": [],
                        "last": "Kulal",
                        "suffix": ""
                    },
                    {
                        "first": "Zhengyang",
                        "middle": [],
                        "last": "Dong",
                        "suffix": ""
                    },
                    {
                        "first": "Congyue",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "Yonglong",
                        "middle": [],
                        "last": "Tian",
                        "suffix": ""
                    },
                    {
                        "first": "Jiajun",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 11,
                "urls": [],
                "raw_text": "Boyang Deng, Sumith Kulal, Zhengyang Dong, Congyue Deng, Yonglong Tian, and Jiajun Wu. Unsupervised learning of shape programs with repeatable implicit parts. NeurIPS, 2022.",
                "links": null
            },
            "BIBREF55": {
                "ref_id": "BIBREF55",
                "title": "On the multi-turn instruction following for conversational web agents",
                "authors": [
                    {
                        "first": "Yang",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "Xuan",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Wenxuan",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Yifei",
                        "middle": [],
                        "last": "Yuan",
                        "suffix": ""
                    },
                    {
                        "first": "See-Kiong",
                        "middle": [],
                        "last": "Ng",
                        "suffix": ""
                    },
                    {
                        "first": "Tat-Seng",
                        "middle": [],
                        "last": "Chua",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2402.15057"
                    ]
                },
                "num": 12,
                "urls": [],
                "raw_text": "Yang Deng, Xuan Zhang, Wenxuan Zhang, Yifei Yuan, See-Kiong Ng, and Tat-Seng Chua. On the multi-turn instruction following for conversational web agents. arXiv preprint arXiv:2402.15057, 2024.",
                "links": null
            },
            "BIBREF66": {
                "ref_id": "BIBREF66",
                "title": "8-bit optimizers via block-wise quantization",
                "authors": [
                    {
                        "first": "Tim",
                        "middle": [],
                        "last": "Dettmers",
                        "suffix": ""
                    },
                    {
                        "first": "Mike",
                        "middle": [],
                        "last": "Lewis",
                        "suffix": ""
                    },
                    {
                        "first": "Sam",
                        "middle": [],
                        "last": "Shleifer",
                        "suffix": ""
                    },
                    {
                        "first": "Luke",
                        "middle": [],
                        "last": "Zettlemoyer",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 13,
                "urls": [],
                "raw_text": "Tim Dettmers, Mike Lewis, Sam Shleifer, and Luke Zettlemoyer. 8-bit optimizers via block-wise quantization. In ICLR, 2022.",
                "links": null
            },
            "BIBREF2": {
                "ref_id": "BIBREF2",
                "title": "Minedojo: Building open-ended embodied agents with internet-scale knowledge",
                "authors": [
                    {
                        "first": "Linxi",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    },
                    {
                        "first": "Guanzhi",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yunfan",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Ajay",
                        "middle": [],
                        "last": "Mandlekar",
                        "suffix": ""
                    },
                    {
                        "first": "Yuncong",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Haoyi",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "De-An",
                        "suffix": ""
                    },
                    {
                        "first": "Yuke",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Anima",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Anandkumar",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 14,
                "urls": [],
                "raw_text": "Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu, and Anima Anandkumar. Minedojo: Building open-ended embodied agents with internet-scale knowledge. NeurIPS, 2022.",
                "links": null
            },
            "BIBREF57": {
                "ref_id": "BIBREF57",
                "title": "Pal: Program-aided language models",
                "authors": [
                    {
                        "first": "Luyu",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Aman",
                        "middle": [],
                        "last": "Madaan",
                        "suffix": ""
                    },
                    {
                        "first": "Shuyan",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Uri",
                        "middle": [],
                        "last": "Alon",
                        "suffix": ""
                    },
                    {
                        "first": "Pengfei",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Yiming",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Jamie",
                        "middle": [],
                        "last": "Callan",
                        "suffix": ""
                    },
                    {
                        "first": "Graham",
                        "middle": [],
                        "last": "Neubig",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 15,
                "urls": [],
                "raw_text": "Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. Pal: Program-aided language models. In ICML, 2023.",
                "links": null
            },
            "BIBREF62": {
                "ref_id": "BIBREF62",
                "title": "Deepseek-r1 incentivizes reasoning in llms through reinforcement learning",
                "authors": [
                    {
                        "first": "Dejian",
                        "middle": [],
                        "last": "Daya Guo",
                        "suffix": ""
                    },
                    {
                        "first": "Haowei",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Junxiao",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Peiyi",
                        "middle": [],
                        "last": "Song",
                        "suffix": ""
                    },
                    {
                        "first": "Qihao",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Runxin",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Ruoyu",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Shirong",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Xiao",
                        "middle": [],
                        "last": "Ma",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Bi",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "Nature",
                "volume": "645",
                "issue": "8081",
                "pages": "633--638",
                "other_ids": {},
                "num": 16,
                "urls": [],
                "raw_text": "Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Peiyi Wang, Qihao Zhu, Runxin Xu, Ruoyu Zhang, Shirong Ma, Xiao Bi, et al. Deepseek-r1 incentivizes reasoning in llms through reinforcement learning. Nature, 645(8081):633\u2013638, 2025.",
                "links": null
            },
            "BIBREF15": {
                "ref_id": "BIBREF15",
                "title": "Lora: Low-rank adaptation of large language models",
                "authors": [
                    {
                        "first": "Edward",
                        "middle": [
                            "J"
                        ],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Yelong",
                        "middle": [],
                        "last": "Shen",
                        "suffix": ""
                    },
                    {
                        "first": "Phillip",
                        "middle": [],
                        "last": "Wallis",
                        "suffix": ""
                    },
                    {
                        "first": "Zeyuan",
                        "middle": [],
                        "last": "Allen-Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Yuanzhi",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Shean",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Lu",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Weizhu",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 17,
                "urls": [],
                "raw_text": "Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. In ICLR, 2022.",
                "links": null
            },
            "BIBREF65": {
                "ref_id": "BIBREF65",
                "title": "Amortizing intractable inference in large language models",
                "authors": [
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Edward",
                        "suffix": ""
                    },
                    {
                        "first": "Moksh",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [],
                        "last": "Jain",
                        "suffix": ""
                    },
                    {
                        "first": "Younesse",
                        "middle": [],
                        "last": "Elmoznino",
                        "suffix": ""
                    },
                    {
                        "first": "Guillaume",
                        "middle": [],
                        "last": "Kaddar",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Lajoie",
                        "suffix": ""
                    },
                    {
                        "first": "Nikolay",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Malkin",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 18,
                "urls": [],
                "raw_text": "Edward J Hu, Moksh Jain, Eric Elmoznino, Younesse Kaddar, Guillaume Lajoie, Yoshua Bengio, and Nikolay Malkin. Amortizing intractable inference in large language models. In ICLR, 2024a.",
                "links": null
            },
            "BIBREF46": {
                "ref_id": "BIBREF46",
                "title": "3d building generation in minecraft via large language models",
                "authors": [
                    {
                        "first": "Shiying",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Zengrong",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Chengpeng",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Jialin",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "2024 IEEE Conference on Games (CoG)",
                "volume": "",
                "issue": "",
                "pages": "1--4",
                "other_ids": {},
                "num": 19,
                "urls": [],
                "raw_text": "Shiying Hu, Zengrong Huang, Chengpeng Hu, and Jialin Liu. 3d building generation in minecraft via large language models. In 2024 IEEE Conference on Games (CoG), pp. 1\u20134. IEEE, 2024b.",
                "links": null
            },
            "BIBREF39": {
                "ref_id": "BIBREF39",
                "title": "Scenecraft: An llm agent for synthesizing 3d scenes as blender code",
                "authors": [
                    {
                        "first": "Ziniu",
                        "middle": [],
                        "last": "Hu",
                        "suffix": ""
                    },
                    {
                        "first": "Ahmet",
                        "middle": [],
                        "last": "Iscen",
                        "suffix": ""
                    },
                    {
                        "first": "Aashi",
                        "middle": [],
                        "last": "Jain",
                        "suffix": ""
                    },
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Kipf",
                        "suffix": ""
                    },
                    {
                        "first": "Yisong",
                        "middle": [],
                        "last": "Yue",
                        "suffix": ""
                    },
                    {
                        "first": "David",
                        "middle": [
                            "A"
                        ],
                        "last": "Ross",
                        "suffix": ""
                    },
                    {
                        "first": "Cordelia",
                        "middle": [],
                        "last": "Schmid",
                        "suffix": ""
                    },
                    {
                        "first": "Alireza",
                        "middle": [],
                        "last": "Fathi",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 20,
                "urls": [],
                "raw_text": "Ziniu Hu, Ahmet Iscen, Aashi Jain, Thomas Kipf, Yisong Yue, David A Ross, Cordelia Schmid, and Alireza Fathi. Scenecraft: An llm agent for synthesizing 3d scenes as blender code. In ICML, 2024c.",
                "links": null
            },
            "BIBREF34": {
                "ref_id": "BIBREF34",
                "title": "Blenderalchemy: Editing 3d graphics with vision-language models",
                "authors": [
                    {
                        "first": "Ian",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Guandao",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Leonidas",
                        "middle": [],
                        "last": "Guibas",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "ECCV",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 21,
                "urls": [],
                "raw_text": "Ian Huang, Guandao Yang, and Leonidas Guibas. Blenderalchemy: Editing 3d graphics with vision-language models. In ECCV, 2024.",
                "links": null
            },
            "BIBREF36": {
                "ref_id": "BIBREF36",
                "title": "Shapelib: Designing a library of programmatic 3d shape abstractions with large language models",
                "authors": [
                    {
                        "first": "Kenny",
                        "middle": [],
                        "last": "Jones",
                        "suffix": ""
                    },
                    {
                        "first": "Paul",
                        "middle": [],
                        "last": "Guerrero",
                        "suffix": ""
                    },
                    {
                        "first": "Niloy",
                        "middle": [
                            "J"
                        ],
                        "last": "Mitra",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Ritchie",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2502.08884"
                    ]
                },
                "num": 22,
                "urls": [],
                "raw_text": "R Kenny Jones, Paul Guerrero, Niloy J Mitra, and Daniel Ritchie. Shapelib: Designing a library of programmatic 3d shape abstractions with large language models. arXiv preprint arXiv:2502.08884, 2025.",
                "links": null
            },
            "BIBREF42": {
                "ref_id": "BIBREF42",
                "title": "Leveraging large language models to improve rest api testing",
                "authors": [
                    {
                        "first": "Myeongsoo",
                        "middle": [],
                        "last": "Kim",
                        "suffix": ""
                    },
                    {
                        "first": "Tyler",
                        "middle": [],
                        "last": "Stennett",
                        "suffix": ""
                    },
                    {
                        "first": "Dhruv",
                        "middle": [],
                        "last": "Shah",
                        "suffix": ""
                    },
                    {
                        "first": "Saurabh",
                        "middle": [],
                        "last": "Sinha",
                        "suffix": ""
                    },
                    {
                        "first": "Alessandro",
                        "middle": [],
                        "last": "Orso",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results",
                "volume": "",
                "issue": "",
                "pages": "37--41",
                "other_ids": {},
                "num": 23,
                "urls": [],
                "raw_text": "Myeongsoo Kim, Tyler Stennett, Dhruv Shah, Saurabh Sinha, and Alessandro Orso. Leveraging large language models to improve rest api testing. In Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results, pp. 37\u201341, 2024.",
                "links": null
            },
            "BIBREF53": {
                "ref_id": "BIBREF53",
                "title": "Tree search for language model agents",
                "authors": [
                    {
                        "first": "Jing",
                        "middle": [],
                        "last": "Yu Koh",
                        "suffix": ""
                    },
                    {
                        "first": "Stephen",
                        "middle": [
                            "Marcus"
                        ],
                        "last": "Mcaleer",
                        "suffix": ""
                    },
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Fried",
                        "suffix": ""
                    },
                    {
                        "first": "Russ",
                        "middle": [],
                        "last": "Salakhutdinov",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 24,
                "urls": [],
                "raw_text": "Jing Yu Koh, Stephen Marcus McAleer, Daniel Fried, and Russ Salakhutdinov. Tree search for language model agents. In ICLR, 2024.",
                "links": null
            },
            "BIBREF31": {
                "ref_id": "BIBREF31",
                "title": "Re-thinking inverse graphics with large language models",
                "authors": [
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Kulits",
                        "suffix": ""
                    },
                    {
                        "first": "Haiwen",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    },
                    {
                        "first": "Weiyang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Victoria",
                        "middle": [],
                        "last": "Fernandez Abrevaya",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [
                            "J"
                        ],
                        "last": "Black",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "Transactions on Machine Learning Research",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 25,
                "urls": [],
                "raw_text": "Peter Kulits, Haiwen Feng, Weiyang Liu, Victoria Fernandez Abrevaya, and Michael J Black. Re-thinking inverse graphics with large language models. Transactions on Machine Learning Research (TMLR), 2025.",
                "links": null
            },
            "BIBREF10": {
                "ref_id": "BIBREF10",
                "title": "Tulu 3: Pushing frontiers in open language model post-training",
                "authors": [
                    {
                        "first": "Nathan",
                        "middle": [],
                        "last": "Lambert",
                        "suffix": ""
                    },
                    {
                        "first": "Jacob",
                        "middle": [],
                        "last": "Morrison",
                        "suffix": ""
                    },
                    {
                        "first": "Valentina",
                        "middle": [],
                        "last": "Pyatkin",
                        "suffix": ""
                    },
                    {
                        "first": "Shengyi",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Hamish",
                        "middle": [],
                        "last": "Ivison",
                        "suffix": ""
                    },
                    {
                        "first": "Faeze",
                        "middle": [],
                        "last": "Brahman",
                        "suffix": ""
                    },
                    {
                        "first": "Lester",
                        "middle": [],
                        "last": "James Validad",
                        "suffix": ""
                    },
                    {
                        "first": "Alisa",
                        "middle": [],
                        "last": "Miranda",
                        "suffix": ""
                    },
                    {
                        "first": "Nouha",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Xinxi",
                        "middle": [],
                        "last": "Dziri",
                        "suffix": ""
                    },
                    {
                        "first": "Yuling",
                        "middle": [],
                        "last": "Lyu",
                        "suffix": ""
                    },
                    {
                        "first": "Saumya",
                        "middle": [],
                        "last": "Gu",
                        "suffix": ""
                    },
                    {
                        "first": "Victoria",
                        "middle": [],
                        "last": "Malik",
                        "suffix": ""
                    },
                    {
                        "first": "Jena",
                        "middle": [
                            "D"
                        ],
                        "last": "Graf",
                        "suffix": ""
                    },
                    {
                        "first": "Jiangjiang",
                        "middle": [],
                        "last": "Hwang",
                        "suffix": ""
                    },
                    {
                        "first": "Ronan",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Oyvind",
                        "middle": [],
                        "last": "Le Bras",
                        "suffix": ""
                    },
                    {
                        "first": "Christopher",
                        "middle": [],
                        "last": "Tafjord",
                        "suffix": ""
                    },
                    {
                        "first": "Luca",
                        "middle": [],
                        "last": "Wilhelm",
                        "suffix": ""
                    },
                    {
                        "first": "Noah",
                        "middle": [
                            "A"
                        ],
                        "last": "Soldaini",
                        "suffix": ""
                    },
                    {
                        "first": "Yizhong",
                        "middle": [],
                        "last": "Smith",
                        "suffix": ""
                    },
                    {
                        "first": "Pradeep",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Hannaneh",
                        "middle": [],
                        "last": "Dasigi",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Hajishirzi",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "COLM",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 26,
                "urls": [],
                "raw_text": "Nathan Lambert, Jacob Morrison, Valentina Pyatkin, Shengyi Huang, Hamish Ivison, Faeze Brahman, Lester James Validad Miranda, Alisa Liu, Nouha Dziri, Xinxi Lyu, Yuling Gu, Saumya Malik, Victoria Graf, Jena D. Hwang, Jiangjiang Yang, Ronan Le Bras, Oyvind Tafjord, Christopher Wilhelm, Luca Soldaini, Noah A. Smith, Yizhong Wang, Pradeep Dasigi, and Hannaneh Hajishirzi. Tulu 3: Pushing frontiers in open language model post-training. In COLM, 2025.",
                "links": null
            },
            "BIBREF49": {
                "ref_id": "BIBREF49",
                "title": "Camel: Communicative agents for\" mind\" exploration of large language model society",
                "authors": [
                    {
                        "first": "Guohao",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Hasan",
                        "middle": [],
                        "last": "Hammoud",
                        "suffix": ""
                    },
                    {
                        "first": "Hani",
                        "middle": [],
                        "last": "Itani",
                        "suffix": ""
                    },
                    {
                        "first": "Dmitrii",
                        "middle": [],
                        "last": "Khizbullin",
                        "suffix": ""
                    },
                    {
                        "first": "Bernard",
                        "middle": [],
                        "last": "Ghanem",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 27,
                "urls": [],
                "raw_text": "Guohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. Camel: Communicative agents for\" mind\" exploration of large language model society. NeurIPS, 2023.",
                "links": null
            },
            "BIBREF4": {
                "ref_id": "BIBREF4",
                "title": "Cad-llama: leveraging large language models for computer-aided design parametric 3d model generation",
                "authors": [
                    {
                        "first": "Jiahao",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Weijian",
                        "middle": [],
                        "last": "Ma",
                        "suffix": ""
                    },
                    {
                        "first": "Xueyang",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Yunzhong",
                        "middle": [],
                        "last": "Lou",
                        "suffix": ""
                    },
                    {
                        "first": "Guichun",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Xiangdong",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "CVPR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 28,
                "urls": [],
                "raw_text": "Jiahao Li, Weijian Ma, Xueyang Li, Yunzhong Lou, Guichun Zhou, and Xiangdong Zhou. Cad-llama: leveraging large language models for computer-aided design parametric 3d model generation. In CVPR, 2025.",
                "links": null
            },
            "BIBREF35": {
                "ref_id": "BIBREF35",
                "title": "Odyssey: Empowering minecraft agents with open-world skills",
                "authors": [
                    {
                        "first": "Shunyu",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Yaoru",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Kongcheng",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Zhenyu",
                        "middle": [],
                        "last": "Cui",
                        "suffix": ""
                    },
                    {
                        "first": "Wenkai",
                        "middle": [],
                        "last": "Fang",
                        "suffix": ""
                    },
                    {
                        "first": "Yuxuan",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "Tongya",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "Mingli",
                        "middle": [],
                        "last": "Song",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "IJCAI",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 29,
                "urls": [],
                "raw_text": "Shunyu Liu, Yaoru Li, Kongcheng Zhang, Zhenyu Cui, Wenkai Fang, Yuxuan Zheng, Tongya Zheng, and Mingli Song. Odyssey: Empowering minecraft agents with open-world skills. In IJCAI, 2025a.",
                "links": null
            },
            "BIBREF67": {
                "ref_id": "BIBREF67",
                "title": "Parameter-efficient orthogonal finetuning via butterfly factorization",
                "authors": [
                    {
                        "first": "Weiyang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Zeju",
                        "middle": [],
                        "last": "Qiu",
                        "suffix": ""
                    },
                    {
                        "first": "Yao",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    },
                    {
                        "first": "Yuliang",
                        "middle": [],
                        "last": "Xiu",
                        "suffix": ""
                    },
                    {
                        "first": "Yuxuan",
                        "middle": [],
                        "last": "Xue",
                        "suffix": ""
                    },
                    {
                        "first": "Longhui",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Haiwen",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    },
                    {
                        "first": "Zhen",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Juyeon",
                        "middle": [],
                        "last": "Heo",
                        "suffix": ""
                    },
                    {
                        "first": "Songyou",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 30,
                "urls": [],
                "raw_text": "Weiyang Liu, Zeju Qiu, Yao Feng, Yuliang Xiu, Yuxuan Xue, Longhui Yu, Haiwen Feng, Zhen Liu, Juyeon Heo, Songyou Peng, et al. Parameter-efficient orthogonal finetuning via butterfly factorization. In ICLR, 2024a.",
                "links": null
            },
            "BIBREF41": {
                "ref_id": "BIBREF41",
                "title": "Toolnet: Connecting large language models with massive tools via tool graph",
                "authors": [
                    {
                        "first": "Xukun",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Zhiyuan",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    },
                    {
                        "first": "Xiaoyuan",
                        "middle": [],
                        "last": "Yi",
                        "suffix": ""
                    },
                    {
                        "first": "Xing",
                        "middle": [],
                        "last": "Xie",
                        "suffix": ""
                    },
                    {
                        "first": "Lirong",
                        "middle": [],
                        "last": "Xiang",
                        "suffix": ""
                    },
                    {
                        "first": "Yuchen",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Dongkuan",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2403.00839"
                    ]
                },
                "num": 31,
                "urls": [],
                "raw_text": "Xukun Liu, Zhiyuan Peng, Xiaoyuan Yi, Xing Xie, Lirong Xiang, Yuchen Liu, and Dongkuan Xu. Toolnet: Connecting large language models with massive tools via tool graph. arXiv preprint arXiv:2403.00839, 2024b.",
                "links": null
            },
            "BIBREF24": {
                "ref_id": "BIBREF24",
                "title": "Efficient diversity-preserving diffusion alignment via gradient-informed gflownets",
                "authors": [
                    {
                        "first": "Zhen",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [
                            "Z"
                        ],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Weiyang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Yoshua",
                        "middle": [],
                        "last": "Bengio",
                        "suffix": ""
                    },
                    {
                        "first": "Dinghuai",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 32,
                "urls": [],
                "raw_text": "Zhen Liu, Tim Z Xiao, Weiyang Liu, Yoshua Bengio, and Dinghuai Zhang. Efficient diversity-preserving diffusion alignment via gradient-informed gflownets. In ICLR, 2025b.",
                "links": null
            },
            "BIBREF59": {
                "ref_id": "BIBREF59",
                "title": "Self-refine: Iterative refinement with self-feedback",
                "authors": [
                    {
                        "first": "Aman",
                        "middle": [],
                        "last": "Madaan",
                        "suffix": ""
                    },
                    {
                        "first": "Niket",
                        "middle": [],
                        "last": "Tandon",
                        "suffix": ""
                    },
                    {
                        "first": "Prakhar",
                        "middle": [],
                        "last": "Gupta",
                        "suffix": ""
                    },
                    {
                        "first": "Skyler",
                        "middle": [],
                        "last": "Hallinan",
                        "suffix": ""
                    },
                    {
                        "first": "Luyu",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    },
                    {
                        "first": "Sarah",
                        "middle": [],
                        "last": "Wiegreffe",
                        "suffix": ""
                    },
                    {
                        "first": "Uri",
                        "middle": [],
                        "last": "Alon",
                        "suffix": ""
                    },
                    {
                        "first": "Nouha",
                        "middle": [],
                        "last": "Dziri",
                        "suffix": ""
                    },
                    {
                        "first": "Shrimai",
                        "middle": [],
                        "last": "Prabhumoye",
                        "suffix": ""
                    },
                    {
                        "first": "Yiming",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 33,
                "urls": [],
                "raw_text": "Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement with self-feedback. NeurIPS, 2023.",
                "links": null
            },
            "BIBREF61": {
                "ref_id": "BIBREF61",
                "title": "How can large language models help humans in design and manufacturing",
                "authors": [
                    {
                        "first": "Liane",
                        "middle": [],
                        "last": "Makatura",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [],
                        "last": "Foshey",
                        "suffix": ""
                    },
                    {
                        "first": "Bohan",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Felix",
                        "middle": [],
                        "last": "H\u00e4hnlein",
                        "suffix": ""
                    },
                    {
                        "first": "Pingchuan",
                        "middle": [],
                        "last": "Ma",
                        "suffix": ""
                    },
                    {
                        "first": "Bolei",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "Megan",
                        "middle": [],
                        "last": "Tjandrasuwita",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Spielberg",
                        "suffix": ""
                    },
                    {
                        "first": "Crystal",
                        "middle": [
                            "Elaine"
                        ],
                        "last": "Owens",
                        "suffix": ""
                    },
                    {
                        "first": "Peter",
                        "middle": [],
                        "last": "Yichen Chen",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2307.14377"
                    ]
                },
                "num": 34,
                "urls": [],
                "raw_text": "Liane Makatura, Michael Foshey, Bohan Wang, Felix H\u00e4hnLein, Pingchuan Ma, Bolei Deng, Megan Tjandrasuwita, Andrew Spielberg, Crystal Elaine Owens, Peter Yichen Chen, et al. How can large language models help humans in design and manufacturing? arXiv preprint arXiv:2307.14377, 2023.",
                "links": null
            },
            "BIBREF38": {
                "ref_id": "BIBREF38",
                "title": "Large language models: A survey",
                "authors": [
                    {
                        "first": "Shervin",
                        "middle": [],
                        "last": "Minaee",
                        "suffix": ""
                    },
                    {
                        "first": "Tomas",
                        "middle": [],
                        "last": "Mikolov",
                        "suffix": ""
                    },
                    {
                        "first": "Narjes",
                        "middle": [],
                        "last": "Nikzad",
                        "suffix": ""
                    },
                    {
                        "first": "Meysam",
                        "middle": [],
                        "last": "Chenaghlu",
                        "suffix": ""
                    },
                    {
                        "first": "Richard",
                        "middle": [],
                        "last": "Socher",
                        "suffix": ""
                    },
                    {
                        "first": "Xavier",
                        "middle": [],
                        "last": "Amatriain",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2402.06196"
                    ]
                },
                "num": 35,
                "urls": [],
                "raw_text": "Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, and Jianfeng Gao. Large language models: A survey. arXiv preprint arXiv:2402.06196, 2024.",
                "links": null
            },
            "BIBREF58": {
                "ref_id": "BIBREF58",
                "title": "Alphaevolve: A coding agent for scientific and algorithmic discovery",
                "authors": [
                    {
                        "first": "Alexander",
                        "middle": [],
                        "last": "Novikov",
                        "suffix": ""
                    },
                    {
                        "first": "Ng\u00e2n",
                        "middle": [],
                        "last": "V\u0169",
                        "suffix": ""
                    },
                    {
                        "first": "Marvin",
                        "middle": [],
                        "last": "Eisenberger",
                        "suffix": ""
                    },
                    {
                        "first": "Emilien",
                        "middle": [],
                        "last": "Dupont",
                        "suffix": ""
                    },
                    {
                        "first": "Po-Sen",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [
                            "Zsolt"
                        ],
                        "last": "Wagner",
                        "suffix": ""
                    },
                    {
                        "first": "Sergey",
                        "middle": [],
                        "last": "Shirobokov",
                        "suffix": ""
                    },
                    {
                        "first": "Borislav",
                        "middle": [],
                        "last": "Kozlovskii",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [
                            "R"
                        ],
                        "last": "Francisco",
                        "suffix": ""
                    },
                    {
                        "first": "Abbas",
                        "middle": [],
                        "last": "Ruiz",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Mehrabian",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2506.13131"
                    ]
                },
                "num": 36,
                "urls": [],
                "raw_text": "Alexander Novikov, Ng\u00e2n V\u0169, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, Francisco JR Ruiz, Abbas Mehrabian, et al. Alphaevolve: A coding agent for scientific and algorithmic discovery. arXiv preprint arXiv:2506.13131, 2025.",
                "links": null
            },
            "BIBREF64": {
                "ref_id": "BIBREF64",
                "title": "Training language models to follow instructions with human feedback",
                "authors": [
                    {
                        "first": "Long",
                        "middle": [],
                        "last": "Ouyang",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Xu",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Diogo",
                        "middle": [],
                        "last": "Almeida",
                        "suffix": ""
                    },
                    {
                        "first": "Carroll",
                        "middle": [],
                        "last": "Wainwright",
                        "suffix": ""
                    },
                    {
                        "first": "Pamela",
                        "middle": [],
                        "last": "Mishkin",
                        "suffix": ""
                    },
                    {
                        "first": "Chong",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Sandhini",
                        "middle": [],
                        "last": "Agarwal",
                        "suffix": ""
                    },
                    {
                        "first": "Katarina",
                        "middle": [],
                        "last": "Slama",
                        "suffix": ""
                    },
                    {
                        "first": "Alex",
                        "middle": [],
                        "last": "Ray",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 37,
                "urls": [],
                "raw_text": "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. NeurIPS, 2022.",
                "links": null
            },
            "BIBREF3": {
                "ref_id": "BIBREF3",
                "title": "Generating physically stable and buildable brick structures from text",
                "authors": [
                    {
                        "first": "Ava",
                        "middle": [],
                        "last": "Pun",
                        "suffix": ""
                    },
                    {
                        "first": "Kangle",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "Ruixuan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Deva",
                        "middle": [],
                        "last": "Ramanan",
                        "suffix": ""
                    },
                    {
                        "first": "Changliu",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Jun-Yan",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "ICCV",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 38,
                "urls": [],
                "raw_text": "Ava Pun, Kangle Deng, Ruixuan Liu, Deva Ramanan, Changliu Liu, and Jun-Yan Zhu. Generating physically stable and buildable brick structures from text. In ICCV, 2025.",
                "links": null
            },
            "BIBREF52": {
                "ref_id": "BIBREF52",
                "title": "Agent q: Advanced reasoning and learning for autonomous ai agents",
                "authors": [
                    {
                        "first": "Pranav",
                        "middle": [],
                        "last": "Putta",
                        "suffix": ""
                    },
                    {
                        "first": "Edmund",
                        "middle": [],
                        "last": "Mills",
                        "suffix": ""
                    },
                    {
                        "first": "Naman",
                        "middle": [],
                        "last": "Garg",
                        "suffix": ""
                    },
                    {
                        "first": "Sumeet",
                        "middle": [],
                        "last": "Motwani",
                        "suffix": ""
                    },
                    {
                        "first": "Chelsea",
                        "middle": [],
                        "last": "Finn",
                        "suffix": ""
                    },
                    {
                        "first": "Divyansh",
                        "middle": [],
                        "last": "Garg",
                        "suffix": ""
                    },
                    {
                        "first": "Rafael",
                        "middle": [],
                        "last": "Rafailov",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2408.07199"
                    ]
                },
                "num": 39,
                "urls": [],
                "raw_text": "Pranav Putta, Edmund Mills, Naman Garg, Sumeet Motwani, Chelsea Finn, Divyansh Garg, and Rafael Rafailov. Agent q: Advanced reasoning and learning for autonomous ai agents. arXiv preprint arXiv:2408.07199, 2024.",
                "links": null
            },
            "BIBREF43": {
                "ref_id": "BIBREF43",
                "title": "ToolLLM: Facilitating large language models to master 16000+ real-world APIs",
                "authors": [
                    {
                        "first": "Yujia",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "Shihao",
                        "middle": [],
                        "last": "Liang",
                        "suffix": ""
                    },
                    {
                        "first": "Yining",
                        "middle": [],
                        "last": "Ye",
                        "suffix": ""
                    },
                    {
                        "first": "Kunlun",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Lan",
                        "middle": [],
                        "last": "Yan",
                        "suffix": ""
                    },
                    {
                        "first": "Yaxi",
                        "middle": [],
                        "last": "Lu",
                        "suffix": ""
                    },
                    {
                        "first": "Yankai",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Xin",
                        "middle": [],
                        "last": "Cong",
                        "suffix": ""
                    },
                    {
                        "first": "Xiangru",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "Bill",
                        "middle": [],
                        "last": "Qian",
                        "suffix": ""
                    },
                    {
                        "first": "Sihan",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Lauren",
                        "middle": [],
                        "last": "Hong",
                        "suffix": ""
                    },
                    {
                        "first": "Runchu",
                        "middle": [],
                        "last": "Tian",
                        "suffix": ""
                    },
                    {
                        "first": "Ruobing",
                        "middle": [],
                        "last": "Xie",
                        "suffix": ""
                    },
                    {
                        "first": "Jie",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    },
                    {
                        "first": "Mark",
                        "middle": [],
                        "last": "Gerstein",
                        "suffix": ""
                    },
                    {
                        "first": "Zhiyuan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Maosong",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 40,
                "urls": [],
                "raw_text": "Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, dahai li, Zhiyuan Liu, and Maosong Sun. ToolLLM: Facilitating large language models to master 16000+ real-world APIs. In ICLR, 2024.",
                "links": null
            },
            "BIBREF68": {
                "ref_id": "BIBREF68",
                "title": "Controlling text-to-image diffusion by orthogonal finetuning",
                "authors": [
                    {
                        "first": "Zeju",
                        "middle": [],
                        "last": "Qiu",
                        "suffix": ""
                    },
                    {
                        "first": "Weiyang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Haiwen",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    },
                    {
                        "first": "Yuxuan",
                        "middle": [],
                        "last": "Xue",
                        "suffix": ""
                    },
                    {
                        "first": "Yao",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    },
                    {
                        "first": "Zhen",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Dan",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Adrian",
                        "middle": [],
                        "last": "Weller",
                        "suffix": ""
                    },
                    {
                        "first": "Bernhard",
                        "middle": [],
                        "last": "Sch\u00f6lkopf",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 41,
                "urls": [],
                "raw_text": "Zeju Qiu, Weiyang Liu, Haiwen Feng, Yuxuan Xue, Yao Feng, Zhen Liu, Dan Zhang, Adrian Weller, and Bernhard Sch\u00f6lkopf. Controlling text-to-image diffusion by orthogonal finetuning. In NeurIPS, 2023.",
                "links": null
            },
            "BIBREF69": {
                "ref_id": "BIBREF69",
                "title": "Reparameterized llm training via orthogonal equivalence transformation",
                "authors": [
                    {
                        "first": "Zeju",
                        "middle": [],
                        "last": "Qiu",
                        "suffix": ""
                    },
                    {
                        "first": "Simon",
                        "middle": [],
                        "last": "Buchholz",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [
                            "Z"
                        ],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Maximilian",
                        "middle": [],
                        "last": "Dax",
                        "suffix": ""
                    },
                    {
                        "first": "Bernhard",
                        "middle": [],
                        "last": "Sch\u00f6lkopf",
                        "suffix": ""
                    },
                    {
                        "first": "Weiyang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 42,
                "urls": [],
                "raw_text": "Zeju Qiu, Simon Buchholz, Tim Z Xiao, Maximilian Dax, Bernhard Sch\u00f6lkopf, and Weiyang Liu. Reparameterized llm training via orthogonal equivalence transformation. In NeurIPS, 2025a.",
                "links": null
            },
            "BIBREF18": {
                "ref_id": "BIBREF18",
                "title": "Can large language models understand symbolic graphics programs?",
                "authors": [
                    {
                        "first": "Zeju",
                        "middle": [],
                        "last": "Qiu",
                        "suffix": ""
                    },
                    {
                        "first": "Weiyang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Haiwen",
                        "middle": [],
                        "last": "Feng",
                        "suffix": ""
                    },
                    {
                        "first": "Zhen",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [
                            "Z"
                        ],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Katherine",
                        "middle": [
                            "M"
                        ],
                        "last": "Collins",
                        "suffix": ""
                    },
                    {
                        "first": "Joshua",
                        "middle": [
                            "B"
                        ],
                        "last": "Tenenbaum",
                        "suffix": ""
                    },
                    {
                        "first": "Adrian",
                        "middle": [],
                        "last": "Weller",
                        "suffix": ""
                    },
                    {
                        "first": "Michael",
                        "middle": [
                            "J"
                        ],
                        "last": "Black",
                        "suffix": ""
                    },
                    {
                        "first": "Bernhard",
                        "middle": [],
                        "last": "Sch\u00f6lkopf",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 43,
                "urls": [],
                "raw_text": "Zeju Qiu, Weiyang Liu, Haiwen Feng, Zhen Liu, Tim Z. Xiao, Katherine M Collins, Joshua B Tenenbaum, Adrian Weller, Michael J Black, and Bernhard Sch\u00f6lkopf. Can large language models understand symbolic graphics programs? In ICLR, 2025b.",
                "links": null
            },
            "BIBREF70": {
                "ref_id": "BIBREF70",
                "title": "Orthogonal finetuning made scalable",
                "authors": [
                    {
                        "first": "Zeju",
                        "middle": [],
                        "last": "Qiu",
                        "suffix": ""
                    },
                    {
                        "first": "Weiyang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Adrian",
                        "middle": [],
                        "last": "Weller",
                        "suffix": ""
                    },
                    {
                        "first": "Bernhard",
                        "middle": [],
                        "last": "Sch\u00f6lkopf",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "EMNLP",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 44,
                "urls": [],
                "raw_text": "Zeju Qiu, Weiyang Liu, Adrian Weller, and Bernhard Sch\u00f6lkopf. Orthogonal finetuning made scalable. In EMNLP, 2025c.",
                "links": null
            },
            "BIBREF56": {
                "ref_id": "BIBREF56",
                "title": "Self-reflection in llm agents: Effects on problem-solving performance",
                "authors": [
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Renze",
                        "suffix": ""
                    },
                    {
                        "first": "Erhan",
                        "middle": [],
                        "last": "Guven",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2405.06682"
                    ]
                },
                "num": 45,
                "urls": [],
                "raw_text": "Matthew Renze and Erhan Guven. Self-reflection in llm agents: Effects on problem-solving performance. arXiv preprint arXiv:2405.06682, 2024.",
                "links": null
            },
            "BIBREF26": {
                "ref_id": "BIBREF26",
                "title": "Neurosymbolic models for computer graphics",
                "authors": [
                    {
                        "first": "Daniel",
                        "middle": [],
                        "last": "Ritchie",
                        "suffix": ""
                    },
                    {
                        "first": "Paul",
                        "middle": [],
                        "last": "Guerrero",
                        "suffix": ""
                    },
                    {
                        "first": "Kenny",
                        "middle": [],
                        "last": "Jones",
                        "suffix": ""
                    },
                    {
                        "first": "Niloy",
                        "middle": [],
                        "last": "Mitra",
                        "suffix": ""
                    },
                    {
                        "first": "Adriana",
                        "middle": [],
                        "last": "Schulz",
                        "suffix": ""
                    },
                    {
                        "first": "Karl",
                        "middle": [
                            "D"
                        ],
                        "last": "Willis",
                        "suffix": ""
                    },
                    {
                        "first": "Jiajun",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "Eurographics",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 46,
                "urls": [],
                "raw_text": "Daniel Ritchie, Paul Guerrero, R Kenny Jones, Niloy Mitra, Adriana Schulz, Karl D Willis, and Jiajun Wu. Neurosymbolic models for computer graphics. In Eurographics, 2023.",
                "links": null
            },
            "BIBREF44": {
                "ref_id": "BIBREF44",
                "title": "Habitat: A platform for embodied ai research",
                "authors": [
                    {
                        "first": "Manolis",
                        "middle": [],
                        "last": "Savva",
                        "suffix": ""
                    },
                    {
                        "first": "Abhishek",
                        "middle": [],
                        "last": "Kadian",
                        "suffix": ""
                    },
                    {
                        "first": "Oleksandr",
                        "middle": [],
                        "last": "Maksymets",
                        "suffix": ""
                    },
                    {
                        "first": "Yili",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Erik",
                        "middle": [],
                        "last": "Wijmans",
                        "suffix": ""
                    },
                    {
                        "first": "Bhavana",
                        "middle": [],
                        "last": "Jain",
                        "suffix": ""
                    },
                    {
                        "first": "Julian",
                        "middle": [],
                        "last": "Straub",
                        "suffix": ""
                    },
                    {
                        "first": "Jia",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Vladlen",
                        "middle": [],
                        "last": "Koltun",
                        "suffix": ""
                    },
                    {
                        "first": "Jitendra",
                        "middle": [],
                        "last": "Malik",
                        "suffix": ""
                    }
                ],
                "year": 2019,
                "venue": "CVPR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 47,
                "urls": [],
                "raw_text": "Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans, Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra Malik, et al. Habitat: A platform for embodied ai research. In CVPR, 2019.",
                "links": null
            },
            "BIBREF40": {
                "ref_id": "BIBREF40",
                "title": "Toolformer: Language models can teach themselves to use tools",
                "authors": [
                    {
                        "first": "Timo",
                        "middle": [],
                        "last": "Schick",
                        "suffix": ""
                    },
                    {
                        "first": "Jane",
                        "middle": [],
                        "last": "Dwivedi-Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Roberto",
                        "middle": [],
                        "last": "Dess\u00ec",
                        "suffix": ""
                    },
                    {
                        "first": "Roberta",
                        "middle": [],
                        "last": "Raileanu",
                        "suffix": ""
                    },
                    {
                        "first": "Maria",
                        "middle": [],
                        "last": "Lomeli",
                        "suffix": ""
                    },
                    {
                        "first": "Eric",
                        "middle": [],
                        "last": "Hambro",
                        "suffix": ""
                    },
                    {
                        "first": "Luke",
                        "middle": [],
                        "last": "Zettlemoyer",
                        "suffix": ""
                    },
                    {
                        "first": "Nicola",
                        "middle": [],
                        "last": "Cancedda",
                        "suffix": ""
                    },
                    {
                        "first": "Thomas",
                        "middle": [],
                        "last": "Scialom",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 48,
                "urls": [],
                "raw_text": "Timo Schick, Jane Dwivedi-Yu, Roberto Dess\u00ec, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. NeurIPS, 2023.",
                "links": null
            },
            "BIBREF25": {
                "ref_id": "BIBREF25",
                "title": "Progress & compress: A scalable framework for continual learning",
                "authors": [
                    {
                        "first": "Jonathan",
                        "middle": [],
                        "last": "Schwarz",
                        "suffix": ""
                    },
                    {
                        "first": "Wojciech",
                        "middle": [],
                        "last": "Czarnecki",
                        "suffix": ""
                    },
                    {
                        "first": "Jelena",
                        "middle": [],
                        "last": "Luketina",
                        "suffix": ""
                    },
                    {
                        "first": "Agnieszka",
                        "middle": [],
                        "last": "Grabska-Barwinska",
                        "suffix": ""
                    },
                    {
                        "first": "Yee",
                        "middle": [
                            "Whye"
                        ],
                        "last": "Teh",
                        "suffix": ""
                    },
                    {
                        "first": "Razvan",
                        "middle": [],
                        "last": "Pascanu",
                        "suffix": ""
                    },
                    {
                        "first": "Raia",
                        "middle": [],
                        "last": "Hadsell",
                        "suffix": ""
                    }
                ],
                "year": 2018,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 49,
                "urls": [],
                "raw_text": "Jonathan Schwarz, Wojciech Czarnecki, Jelena Luketina, Agnieszka Grabska-Barwinska, Yee Whye Teh, Razvan Pascanu, and Raia Hadsell. Progress & compress: A scalable framework for continual learning. In ICML, 2018.",
                "links": null
            },
            "BIBREF14": {
                "ref_id": "BIBREF14",
                "title": "Deepseekmath: Pushing the limits of mathematical reasoning in open language models",
                "authors": [
                    {
                        "first": "Zhihong",
                        "middle": [],
                        "last": "Shao",
                        "suffix": ""
                    },
                    {
                        "first": "Peiyi",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Qihao",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Runxin",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Junxiao",
                        "middle": [],
                        "last": "Song",
                        "suffix": ""
                    },
                    {
                        "first": "Xiao",
                        "middle": [],
                        "last": "Bi",
                        "suffix": ""
                    },
                    {
                        "first": "Haowei",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Mingchuan",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Y",
                        "middle": [
                            "K"
                        ],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Yang",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2402.03300"
                    ]
                },
                "num": 50,
                "urls": [],
                "raw_text": "Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Yang Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.",
                "links": null
            },
            "BIBREF17": {
                "ref_id": "BIBREF17",
                "title": "Hybridflow: A flexible and efficient rlhf framework",
                "authors": [
                    {
                        "first": "Guangming",
                        "middle": [],
                        "last": "Sheng",
                        "suffix": ""
                    },
                    {
                        "first": "Chi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Zilingfeng",
                        "middle": [],
                        "last": "Ye",
                        "suffix": ""
                    },
                    {
                        "first": "Xibin",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Wang",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Ru",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Yanghua",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    },
                    {
                        "first": "Haibin",
                        "middle": [],
                        "last": "Lin",
                        "suffix": ""
                    },
                    {
                        "first": "Chuan",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "Proceedings of the Twentieth European Conference on Computer Systems",
                "volume": "",
                "issue": "",
                "pages": "1279--1297",
                "other_ids": {},
                "num": 51,
                "urls": [],
                "raw_text": "Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang, Ru Zhang, Yanghua Peng, Haibin Lin, and Chuan Wu. Hybridflow: A flexible and efficient rlhf framework. In Proceedings of the Twentieth European Conference on Computer Systems, pp. 1279\u20131297, 2025.",
                "links": null
            },
            "BIBREF47": {
                "ref_id": "BIBREF47",
                "title": "Reflexion: Language agents with verbal reinforcement learning",
                "authors": [
                    {
                        "first": "Noah",
                        "middle": [],
                        "last": "Shinn",
                        "suffix": ""
                    },
                    {
                        "first": "Federico",
                        "middle": [],
                        "last": "Cassano",
                        "suffix": ""
                    },
                    {
                        "first": "Ashwin",
                        "middle": [],
                        "last": "Gopinath",
                        "suffix": ""
                    },
                    {
                        "first": "Karthik",
                        "middle": [],
                        "last": "Narasimhan",
                        "suffix": ""
                    },
                    {
                        "first": "Shunyu",
                        "middle": [],
                        "last": "Yao",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 52,
                "urls": [],
                "raw_text": "Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion: Language agents with verbal reinforcement learning. NeurIPS, 2023.",
                "links": null
            },
            "BIBREF45": {
                "ref_id": "BIBREF45",
                "title": "Alfworld: Aligning text and embodied environments for interactive learning",
                "authors": [
                    {
                        "first": "Mohit",
                        "middle": [],
                        "last": "Shridhar",
                        "suffix": ""
                    },
                    {
                        "first": "Xingdi",
                        "middle": [],
                        "last": "Yuan",
                        "suffix": ""
                    },
                    {
                        "first": "Marc-Alexandre",
                        "middle": [],
                        "last": "Cote",
                        "suffix": ""
                    },
                    {
                        "first": "Yonatan",
                        "middle": [],
                        "last": "Bisk",
                        "suffix": ""
                    },
                    {
                        "first": "Adam",
                        "middle": [],
                        "last": "Trischler",
                        "suffix": ""
                    },
                    {
                        "first": "Matthew",
                        "middle": [],
                        "last": "Hausknecht",
                        "suffix": ""
                    }
                ],
                "year": 2021,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 53,
                "urls": [],
                "raw_text": "Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Cote, Yonatan Bisk, Adam Trischler, and Matthew Hausknecht. Alfworld: Aligning text and embodied environments for interactive learning. In ICLR, 2021.",
                "links": null
            },
            "BIBREF27": {
                "ref_id": "BIBREF27",
                "title": "3d-gpt: Procedural 3d modeling with large language models",
                "authors": [
                    {
                        "first": "Chunyi",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Junlin",
                        "middle": [],
                        "last": "Han",
                        "suffix": ""
                    },
                    {
                        "first": "Weijian",
                        "middle": [],
                        "last": "Deng",
                        "suffix": ""
                    },
                    {
                        "first": "Xinlong",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Zishan",
                        "middle": [],
                        "last": "Qin",
                        "suffix": ""
                    },
                    {
                        "first": "Stephen",
                        "middle": [],
                        "last": "Gould",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "3",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 54,
                "urls": [],
                "raw_text": "Chunyi Sun, Junlin Han, Weijian Deng, Xinlong Wang, Zishan Qin, and Stephen Gould. 3d-gpt: Procedural 3d modeling with large language models. In 3DV, 2025.",
                "links": null
            },
            "BIBREF16": {
                "ref_id": "BIBREF16",
                "title": "Optimizing language models for inference time objectives using reinforcement learning",
                "authors": [
                    {
                        "first": "Yunhao",
                        "middle": [],
                        "last": "Tang",
                        "suffix": ""
                    },
                    {
                        "first": "Kunhao",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "Gabriel",
                        "middle": [],
                        "last": "Synnaeve",
                        "suffix": ""
                    },
                    {
                        "first": "Remi",
                        "middle": [],
                        "last": "Munos",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 55,
                "urls": [],
                "raw_text": "Yunhao Tang, Kunhao Zheng, Gabriel Synnaeve, and Remi Munos. Optimizing language models for inference time objectives using reinforcement learning. In ICML, 2025.",
                "links": null
            },
            "BIBREF8": {
                "ref_id": "BIBREF8",
                "title": "Atom of thoughts for markov llm test-time scaling",
                "authors": [
                    {
                        "first": "Fengwei",
                        "middle": [],
                        "last": "Teng",
                        "suffix": ""
                    },
                    {
                        "first": "Zhaoyang",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Quan",
                        "middle": [],
                        "last": "Shi",
                        "suffix": ""
                    },
                    {
                        "first": "Jiayi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Chenglin",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Yuyu",
                        "middle": [],
                        "last": "Luo",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2502.12018"
                    ]
                },
                "num": 56,
                "urls": [],
                "raw_text": "Fengwei Teng, Zhaoyang Yu, Quan Shi, Jiayi Zhang, Chenglin Wu, and Yuyu Luo. Atom of thoughts for markov llm test-time scaling. arXiv preprint arXiv:2502.12018, 2025.",
                "links": null
            },
            "BIBREF60": {
                "ref_id": "BIBREF60",
                "title": "Voyager: An open-ended embodied agent with large language models",
                "authors": [
                    {
                        "first": "Guanzhi",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yuqi",
                        "middle": [],
                        "last": "Xie",
                        "suffix": ""
                    },
                    {
                        "first": "Yunfan",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Ajay",
                        "middle": [],
                        "last": "Mandlekar",
                        "suffix": ""
                    },
                    {
                        "first": "Chaowei",
                        "middle": [],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Yuke",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Linxi",
                        "middle": [],
                        "last": "Fan",
                        "suffix": ""
                    },
                    {
                        "first": "Anima",
                        "middle": [],
                        "last": "Anandkumar",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "Transactions on Machine Learning Research",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 57,
                "urls": [],
                "raw_text": "Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. Transactions on Machine Learning Research (TMLR), 2024.",
                "links": null
            },
            "BIBREF13": {
                "ref_id": "BIBREF13",
                "title": "Reinforcement learning for reasoning in large language models with one training example",
                "authors": [
                    {
                        "first": "Yiping",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Qing",
                        "middle": [],
                        "last": "Yang",
                        "suffix": ""
                    },
                    {
                        "first": "Zhiyuan",
                        "middle": [],
                        "last": "Zeng",
                        "suffix": ""
                    },
                    {
                        "first": "Liliang",
                        "middle": [],
                        "last": "Ren",
                        "suffix": ""
                    },
                    {
                        "first": "Liyuan",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Baolin",
                        "middle": [],
                        "last": "Peng",
                        "suffix": ""
                    },
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    },
                    {
                        "first": "Xuehai",
                        "middle": [],
                        "last": "He",
                        "suffix": ""
                    },
                    {
                        "first": "Kuan",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Jianfeng",
                        "middle": [],
                        "last": "Gao",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2504.20571"
                    ]
                },
                "num": 58,
                "urls": [],
                "raw_text": "Yiping Wang, Qing Yang, Zhiyuan Zeng, Liliang Ren, Liyuan Liu, Baolin Peng, Hao Cheng, Xuehai He, Kuan Wang, Jianfeng Gao, et al. Reinforcement learning for reasoning in large language models with one training example. arXiv preprint arXiv:2504.20571, 2025.",
                "links": null
            },
            "BIBREF5": {
                "ref_id": "BIBREF5",
                "title": "Chain of thought prompting elicits reasoning in large language models",
                "authors": [
                    {
                        "first": "Jason",
                        "middle": [],
                        "last": "Wei",
                        "suffix": ""
                    },
                    {
                        "first": "Xuezhi",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Dale",
                        "middle": [],
                        "last": "Schuurmans",
                        "suffix": ""
                    },
                    {
                        "first": "Maarten",
                        "middle": [],
                        "last": "Bosma",
                        "suffix": ""
                    },
                    {
                        "first": "Fei",
                        "middle": [],
                        "last": "Xia",
                        "suffix": ""
                    },
                    {
                        "first": "Ed",
                        "middle": [
                            "H"
                        ],
                        "last": "Chi",
                        "suffix": ""
                    },
                    {
                        "first": "Denny",
                        "middle": [],
                        "last": "Quoc V Le",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Zhou",
                        "suffix": ""
                    }
                ],
                "year": 2022,
                "venue": "NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 59,
                "urls": [],
                "raw_text": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. In NeurIPS, 2022.",
                "links": null
            },
            "BIBREF1": {
                "ref_id": "BIBREF1",
                "title": "Llm-to-phy3d: Physically conform online 3d object generation with llms",
                "authors": [
                    {
                        "first": "Melvin",
                        "middle": [],
                        "last": "Wong",
                        "suffix": ""
                    },
                    {
                        "first": "Yueming",
                        "middle": [],
                        "last": "Lyu",
                        "suffix": ""
                    },
                    {
                        "first": "Thiago",
                        "middle": [],
                        "last": "Rios",
                        "suffix": ""
                    },
                    {
                        "first": "Stefan",
                        "middle": [],
                        "last": "Menzel",
                        "suffix": ""
                    },
                    {
                        "first": "Yew-Soon",
                        "middle": [],
                        "last": "Ong",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2506.11148"
                    ]
                },
                "num": 60,
                "urls": [],
                "raw_text": "Melvin Wong, Yueming Lyu, Thiago Rios, Stefan Menzel, and Yew-Soon Ong. Llm-to-phy3d: Physically conform online 3d object generation with llms. arXiv preprint arXiv:2506.11148, 2025.",
                "links": null
            },
            "BIBREF33": {
                "ref_id": "BIBREF33",
                "title": "Cad-llm: Large language model for cad generation",
                "authors": [
                    {
                        "first": "Sifan",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    },
                    {
                        "first": "Amir",
                        "middle": [],
                        "last": "Khasahmadi",
                        "suffix": ""
                    },
                    {
                        "first": "Mor",
                        "middle": [],
                        "last": "Katz",
                        "suffix": ""
                    },
                    {
                        "first": "Pradeep",
                        "middle": [],
                        "last": "Kumar Jayaraman",
                        "suffix": ""
                    },
                    {
                        "first": "Yewen",
                        "middle": [],
                        "last": "Pu",
                        "suffix": ""
                    },
                    {
                        "first": "Karl",
                        "middle": [],
                        "last": "Willis",
                        "suffix": ""
                    },
                    {
                        "first": "Bang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 61,
                "urls": [],
                "raw_text": "Sifan Wu, Amir Khasahmadi, Mor Katz, Pradeep Kumar Jayaraman, Yewen Pu, Karl Willis, and Bang Liu. Cad-llm: Large language model for cad generation. In NeurIPS, 2023.",
                "links": null
            },
            "BIBREF7": {
                "ref_id": "BIBREF7",
                "title": "Verbalized machine learning: Revisiting machine learning with language models",
                "authors": [
                    {
                        "first": "Robert",
                        "middle": [],
                        "last": "Tim Z Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Bernhard",
                        "middle": [],
                        "last": "Bamler",
                        "suffix": ""
                    },
                    {
                        "first": "Weiyang",
                        "middle": [],
                        "last": "Sch\u00f6lkopf",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "Transactions on Machine Learning Research",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 62,
                "urls": [],
                "raw_text": "Tim Z Xiao, Robert Bamler, Bernhard Sch\u00f6lkopf, and Weiyang Liu. Verbalized machine learning: Revisiting machine learning with language models. Transactions on Machine Learning Research, 2025.",
                "links": null
            },
            "BIBREF51": {
                "ref_id": "BIBREF51",
                "title": "Tree of thoughts: Deliberate problem solving with large language models",
                "authors": [
                    {
                        "first": "Shunyu",
                        "middle": [],
                        "last": "Yao",
                        "suffix": ""
                    },
                    {
                        "first": "Dian",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Izhak",
                        "middle": [],
                        "last": "Shafran",
                        "suffix": ""
                    },
                    {
                        "first": "Tom",
                        "middle": [],
                        "last": "Griffiths",
                        "suffix": ""
                    },
                    {
                        "first": "Yuan",
                        "middle": [],
                        "last": "Cao",
                        "suffix": ""
                    },
                    {
                        "first": "Karthik",
                        "middle": [],
                        "last": "Narasimhan",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "NeurIPS",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 63,
                "urls": [],
                "raw_text": "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. NeurIPS, 2023a.",
                "links": null
            },
            "BIBREF37": {
                "ref_id": "BIBREF37",
                "title": "React: Synergizing reasoning and acting in language models",
                "authors": [
                    {
                        "first": "Shunyu",
                        "middle": [],
                        "last": "Yao",
                        "suffix": ""
                    },
                    {
                        "first": "Jeffrey",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Dian",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Nan",
                        "middle": [],
                        "last": "Du",
                        "suffix": ""
                    },
                    {
                        "first": "Izhak",
                        "middle": [],
                        "last": "Shafran",
                        "suffix": ""
                    },
                    {
                        "first": "Karthik",
                        "middle": [],
                        "last": "Narasimhan",
                        "suffix": ""
                    },
                    {
                        "first": "Yuan",
                        "middle": [],
                        "last": "Cao",
                        "suffix": ""
                    }
                ],
                "year": 2023,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 64,
                "urls": [],
                "raw_text": "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. In ICLR, 2023b.",
                "links": null
            },
            "BIBREF48": {
                "ref_id": "BIBREF48",
                "title": "Generating symbolic world models via test-time scaling of large language models",
                "authors": [
                    {
                        "first": "Zhouliang",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Yuhuan",
                        "middle": [],
                        "last": "Yuan",
                        "suffix": ""
                    },
                    {
                        "first": "Tim",
                        "middle": [
                            "Z"
                        ],
                        "last": "Xiao",
                        "suffix": ""
                    },
                    {
                        "first": "Fuxiang",
                        "middle": [],
                        "last": "Frank Xia",
                        "suffix": ""
                    },
                    {
                        "first": "Jie",
                        "middle": [],
                        "last": "Fu",
                        "suffix": ""
                    },
                    {
                        "first": "Ge",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Weiyang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "Transactions on Machine Learning Research",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 65,
                "urls": [],
                "raw_text": "Zhouliang Yu, Yuhuan Yuan, Tim Z Xiao, Fuxiang Frank Xia, Jie Fu, Ge Zhang, Weiyang Liu, et al. Generating symbolic world models via test-time scaling of large language models. Transactions on Machine Learning Research, 2025.",
                "links": null
            },
            "BIBREF30": {
                "ref_id": "BIBREF30",
                "title": "Cadtalk: An algorithm and benchmark for semantic commenting of cad programs",
                "authors": [
                    {
                        "first": "Haocheng",
                        "middle": [],
                        "last": "Yuan",
                        "suffix": ""
                    },
                    {
                        "first": "Jing",
                        "middle": [],
                        "last": "Xu",
                        "suffix": ""
                    },
                    {
                        "first": "Hao",
                        "middle": [],
                        "last": "Pan",
                        "suffix": ""
                    },
                    {
                        "first": "Adrien",
                        "middle": [],
                        "last": "Bousseau",
                        "suffix": ""
                    },
                    {
                        "first": "J",
                        "middle": [],
                        "last": "Niloy",
                        "suffix": ""
                    },
                    {
                        "first": "Changjian",
                        "middle": [],
                        "last": "Mitra",
                        "suffix": ""
                    },
                    {
                        "first": "",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    }
                ],
                "year": 2024,
                "venue": "CVPR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 66,
                "urls": [],
                "raw_text": "Haocheng Yuan, Jing Xu, Hao Pan, Adrien Bousseau, Niloy J Mitra, and Changjian Li. Cadtalk: An algorithm and benchmark for semantic commenting of cad programs. In CVPR, 2024.",
                "links": null
            },
            "BIBREF11": {
                "ref_id": "BIBREF11",
                "title": "Does reinforcement learning really incentivize reasoning capacity in LLMs beyond the base model?",
                "authors": [
                    {
                        "first": "Yang",
                        "middle": [],
                        "last": "Yue",
                        "suffix": ""
                    },
                    {
                        "first": "Zhiqi",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Rui",
                        "middle": [],
                        "last": "Lu",
                        "suffix": ""
                    },
                    {
                        "first": "Andrew",
                        "middle": [],
                        "last": "Zhao",
                        "suffix": ""
                    },
                    {
                        "first": "Zhaokai",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Yang",
                        "middle": [],
                        "last": "Yue",
                        "suffix": ""
                    },
                    {
                        "first": "Shiji",
                        "middle": [],
                        "last": "Song",
                        "suffix": ""
                    },
                    {
                        "first": "Gao",
                        "middle": [],
                        "last": "Huang",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "ICML",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 67,
                "urls": [],
                "raw_text": "Yang Yue, Zhiqi Chen, Rui Lu, Andrew Zhao, Zhaokai Wang, Yang Yue, Shiji Song, and Gao Huang. Does reinforcement learning really incentivize reasoning capacity in LLMs beyond the base model? In ICML, 2025.",
                "links": null
            },
            "BIBREF9": {
                "ref_id": "BIBREF9",
                "title": "AFlow: Automating agentic workflow generation",
                "authors": [
                    {
                        "first": "Jiayi",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Jinyu",
                        "middle": [],
                        "last": "Xiang",
                        "suffix": ""
                    },
                    {
                        "first": "Zhaoyang",
                        "middle": [],
                        "last": "Yu",
                        "suffix": ""
                    },
                    {
                        "first": "Fengwei",
                        "middle": [],
                        "last": "Teng",
                        "suffix": ""
                    },
                    {
                        "first": "Xiong-Hui",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Jiaqi",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Mingchen",
                        "middle": [],
                        "last": "Zhuge",
                        "suffix": ""
                    },
                    {
                        "first": "Xin",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    },
                    {
                        "first": "Sirui",
                        "middle": [],
                        "last": "Hong",
                        "suffix": ""
                    },
                    {
                        "first": "Jinlin",
                        "middle": [],
                        "last": "Wang",
                        "suffix": ""
                    },
                    {
                        "first": "Bingnan",
                        "middle": [],
                        "last": "Zheng",
                        "suffix": ""
                    },
                    {
                        "first": "Bang",
                        "middle": [],
                        "last": "Liu",
                        "suffix": ""
                    },
                    {
                        "first": "Yuyu",
                        "middle": [],
                        "last": "Luo",
                        "suffix": ""
                    },
                    {
                        "first": "Chenglin",
                        "middle": [],
                        "last": "Wu",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "ICLR",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {},
                "num": 68,
                "urls": [],
                "raw_text": "Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xiong-Hui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng, Sirui Hong, Jinlin Wang, Bingnan Zheng, Bang Liu, Yuyu Luo, and Chenglin Wu. AFlow: Automating agentic workflow generation. In ICLR, 2025.",
                "links": null
            },
            "BIBREF12": {
                "ref_id": "BIBREF12",
                "title": "The surprising effectiveness of negative reinforcement in llm reasoning",
                "authors": [
                    {
                        "first": "Xinyu",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Mengzhou",
                        "middle": [],
                        "last": "Xia",
                        "suffix": ""
                    },
                    {
                        "first": "Zhepei",
                        "middle": [],
                        "last": "Wei",
                        "suffix": ""
                    },
                    {
                        "first": "Wei-Lin",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Danqi",
                        "middle": [],
                        "last": "Chen",
                        "suffix": ""
                    },
                    {
                        "first": "Yu",
                        "middle": [],
                        "last": "Meng",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2506.01347"
                    ]
                },
                "num": 69,
                "urls": [],
                "raw_text": "Xinyu Zhu, Mengzhou Xia, Zhepei Wei, Wei-Lin Chen, Danqi Chen, and Yu Meng. The surprising effectiveness of negative reinforcement in llm reasoning. arXiv preprint arXiv:2506.01347, 2025a.",
                "links": null
            },
            "BIBREF20": {
                "ref_id": "BIBREF20",
                "title": "Flowrl: Matching reward distributions for llm reasoning",
                "authors": [
                    {
                        "first": "Xuekai",
                        "middle": [],
                        "last": "Zhu",
                        "suffix": ""
                    },
                    {
                        "first": "Daixuan",
                        "middle": [],
                        "last": "Cheng",
                        "suffix": ""
                    },
                    {
                        "first": "Dinghuai",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Hengli",
                        "middle": [],
                        "last": "Li",
                        "suffix": ""
                    },
                    {
                        "first": "Kaiyan",
                        "middle": [],
                        "last": "Zhang",
                        "suffix": ""
                    },
                    {
                        "first": "Che",
                        "middle": [],
                        "last": "Jiang",
                        "suffix": ""
                    },
                    {
                        "first": "Youbang",
                        "middle": [],
                        "last": "Sun",
                        "suffix": ""
                    },
                    {
                        "first": "Ermo",
                        "middle": [],
                        "last": "Hua",
                        "suffix": ""
                    },
                    {
                        "first": "Yuxin",
                        "middle": [],
                        "last": "Zuo",
                        "suffix": ""
                    },
                    {
                        "first": "Xingtai",
                        "middle": [],
                        "last": "Lv",
                        "suffix": ""
                    }
                ],
                "year": 2025,
                "venue": "",
                "volume": "",
                "issue": "",
                "pages": "",
                "other_ids": {
                    "arXiv": [
                        "arXiv:2509.15207"
                    ]
                },
                "num": 70,
                "urls": [],
                "raw_text": "Xuekai Zhu, Daixuan Cheng, Dinghuai Zhang, Hengli Li, Kaiyan Zhang, Che Jiang, Youbang Sun, Ermo Hua, Yuxin Zuo, Xingtai Lv, et al. Flowrl: Matching reward distributions for llm reasoning. arXiv preprint arXiv:2509.15207, 2025b.",
                "links": null
            }
        },
        "ref_entries": {
            "FIGREF1": {
                "type_str": "figure",
                "num": "1",
                "fig_num": null,
                "text": "The task of compositional machine design is illustrated in our BesiegeField environment. The figure shows a high-level sketch of the agentic workflow (w/ Gemini Pro 2.5), along with the resulting machines and their simulated performance. The design objective is to create a machine that throws boulders long distances.",
                "uris": [
                    "figures/teaser_final_new.pdf"
                ]
            },
            "FIGREF8": {
                "type_str": "figure",
                "num": "2",
                "fig_num": null,
                "text": "Demonstration of the machine design tasks in our experiments. (Left: car; Right: catapult).",
                "uris": [
                    "figures/environment_intro_cropped.pdf"
                ]
            },
            "FIGREF9": {
                "type_str": "figure",
                "num": "3",
                "fig_num": null,
                "text": "Demonstration of the default XML representation and our construction tree representation. Parent block info is in blue and child info is in red.",
                "uris": [
                    "figures/xml_intro_v2_cropped.pdf"
                ]
            },
            "FIGREF10": {
                "type_str": "figure",
                "num": "4",
                "fig_num": null,
                "text": "Example CoT of inspector agents (w/ Gemini 2.5 Pro). Blue text highlights the moderate capability of LLMs in spatial reasoning and imagined physical simulation.",
                "uris": [
                    "figures/gemini_cot_example_v3.pdf"
                ]
            },
            "FIGREF11": {
                "type_str": "figure",
                "num": "5",
                "fig_num": null,
                "text": "Example CoT of inspector agents (w/ OpenAI o3). Red text highlights reasoning errors.",
                "uris": [
                    "figures/o3_cot_example_v4_green_cropped.pdf"
                ]
            },
            "FIGREF14": {
                "type_str": "figure",
                "num": "7",
                "fig_num": null,
                "text": "Machines produced by agentic systems with different LLMs (Top: car; Bottom: catapult).",
                "uris": [
                    "figures/LLM_Comp_v4_cropped.pdf"
                ]
            },
            "FIGREF28": {
                "type_str": "figure",
                "num": "9",
                "fig_num": null,
                "text": "Besiege editor view.",
                "uris": [
                    "figures/game_editor_view.png"
                ]
            },
            "FIGREF29": {
                "type_str": "figure",
                "num": "10",
                "fig_num": null,
                "text": "Common useful blocks in constructing standard machines in BesiegeField.",
                "uris": [
                    "figures/block_stats.png"
                ]
            },
            "FIGREF67": {
                "type_str": "figure",
                "num": "11",
                "fig_num": null,
                "text": "Illustration of the task car / movement on a rocky terrain, a more difficult setting compared to the environment used for the car task in our experiments.",
                "uris": [
                    "figures/tasks/movement_rocky.png"
                ]
            },
            "FIGREF68": {
                "type_str": "figure",
                "num": "12",
                "fig_num": null,
                "text": "Illustration of the task catapult / throw.",
                "uris": [
                    "figures/tasks/throw.png"
                ]
            },
            "FIGREF69": {
                "type_str": "figure",
                "num": "13",
                "fig_num": null,
                "text": "Illustration of the task pick.",
                "uris": [
                    "figures/tasks/pick.png"
                ]
            },
            "FIGREF70": {
                "type_str": "figure",
                "num": "14",
                "fig_num": null,
                "text": "Illustration of the task delivery with a bump on the track.",
                "uris": [
                    "figures/tasks/delivery.png"
                ]
            },
            "FIGREF71": {
                "type_str": "figure",
                "num": "15",
                "fig_num": null,
                "text": "Illustration of the task catapult / Throw with the objective of throwing the boulder through the target ring.",
                "uris": [
                    "figures/tasks/thru_ring.png"
                ]
            },
            "FIGREF72": {
                "type_str": "figure",
                "num": "16",
                "fig_num": null,
                "text": "Illustration of the task car / movement with a curved track.",
                "uris": [
                    "figures/tasks/curved_track.png"
                ]
            },
            "FIGREF75": {
                "type_str": "figure",
                "num": "17",
                "fig_num": null,
                "text": "The variation in machine average scores with the increasing number of LLM node expansion operations under different search strategies.",
                "uris": [
                    "figures/RL_Metrics/search_strategy.png"
                ]
            },
            "FIGREF89": {
                "type_str": "figure",
                "num": "18",
                "fig_num": null,
                "text": "Examples to illustrate failure patterns. In each example, the original machine is shown on the left and the modified machine on the right. Failure patterns are sampled from Qwen3-Coder-480B-A35B-Instruct.",
                "uris": [
                    "figures/failure_mode_v3_cropped.pdf"
                ]
            },
            "FIGREF91": {
                "type_str": "figure",
                "num": "19",
                "fig_num": null,
                "text": "Illustration of how machines built with feasible high-level designs may fail due to inaccurate part placement. Machine sampled from Gemini 2.5 Pro. Left: designed machines; Right: simulation results.",
                "uris": [
                    "figures/tiny_modify_v3_cropped.pdf"
                ]
            },
            "FIGREF93": {
                "type_str": "figure",
                "num": "20",
                "fig_num": null,
                "text": "Boulder-throwing trajectories for various machine designs generated by Gemini 2.5 Pro. From left to right, each row first shows the machine design, followed by a time-lapsed bird\u2019s-eye view of its throw.",
                "uris": [
                    "figures/throw_comp_v4_cropped.pdf"
                ]
            },
            "FIGREF95": {
                "type_str": "figure",
                "num": "21",
                "fig_num": null,
                "text": "Examples of Gemini-synthesized machines.",
                "uris": [
                    "figures/synthesised_dataset_v3_cropped.pdf"
                ]
            },
            "FIGREF99": {
                "type_str": "figure",
                "num": "22",
                "fig_num": null,
                "text": "Construction guidance comparison of Meta Designer and Detailed Meta Designer, sampled with Gemini 2.5 Pro.",
                "uris": [
                    "figures/designer_detailed_designer_cropped.pdf"
                ]
            },
            "FIGREF102": {
                "type_str": "figure",
                "num": "23",
                "fig_num": null,
                "text": "Catapult task machine scores across RL steps. KL regularization helps the model discover better structure designs. Pass@64 is greatly more efficient at uncovering powerful machine designs. Pass@8 (roll-out 8) outperforms Pass@1 (roll-out 64) in efficiency and matches its performance with fewer roll-outs. No cold start models lack the advanced knowledge needed to find better machines.",
                "uris": [
                    "figures/RL_Metrics/Catapult/score_max.png"
                ]
            },
            "FIGREF103": {
                "type_str": "figure",
                "num": "24",
                "fig_num": null,
                "text": "Car machine scores across RL steps. The RL finetuning hyperparameter setting is the same as the base hyperparameter setting of Catapult. Machine performance slightly rises as training steps increase.",
                "uris": [
                    "figures/RL_Metrics/Car/score_max.png"
                ]
            },
            "FIGREF104": {
                "type_str": "figure",
                "num": "25",
                "fig_num": null,
                "text": "Catapult task machine validity rate and reward non-zero rate across RL steps. The machine validity rate refers to the proportion of machines that can successfully run simulations. The reward non-zero rate represents the ratio of machines that can simulate with a non-zero reward. LLM constructs more legal machines as training steps increase, and rewards non-zero machines. Pass@8 and Pass@1 converge early. \u201cNo KL\u201d fills roll-outs with failure cases, slowing performance gains. \u201cNo cold start\u201d lacks design knowledge, encounters more failures than no KL, and improves validity rate most slowly. The base setting balances convergence and performance improvement.",
                "uris": [
                    "figures/RL_Metrics/Catapult/MachineValid_Reward.png"
                ]
            },
            "FIGREF105": {
                "type_str": "figure",
                "num": "26",
                "fig_num": null,
                "text": "Car task machine validity rate and reward non-zero rate across RL steps. The machine validity converges early and remains stable during further training.",
                "uris": [
                    "figures/RL_Metrics/Car/MachineValid_Reward.png"
                ]
            },
            "FIGREF106": {
                "type_str": "figure",
                "num": "27",
                "fig_num": null,
                "text": "Catapult task. Average Best@N metric. At each test step, the LLM generates 64 samples, selects the top N samples, and records the maximum score. This process is repeated 1,000 times, and the mean value is calculated. Base settings (both seeds) dominates Best@N performance; excluding base settings, \u201cno KL\u201d dominates the rest. Pass@1 and Pass@8 spawn only a handful of high-performance machines. No cold start produces machines of more average quality.",
                "uris": [
                    "figures/RL_Metrics/Catapult/Val_Best.png"
                ]
            },
            "FIGREF107": {
                "type_str": "figure",
                "num": "28",
                "fig_num": null,
                "text": "Car task. Mean Best@N metrics. Similar to the machine validity rate, the Best@N performance increases quickly and remains stable in rest training periods.",
                "uris": [
                    "figures/RL_Metrics/Car/Val_Best.png"
                ]
            },
            "FIGREF109": {
                "type_str": "figure",
                "num": "29",
                "fig_num": null,
                "text": "Qwen2.5-14B-Instruct cold started RL model catapult task sample from roll-out. Throwing distances are labeled on the bottom-right corner of the image.",
                "uris": [
                    "figures/RL_sample_new_v2.pdf"
                ]
            },
            "FIGREF111": {
                "type_str": "figure",
                "num": "30",
                "fig_num": null,
                "text": "The LLM inference gallery of machine-generated samples. The rows, from top to bottom, were inferred by the following models, respectively: Claude 4 Opus, Gemini 2.5 Pro, o3, Doubao Seed 1.6, and Qwen3-Coder-480B-A35B-Instruct. Throwing distances are labeled on the bottom-right corner of the image.",
                "uris": [
                    "figures/test_time_scaling_gallery_withcaption.pdf"
                ]
            },
            "FIGREF112": {
                "type_str": "figure",
                "num": "31",
                "fig_num": null,
                "text": "Comparison between generated machines conditioned on their own CoT or Gemini-generated CoT.",
                "uris": [
                    "figures/LLM_feed_gemini_cot_v4_cropped.pdf"
                ]
            },
            "FIGREF13": {
                "type_str": "figure",
                "num": "6",
                "fig_num": null,
                "text": "Our agentic machine design workflow.",
                "uris": [
                    "figures/besiegefield_pipeline_compressed.pdf"
                ]
            },
            "FIGREF20": {
                "type_str": "figure",
                "num": "8",
                "fig_num": null,
                "text": "Designs at RL finetuning stages. font=footnotesize",
                "uris": [
                    "figures/14b_model_sample_v4_cropped.pdf"
                ]
            },
            "TABREF15": {
                "content": [],
                "type_str": "table",
                "num": "1",
                "html": "",
                "text": "Quantitative results of agentic systems with different LLMs."
            },
            "TABREF18": {
                "content": [],
                "type_str": "table",
                "num": "2",
                "html": "",
                "text": "Results of RLVR post-training in BesiegeField. We use Qwen2.5-14B as the backbond LLM."
            },
            "TABREF21": {
                "content": [],
                "type_str": "table",
                "num": "3",
                "html": "",
                "text": "Comparison between the performance of machines generated by different stages. The mean score is computed by taking the average of the scores of all valid machines. We sample 8 machines at the designer stage and keep only the valid machines. The maximum number of retries in the following stages is thus equal to the number of valid machines produced at the designer stage."
            },
            "TABREF22": {
                "content": [],
                "type_str": "table",
                "num": "4",
                "html": "",
                "text": "Performance of machines generated after different stages of the iterative editing workflow (without meta-designer). Mean scores are computed on valid machines."
            },
            "TABREF23": {
                "content": [],
                "type_str": "table",
                "num": "5",
                "html": "",
                "text": "Ablation on the effect of parsed 3D information. We compute the blind refinement score under two machine representations. The average score is computed with respect to valid machines only; 8 tries for each experiment."
            },
            "TABREF24": {
                "content": [],
                "type_str": "table",
                "num": "6",
                "html": "",
                "text": "Ablation of edit history as refiner inputs."
            },
            "TABREF25": {
                "content": [],
                "type_str": "table",
                "num": "7",
                "html": "",
                "text": "Ablation study on machine representations."
            },
            "TABREF73": {
                "content": [],
                "type_str": "table",
                "num": "8",
                "html": "",
                "text": "Ablation study on different search strategies. We compare the agentic workflow final scores. MCTS is executed for 5 rounds, with Random Search and Best-of-N also run for the same number of rounds. Avg.I denotes the average number of node expansions per search round."
            },
            "TABREF74": {
                "content": [],
                "type_str": "table",
                "num": "9",
                "html": "",
                "text": "Ablation study on the effect of search depth in MCTS. R2, R5, and R10 represent the running rounds of MCTS on the same search tree."
            },
            "TABREF98": {
                "content": [],
                "type_str": "table",
                "num": "10",
                "html": "",
                "text": "Ablation study on the meta-designer. Machine validity is evaluated in two aspects: file validity, 3D validity. Note that 3D validity requires the machine to first pass file validity. Final validity refers to a fully valid machine (satisfying both file and 3D validity). The mean simulation score is calculated based solely on the final valid outputs. Detailed Meta-Designer provides more concisely, step-by-step construction guidance to the Designer. Compared to Baseline, Single Agent is slightly harder to construct valid machines, but the simulation scores are better. Detailed Meta-Designer improves both metrics, but requires LLMs to have a strong 3D understanding and a large context window. The comparison between Meta-Designer and Detailed Meta-Designer is illustrated in Fig. FIGREF99 ."
            },
            "TABREF100": {
                "content": [],
                "type_str": "table",
                "num": "11",
                "html": "",
                "text": "Ablation study on inspector agentic design. The mean simulation score is calculated based solely on the valid machines after blind refinement. Removing the inspector from the agentic flow lowers the blind refiner\u2019s mean performance on LLMs with weaker 3D understanding, while barely affecting other models."
            },
            "TABREF101": {
                "content": [],
                "type_str": "table",
                "num": "12",
                "html": "",
                "text": "Ablation study on the environment querier agent. For the refiner, the baseline includes simulation scores, basic environment feedback, and querier-required feedback. The \"w/o env querier\" setting provides only simulation scores and basic environment feedback. In the \"pure score only\" setting, only simulation scores are provided. Removing the environment querier causes a slight drop in average machine performance. With reward signals only, the performance markedly degrades across most LLMs."
            },
            "FOOTREF2": {
                "type_str": "footnote",
                "num": "1",
                "text": "https://en.wikipedia.org/wiki/Besiege_(video_game)"
            },
            "FOOTREF26": {
                "type_str": "footnote",
                "num": "2",
                "text": "https://en.wikipedia.org/wiki/Unity_(game_engine)"
            },
            "FOOTREF27": {
                "type_str": "footnote",
                "num": "3",
                "text": "https://en.wikipedia.org/wiki/Video_game_modding"
            },
            "SECREF1": {
                "type_str": "section",
                "num": "1",
                "text": "Introduction",
                "parent": null
            },
            "SECREF2": {
                "type_str": "section",
                "num": "2",
                "text": "Compositional Machine Design",
                "parent": null
            },
            "SECREF3": {
                "type_str": "section",
                "num": "3",
                "text": "BesiegeField : Playground for Compositional Machine Design",
                "parent": null
            },
            "SECREF4": {
                "type_str": "section",
                "num": "4",
                "text": "",
                "parent": null
            },
            "SECREFU7": {
                "type_str": "section",
                "num": "4.1",
                "text": "Benchmark Settings",
                "parent": "SECREF4"
            },
            "SECREFU12": {
                "type_str": "section",
                "num": "4.2",
                "text": "Agentic Workflow Design",
                "parent": "SECREF4"
            },
            "SECREFU16": {
                "type_str": "section",
                "num": "4.3",
                "text": "Key Empirical Observations",
                "parent": "SECREF4"
            },
            "SECREF5": {
                "type_str": "section",
                "num": "5",
                "text": "",
                "parent": null
            },
            "SECREFU17": {
                "type_str": "section",
                "num": "5.1",
                "text": "Experimental Settings",
                "parent": "SECREF5"
            },
            "SECREFU19": {
                "type_str": "section",
                "num": "5.2",
                "text": "Main Results and Observations",
                "parent": "SECREF5"
            },
            "SECREF6": {
                "type_str": "section",
                "num": "6",
                "text": "Discussions and Intriguing Insights",
                "parent": null
            },
            "SECREF7": {
                "type_str": "section",
                "num": "7",
                "text": "Related Work and Concluding Remarks",
                "parent": null
            },
            "SECREF1007": {
                "type_str": "section",
                "num": null,
                "text": "Acknowledgment",
                "parent": null
            },
            "SECREF8": {
                "type_str": "section",
                "num": "",
                "text": "Appendix",
                "parent": null
            },
            "SECREF9": {
                "type_str": "section",
                "num": "A",
                "text": "Supplementary Tables",
                "parent": null
            },
            "SECREF10": {
                "type_str": "section",
                "num": "B",
                "text": "Details on the BesiegeField Environment",
                "parent": null
            },
            "SECREFU30": {
                "type_str": "section",
                "num": "B.1",
                "text": "Construction Rule",
                "parent": "SECREF10"
            },
            "SECREFU31": {
                "type_str": "section",
                "num": "B.2",
                "text": "Simulation",
                "parent": "SECREF10"
            },
            "SECREFU32": {
                "type_str": "section",
                "num": "B.3",
                "text": "Blocks",
                "parent": "SECREF10"
            },
            "SECREFU60": {
                "type_str": "section",
                "num": "B.4",
                "text": "Tasks",
                "parent": "SECREF10"
            },
            "SECREF11": {
                "type_str": "section",
                "num": "C",
                "text": "Search Strategies in Machine Modification Loops",
                "parent": null
            },
            "SECREF12": {
                "type_str": "section",
                "num": "D",
                "text": "",
                "parent": null
            },
            "SECREFU76": {
                "type_str": "section",
                "num": "D.1",
                "text": "Machine Representation",
                "parent": "SECREF12"
            },
            "SECREFU77": {
                "type_str": "section",
                "num": "D.2",
                "text": "Global Position-based Representation",
                "parent": "SECREF12"
            },
            "SECREFU78": {
                "type_str": "section",
                "num": "D.3",
                "text": "Construction Tree Representation",
                "parent": "SECREF12"
            },
            "SECREFU79": {
                "type_str": "section",
                "num": "D.4",
                "text": "Reward Setting",
                "parent": "SECREF12"
            },
            "SECREFU80": {
                "type_str": "section",
                "num": "D.5",
                "text": "Environment Feedback",
                "parent": "SECREF12"
            },
            "SECREF13": {
                "type_str": "section",
                "num": "E",
                "text": "Challenges in Compositional Machine Design",
                "parent": null
            },
            "SECREFU88": {
                "type_str": "section",
                "num": "E.1",
                "text": "Failure Patterns",
                "parent": "SECREF13"
            },
            "SECREFU90": {
                "type_str": "section",
                "num": "E.2",
                "text": "Need for Precision",
                "parent": "SECREF13"
            },
            "SECREFU92": {
                "type_str": "section",
                "num": "E.3",
                "text": "Appearance vs.\u00a0Performance",
                "parent": "SECREF13"
            },
            "SECREF14": {
                "type_str": "section",
                "num": "F",
                "text": "Settings for RL Finetuning",
                "parent": null
            },
            "SECREFU94": {
                "type_str": "section",
                "num": "F.1",
                "text": "Cold-Start Dataset Curation",
                "parent": "SECREF14"
            },
            "SECREFU96": {
                "type_str": "section",
                "num": "F.2",
                "text": "Cold-Start Details",
                "parent": "SECREF14"
            },
            "SECREFU97": {
                "type_str": "section",
                "num": "F.3",
                "text": "RL Experiment Details",
                "parent": "SECREF14"
            },
            "SECREF15": {
                "type_str": "section",
                "num": "G",
                "text": "Additional Ablation Studies",
                "parent": null
            },
            "SECREF16": {
                "type_str": "section",
                "num": "H",
                "text": "Generated Samples",
                "parent": null
            },
            "SECREFU108": {
                "type_str": "section",
                "num": "H.1",
                "text": "From RL-finetuned Models",
                "parent": "SECREF16"
            },
            "SECREFU110": {
                "type_str": "section",
                "num": "H.2",
                "text": "From Agentic Workflow",
                "parent": "SECREF16"
            },
            "SECREF17": {
                "type_str": "section",
                "num": "I",
                "text": "Relations between CoT and Machines",
                "parent": null
            },
            "SECREF18": {
                "type_str": "section",
                "num": "J",
                "text": "CoT Samples from Gemini 2.5 Pro",
                "parent": null
            },
            "SECREFU113": {
                "type_str": "section",
                "num": "J.1",
                "text": "Single Agent",
                "parent": "SECREF18"
            },
            "SECREFU114": {
                "type_str": "section",
                "num": "J.2",
                "text": "Meta Designer",
                "parent": "SECREF18"
            },
            "SECREFU115": {
                "type_str": "section",
                "num": "J.3",
                "text": "Designer",
                "parent": "SECREF18"
            },
            "SECREFU116": {
                "type_str": "section",
                "num": "J.4",
                "text": "Inspector",
                "parent": "SECREF18"
            },
            "SECREFU117": {
                "type_str": "section",
                "num": "J.5",
                "text": "Environment Querier",
                "parent": "SECREF18"
            },
            "SECREFU118": {
                "type_str": "section",
                "num": "J.6",
                "text": "Refiner",
                "parent": "SECREF18"
            },
            "SECREF19": {
                "type_str": "section",
                "num": "K",
                "text": "Single-Agent Prompt",
                "parent": null
            },
            "SECREF20": {
                "type_str": "section",
                "num": "L",
                "text": "Multi-Agent Prompts",
                "parent": null
            },
            "SECREFU119": {
                "type_str": "section",
                "num": "L.1",
                "text": "Shared Prompts",
                "parent": "SECREF20"
            },
            "SECREFU120": {
                "type_str": "section",
                "num": "L.1.1",
                "text": "Game Introduction With 3D Knowledge",
                "parent": "SECREFU119"
            },
            "SECREFU121": {
                "type_str": "section",
                "num": "L.1.2",
                "text": "Machine 3D JSON Format",
                "parent": "SECREFU119"
            },
            "SECREFU122": {
                "type_str": "section",
                "num": "L.1.3",
                "text": "Build Guidance",
                "parent": "SECREFU119"
            },
            "SECREFU123": {
                "type_str": "section",
                "num": "L.1.4",
                "text": "Meta Designer System Prompt",
                "parent": "SECREFU119"
            },
            "SECREFU124": {
                "type_str": "section",
                "num": "L.2",
                "text": "Designer System And User Prompt",
                "parent": "SECREF20"
            },
            "SECREFU125": {
                "type_str": "section",
                "num": "L.3",
                "text": "Inspector System And User Prompt",
                "parent": "SECREF20"
            },
            "SECREFU126": {
                "type_str": "section",
                "num": "L.4",
                "text": "Refiner System Prompt",
                "parent": "SECREF20"
            },
            "SECREFU127": {
                "type_str": "section",
                "num": "L.5",
                "text": "Environment Querier System Prompt",
                "parent": "SECREF20"
            },
            "SECREFU128": {
                "type_str": "section",
                "num": "L.6",
                "text": "Block Informations",
                "parent": "SECREF20"
            }
        }
    }
}