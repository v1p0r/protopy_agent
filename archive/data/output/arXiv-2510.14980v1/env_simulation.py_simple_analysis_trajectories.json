[{"role": "system", "content": "You are an expert researcher, strategic analyzer and software engineer with a deep understanding of experimental design and reproducibility in scientific research.\nYou will receive a research paper, an overview of the plan, a design in JSON format consisting of \"Implementation approach\", \"File list\", \"Data structures and interfaces\", and \"Program call flow\", followed by a task in JSON format that includes \"Required packages\", \"Required other language third-party packages\", \"Logic Analysis\", and \"Task list\", along with a configuration file named \"config.yaml\". \n\nYour task is to conduct a comprehensive logic analysis to accurately reproduce the experiments and methodologies described in the research paper. \nThis analysis must align precisely with the paper\u2019s methodology, experimental setup, and evaluation criteria.\n\n1. Align with the Paper: Your analysis must strictly follow the methods, datasets, model configurations, hyperparameters, and experimental setups described in the paper.\n2. Be Clear and Structured: Present your analysis in a logical, well-organized, and actionable format that is easy to follow and implement.\n3. Prioritize Efficiency: Optimize the analysis for clarity and practical implementation while ensuring fidelity to the original experiments.\n4. Follow design: YOU MUST FOLLOW \"Data structures and interfaces\". DONT CHANGE ANY DESIGN. Do not use public member functions that do not exist in your design.\n5. REFER TO CONFIGURATION: Always reference settings from the config.yaml file. Do not invent or assume any values\u2014only use configurations explicitly provided.\n     \n"}, {"role": "user", "content": "## Paper\n{'abstract': '\\nAgentic Design of Compositional Machines\\n', 'Introduction': 'The history of human progress is, at its core, the history of machines, just as the ancient Greeks built the Antikythera mechanism to predict eclipses and Leonardo da Vinci envisioned machines to fly. Today, as large language models (LLMs) begin to approximate\u2014and in some domains, surpass\u2014human cognitive abilities, a natural question arises:  [leftmargin=1em, rightmargin=1em] Can computational models, like humans, conceive and create complex machines to achieve purposeful goals?    At the heart of this question lie two tightly coupled concepts: compositionality , how parts are put together into assemblies, and functionality , the tasks these assemblies perform as they interact with external forces or inputs. While foundation models are already capable of synthesizing 3D shapes and building mechanical parts with computer-aided design (CAD) models, it is the complex compositional structures, in which very different parts and components are orchestrated to smoothly move together, that realize a vast array of demands. Just as a clock emerges from the composition of simple and standardized mechanical elements such as gears and flywheels, these same elements, when combined differently, can give rise to entirely different machines, such as a sewing machine. On the other hand, the same functionality may be realized by different part compositions, just as both cars and bicycles can transport a person from place to place. Put it concisely: composition is shaped by functionality, and functionality is realized through composition . Since such compositional machines can be expressed programmatically, with types, placements and articulations of parts represented in structured code that LLMs can generate and manipulate, we formalize the above question as:  [leftmargin=1em, rightmargin=1em] Can LLMs, given standardized mechanical parts and a reward function for the desired functionality, discover diverse spatial part compositions that maximize the reward and complete the task?    The question is not only about the pursuit of intelligence but also about the practice of engineering. Modern design pipelines are often long and costly, especially in large-scale projects where each iteration demands substantial resources. These projects accumulate vast collections of documents and blueprints, making it difficult to trace, retrieve, or reuse past design efforts. Much essential know-how is passed informally across teams and generations, and in many cases, never fully recorded and since forgotten. An automated machine design system could directly address these challenges. Rather than merely mimicking patterns from historical designs, such a system should be agentic: capable of exploring the exponentially large design space, leveraging prior knowledge to create novel designs for new demands and constraints, and improving them through feedback. To investigate this concretely, we introduce BesiegeField , an interactive environment built on the machine-design game of Besiege FOOTREF2 . The environment allows for construction of simple mechanical machines with standardized and semantic parts such as gears and wheels, and supports customized physical scenarios in which LLM agents can test constructed machines and evaluate their dynamics and interactions. Building on BesiegeField , we benchmark state-of-the-art LLMs with different agent designs and strategies for selecting and placing basic mechanical elements to build machines for representative functional demands, a task we term compositional machine design . Through these experiments, we empirically identify key capabilities required for this task: accurate spatial reasoning, high-level knowledge of design strategies, and instruction-following in spatial domains. Since only a few proprietary LLMs achieve satisfactory results, we further investigate how reinforcement learning (RL) can improve the performance of open-source LLMs. To this end, we curate a small machine design dataset to cold-start RL finetuning, perform exploratory RL experiments, and highlight key challenges that chart directions for future research. In summary, our contributions are listed below: 1. We introduce and formalize the task of compositional machine design , where machines are assembled from standardized parts to achieve functional goals.  2. We present BesiegeField , an interactive environment that enables LLM agents to construct, simulate, and evaluate compositional machines in customized physical scenarios.  3. We systematically benchmark state-of-the-art LLMs and different agentic workflow designs on representative machine-design tasks.  4. We explore RL finetuning of LLMs on this task, for which we curate a cold-start dataset, conduct experiments, and highlight the key challenges. ', 'Compositional Machine Design': 'Full machine design involves many coupled elements: geometry, statics and dynamics, demand analysis, failure modes, safety, and even legal constraints BIBREF0 , BIBREF1 . To isolate a tractable subproblem, we focus on the structural composition of machines: how standardized parts are spatially arranged and mechanically linked to produce functional behavior. We refer to this task, introduced in the previous section, as compositional machine design . It captures two essential components: (i) the static geometry of a machine as a part-based assembly, and (ii) its compatibility with functional demands, typically assessed through physical simulation. This abstraction omits considerations such as manufacturing constraints, material properties, or domain-specific regulations, but retains the core spatial and behavioral reasoning challenges relevant to design. This special task of compositional machine design mirrors challenges found in other exploration domains. For example, automatic theorem proving involves a compositional and exponentially large action space, while electronic design automation (EDA) for chip layouts requires spatial reasoning to place components of varying shapes under spatial constraints (albeit in a more regular and grid-constrained fashion than mechanical parts in machines). A unique challenge in machine design, however, is its dependence on diverse long-horizon behaviors, both autonomous and non-autonomous, within an environment. Specifically, a machine may behave differently when operated in different ways ( e.g. , a bicycle when pedaled versus when braking) or under different external conditions ( e.g. , driving a car in sunny versus rainy weather). Similarly, many sophisticated machines cannot function without appropriate control policies, as exemplified by aircraft that rely on fly-by-wire systems to stabilize their inherently unstable aerodynamic configurations (which would otherwise be unflyable by a human pilot alone). A key open problem is therefore how to account for the interplay among physics, control policy, and compositional structure in machine design. It is worth noting that, unlike in math theorem proving where one valid proof often suffices (even though multiple proofs may still be valued), design domains typically require generating a diverse set of candidate solutions. This diversity is essential to (i) differentiate products, (ii) adapt to unpredictable market demands, and (iii) account for uncertainty in real-world testing and deployment. Consequently, the task places greater emphasis on diversity, and a model for compositional machine design should function more like a generative model than a simple reward maximizer.', 'BesiegeField : Playground for Compositional Machine Design': 'Studying the full problem of compositional machine design is challenging, as it involves the coupling of many interacting factors. We therefore focus on a minimalist, component-level setting in which machines are constructed primarily from cuboid primitives with clear functional semantics, together with a small set of specialized exceptions, and operate under a shared control policy in an environment governed by rigid-body and elastic mechanics. This abstraction allows us to properly benchmark the capabilities of existing LLMs and to assess the upper bounds, potential, and challenges of agentic systems and RL algorithms. To this end, we create BesiegeField , an interactive environment adapted from the machine-building game Besiege, in which players design medieval machines to complete tasks such as destroying castles. Powered by the built-in physics engine, BesiegeField supports physical simulation of mechanical systems such as vehicles and catapults in user-customized environments with terrains, obstacles, external forces ( e.g. , wind and gravity), and co-existing agents. The environment provides nearly 80 types of building blocks (examples illustrated in Fig. FIGREF29 ), including passive ones like drills and logs, and powered ones like powered cogs and wheels. Machines are constructed by sequentially attaching new parts to vacant and attachable faces of existing blocks, starting from a root block and thus forming a \u201cconstruction tree\u201d (indeed a directly acyclic graph (DAG), in the sense of operation orders; one block can has two parents in the DAG; the actual structures may contain loops). Powered blocks can receive control commands, allowing machines to be operated precisely. During simulation, complete state information (e.g., the position and velocity of each block in the constructed machine) can be recorded for model feedback. Finally, the environment supports custom modifications and can be extended with additional block types and richer physics ( e.g. , simple fluid simulation). Further details are explained in Appendix SECREF10 .  BesiegeField is unique in balancing real-world geometry and physics, part-level semantics, and simple compositional rules. Block-stacking environments like LEGO BIBREF2 and Minecraft BIBREF2 , BIBREF3 allow intuitive combinatorial assembly but do not natively provide realistic physical simulation and rely on generic blocks with limited semantic meaning. CAD modeling BIBREF4 captures fine-grained geometry and interactions, but its complexity makes rules cumbersome and sequences prohibitively long. By contrast, BesiegeField uses semantically meaningful parts with cuboid-like construction rules\u2014supporting realistic physics while remaining abstract enough for tractable composition. This calibrated balance enables the study of compositional creativity and geometric reasoning at a level of difficulty that both differentiates algorithms and permits rapid experimentation. Moreover, unlike prior environments, BesiegeField supports machine destruction, adding durability and failure analysis to the design space.', '::Benchmark Settings': \" Representative target machines and tasks. To benchmark and characterize the performance of different LLMs for agentic compositional machine design, we consider two conceptually simple yet representative target machines to build: car and catapult as shown in Fig. FIGREF8 . While success in both requires understanding part semantics and structural syntax, car building primarily tests static relational reasoning, such as enforcing correct part orientations, symmetry, and stability; in contrast, catapult building challenges models with dynamic relational reasoning, where parts must coordinate over time to produce causal mechanical effects. Moreover, the two tasks are simple enough to be constructed with only a few blocks so that they fit within the LLM\u2019s context window, yet complex enough to require explicit reasoning about construction strategies and causal dependencies. We evaluate the performance of cars and catapults by their moving distance and their throwing distance ( i.e. , the moving distance of the stone), respectively, towards a fixed and given direction. During each simulation, the generated machine will be placed at a designated position, and the active parts will be powered after a few seconds. As there can be reward hacking issues, for catapults experiments we surround the designated machine placement position with moderate-height walls. More details about the target machines, rewards, and environments can be found in Appendix SECREF10 .  Machine representations. In BesiegeField , the default XML representation records all blocks with global 3D positions and uses a built-in algorithm to recover connections. Such a representation, however, does not well encode machine structures. Instead, we propose a parsimonious representation aligned with the game\u2019s building logic, based on pairwise relative attachment relationships (i.e., how one part is rotated and attached to another). Details are explained in Appendix SECREFU78 .  Performance metrics. We evaluate our agentic systems using the following quantitative metrics: 1) file validity rate , the proportion of generated JSON files that can be successfully parsed into machine construction trees; 2) spatial validity rate , the proportion of generated machines that are free from self-collisions; 3) machine validity rate , the proportion of machines that satisfy both file and spatial validity; 4) mean and maximum simulation scores , the average and highest rewards achieved by generated machines in the environment.  Environment feedback. For the simple target machines car and catapult , we consider environment feedback within a time window of 5 seconds that is long enough to characterize their designated functionalities. Specifically, for car we consider maximum speed and driving distance; for catapult , we consider boulder throwing distance and maximum height. We also record the machines' global orientation and broken parts information (if any). Details are elaborated in Appendix SECREFU80 .\", '::Agentic Workflow Design': ' Single-agent setting. We first benchmark if a single LLM agent alone is capable of completing the task. Specifically, one LLM agent is provided with the environment description, the available machine components, the assembly syntax, and the functional requirements ( e.g. , moving an object forward). The agent generates a chain-of-thought (CoT; BIBREF5 ) to reason about what is needed and why, and then derives an abstract plan (e.g., connecting a lever to a container with a boulder). This plan is later translated into the construction tree representation.  Iterative editing. Because compositional machine design requires both low-level spatial reasoning and high-level ideation, a single agent rarely produces satisfactory machines. We therefore also design an iterative editing workflow that involves three major agents: 1) designer , which produces an initial plan from the environment description, the available machine components, the assembly syntax, and the functional requirements; 2) refiner , a self-critic agent that which evaluates a draft against requirements and constraints and proposes multiple candidate revisions at each step; 3) environment querier , an agent that runs machine simulation and summarizes the environment feedback, in the way that it always provides global information such as machine orientation throughout the trajectory but selectively reports the feedback on specific blocks ( e.g. , position and speed) for further machine refinement. The workflow begins with a draft from the designer that is later critiqued by an inspector , which assess the designed machine in an abstract fashion, then polished once by a refiner. The design then undergoes a fixed number of iterations, each consisting of one querier and one refiner step. At refiner stages, multiple candidates are generated for running Monte Carlo tree search (MCTS; BIBREF6 ). The best design found in this search process is selected as output.  Hierarchical construction. Inspired by typical human design processes as well as recent designs of agentic systems BIBREF7 , BIBREF8 , BIBREF9 , we introduce a meta-designer agent that first analyzes the requirements and constraints, and then constructs a high-level blueprint of the major functional blocks ( e.g. , the suspension system) and their interconnections. With this blueprint in place, we adopt an autoregressive strategy to build the machine block by block: 1) we begin with the first functional block and dispatch the job to eight parallel builder agents; 2) the valid designs from this stage are evenly distributed to another eight builder agents to construct the second block; and 3) the process iterates in this manner until the entire machine is assembled. Empirically, we find that the meta-designer typically decomposes a machine into three to four functional blocks.', '::Key Empirical Observations': ' General observations. We find compositional machine design to be a challenging task for LLMs (Fig. FIGREF14 and Table TABREF15 ), though not intractable: Gemini 2.5 Pro can consistently construct visually sensible machines with non-trivial performance. We find no evidence that reasoning models outperform non-reasoning ones, suggesting the main bottleneck lies in LLMs\u2019 limited 3D understanding and/or in-context learning. We also find that LLMs, especially reasoning models, still exhibit some spatial and physical reasoning as exemplified by the CoT from Gemini Pro 2.5 (Fig. FIGREF10 ), much like a world model in text space.  Failure patterns. We identified common failure patterns in LLM-generated machines (Fig. FIGREF89 ): 1) incorrect part orientations ; 2) incorrect part placements , where parts attach to wrong parents; 3) instruction-following failures , where elements of the high-level blueprint are not strictly observed; 4) flawed high-level reasoning , where LLMs fail to recognize correct physics or essential components.  Effect of environment feedback. It is unsurprising that with the more environment feedback the agents receive, the better performance of generated machines improve in general (Table TABREF101 ).  Effect of edit history. We find that edit histories are generally helpful in decreasing the number of failure attempts in creating valid machines (Table TABREF24 ), which underscores the importance of longer context window of base models for efficient exploration.  Hierarchical design. We observe the mean performance improves with hierarchical design only when the abstract-level reasoning on blueprints is reliable, as shown by the performance of Gemini 2.5 Pro. In the meantime, consistent with the intuition that hierarchical design is more structured and principled, it generally yields lower variance in obtained scores.  Effect of CoT reasoning. As shown in Fig. FIGREF89 , LLMs often fail to faithfully translate high-level machine design plans in their CoT into semantically and geometrically consistent machine construction trees. To better assess the impact of CoT reasoning on high-level design, we feed the CoT generated by Gemini 2.5 Pro (the best-performing model) to other LLMs, prompting them to directly output construction trees. The resulting machines generally show improved performance (Fig. FIGREF112 ) and highlight the critical role of high-level semantic reasoning in machine design.  CoT-machine correspondence. Though the CoT often provides a reasonably high-level blueprint, agents may still generate machines that deviate from the intended structure (Fig. FIGREF89 ). We hypothesize that this misalignment is a key reason many LLMs struggle to build better machines.  Machine representation. We experiment with a coordinate-only representation derived from the default XML (Appendix SECREFU76 ) and our construction tree representation. Results show that the coordinate-only representation performs significantly worse (Table TABREF25 ), implying that explicit structural information is necessary for LLM understanding.  3D information. We observe that (Table TABREF23 ) the performance generally improves when we also feed parsed 3D information into the context of LLMs, which implies that LLMs are less capable of understanding relative spatial relationship ( e.g. , construction trees).', '': 'Although agentic systems show promise in compositional machine design, simply scaling system size is unlikely to be economical, as errors compound rapidly. Like humans who internalize experience, LLM agents should consolidate new knowledge into weights. We thus explore reinforcement learning with verifiable rewards (RLVR) in BesiegeField to develop machine-design capabilities.', '::Experimental Settings': ' Cold-start finetuning and dataset curation. Following recent RLVR practices BIBREF10 , BIBREF11 , BIBREF12 , we curated a small dataset to cold-start LLMs by aligning their reasoning process with expert CoT. Specifically, we collected textual descriptions of machine functionalities from Besiege player communities and prompted Gemini 2.5 Pro to generate corresponding machines. After filtering out invalid generations, we obtained 9,984 valid machine\u2013CoT pairs. We then used this dataset to perform supervised finetuning on Qwen-2.5-14B-Instruct for 12 epochs. Additional training details are provided in Appendix SECREFU96 .  Reward design. We use the reward INLINEFORM0 where INLINEFORM1 indicates whether constraints are satisfied (Appendix SECREFU79 ). For car , INLINEFORM2 is the maximum travel distance; for catapult , it is the product of the boulder\u2019s maximum height and distance, penalizing solutions that are extreme in only one dimension.  RL finetuning settings. We finetune agents specialized in building a single type of machine (either car or catapult ), making our setup closely aligned with one-shot RLVR BIBREF13 where a single prompt is used throughout the RL process. We adopt group relative policy optimization (GRPO; BIBREF14 ) with LoRA parametrization BIBREF15 (rank 64) and mixed-precision training to finetune the cold-started model. We evaluate both the standard GRPO advantage estimator and the pass@k variant BIBREF16 . In the latter case, due to the implementation of the RLVR framework verl BIBREF17 , the number of rollouts is set equal to INLINEFORM0 . Each experiment is run for 400 iterations on 8 A100 GPUs with per-GPU batch size of 1 and gradient accumulation of 8. We apply KL regularization with strength 0.001 to encourage the model to remain close to its initialization.', '::Main Results and Observations': ' General results. As shown in Fig. FIGREF104 , RL finetuning can generally improve the mean performance, mostly by increasing the percentage that machines are valid (including file validity, machine validity and satisfaction of minimum performance threshold). In the meantime, we also find that the maximum reward increases in our best setting. Similar to observations in many other RLVR settings, the entropy of the output distribution quickly drops even with regularization.  Pass@k advantage vs. Pass@1 advantage. Since we eventually care about the best performing designs, especially given the low validity rate, our default setting adopts Pass@k advantage estimator. Indeed, Pass@k finetuning is more likely to discovery promising machine designs (Fig. FIGREF102 ).  Evolution of generated machines during finetuning. In Fig. FIGREF20 , we qualitatively examine how models refine their designs over the course of finetuning. We observe that models typically make detail-level adjustments, such as shifting part positions, while keeping the same high-level design strategy rather than exploring alternative strategies. Although these strategies are often reasonable, the models struggle to find precise configurations that enable smooth coordination among parts. This precision is especially critical for sophisticated mechanisms like catapults to function properly.  Cold-start. Not surprisingly, we find that cold-start alone does not enable models to produce satisfactory designs, and that finetuning on the cold-start model is better than on the base model (Table TABREF18 ).', 'Discussions and Intriguing Insights': ' Capabilities for compositional machine design. Although tasks such as visual understanding and generation also depend on spatial, physical, and semantic reasoning, compositional machine design introduces unique requirements for LLM capabilities. Without precise spatial placement of machine parts, a design may fail to function correctly; a gear train, for example, will not transmit rotation if the gears are misaligned. Since the design process is typically hierarchical, successful LLMs must be able to accurately translate high-level blueprints into detailed geometric designs. In addition, machine design spans both concept-level reasoning and detailed specification. This dual demand often leads to large design documents and calls for a form of \u201cvisual reasoning\u201d expressed through text, similar to what has been studied in LLMs applied to scalable vector graphics (SVG) and CAD models BIBREF18 , BIBREF19 . Multimodal reasoning is also important because effective machine design typically relies on integrating textual descriptions with visual or schematic representations. In this work, however, we focus only on pure LLM-based reasoning to isolate and analyze its capabilities for compositional machine design.  Challenges in agentic machine design systems. The task of machine design faces similar challenges found in agentic systems in domains such as legal services and other knowledge-intensive fields. A key difficulty is the highly varied requirements and domain knowledge of different customers. To address this, LLMs need to acquire task-specific knowledge through in-context learning or finetuning. In addition, the complexity of design tasks often requires multiple agents to coordinate, and such pipelines can suffer error accumulation when the base LLM lacks sufficient capability.  Exploration in machine design space. Different from tasks such as theorem proving, the goal of compositional machine design is to discover structures that more effectively achieve desired functionalities. Rather than reusing existing solutions, a practical design agent should be able to propose novel strategies, structural layouts, and part specifications as machine complexity increases. Meeting this requirement calls for RL finetuning methods that prevent models from collapsing into a narrow set of strategies and structures, which recent methods aim to alleviate BIBREF20 , BIBREF21 , BIBREF22 , BIBREF23 , BIBREF24 . This demand is closely related to continual RL BIBREF25 , since finetuned LLMs must avoid catastrophic forgetting, maintain its reasoning ability, and consolidate learned strategies, which is particularly important because large-scale machine design datasets are rare and commercially infeasible to collect.', 'Related Work and Concluding Remarks': ' 3D graphics codes for generative modeling. There is a long history in 3D asset generation and engineering design of representing the construction of a target instance as a program or sequence of operations in a domain-specific language BIBREF26 , BIBREF27 , BIBREF28 , which we refer to here as 3D graphics codes BIBREF18 , BIBREF29 . Unlike geometric representations such as point clouds or meshes, these codes describe objects at a higher semantic level, capturing part composition, design constraints, and user operations in modeling software. Similar to programming languages, 3D graphics codes are inherently discrete and are typically generated with autoregressive models trained from scratch BIBREF30 or with LLMs finetuned on curated datasets BIBREF31 , BIBREF32 . Much of the existing work centers on CAD scripts for individual parts BIBREF33 , BIBREF19 , BIBREF4 or Blender macros for single assets BIBREF34 . Whereas recent studies on LEGO assemblies BIBREF3 , Minecraft structures BIBREF2 , BIBREF35 , and procedural scene generation BIBREF27 , BIBREF29 , BIBREF36 , BIBREF30 introduce richer compositionality, they still fall short of the task of compositional machine design, which requires assemblies that both function under physical laws and exhibit the precise geometry of real objects.  LLM agents. LLM agents are language models organized to operate in iterative loops of perception and action BIBREF37 , BIBREF38 , BIBREF39 . They interact with external tools BIBREF40 , BIBREF41 , BIBREF42 , BIBREF43 , respond to signals from simulated or real environments BIBREF44 , BIBREF45 , incorporate self-reflection to refine their outputs BIBREF46 , BIBREF19 , BIBREF47 , BIBREF48 , and are commonly organized into multi-agent systems that coordinate roles and exchange information BIBREF49 , BIBREF50 , BIBREF9 . These designs move beyond one-shot text generation and establish LLMs as adaptive decision makers capable of long-horizon reasoning. Approaches that introduce search over possible solutions BIBREF51 , BIBREF52 , BIBREF53 or reflection on prior attempts BIBREF54 , BIBREF55 , BIBREF56 , BIBREF7 , BIBREF48 have enabled progress on increasingly complex tasks. LLM agents have already been used in design tasks such as code synthesis BIBREF57 , BIBREF58 , BIBREF59 , CAD design BIBREF19 and game environments BIBREF60 , BIBREF2 . Partially inspired by these developments, BIBREF61 proposed a prototypical agent-based design framework that generates mechanical structures from text prompts. Their system treats structure generation as a one-shot process and delegates the search for optimal geometric and physical parameters to external optimization tools. In contrast, our work with BesiegeField explores how LLM agents can directly and iteratively bridge compositional structures to functional goals, framing design as a process of reasoning and adaptation with both accurate simulation and intuitive physics.  Reinforcement learning with verifiable rewards (RLVR). Recent studies indicate that, by running RL finetuning with verifiable rewards from simulators or verifiers, reasoning abilities emerge BIBREF14 , BIBREF62 , BIBREF63 , even when single prompt is used during finetuning BIBREF13 . Yet, many methods exhibit loss of diversity as output entropy collapses during reinforcement learning and thus do not fully enable LLMs to explore novel solutions. Examples of mitigation methods include explicit entropy or KL regularization BIBREF22 , BIBREF64 , Pass@k training BIBREF16 , BIBREF21 , and distribution-matching objectives like generative flow networks BIBREF20 , BIBREF65 . BesiegeField provides verifiable rewards and thus enables direct application of RLVR to compositional machine design.  Concluding remarks . We introduced compositional machine design , a simplified yet challenging task that reflects core aspects of real-world machine design. To evaluate LLM performance on this task, we developed BesiegeField , an interactive environment based on the game Besiege. Our results with agentic systems and reinforcement learning demonstrate that LLMs hold promise for solving this problem. While we did not exhaustively explore all designs or integrate multi-modal information, our findings underscore the need to advance fundamental LLM algorithms and capabilities, and point toward exciting future directions in machine design.', 'Acknowledgment': 'We sincerely thank the developers of Besiege for creating the game and fostering an open and vibrant community, without which our exploration of this exciting idea would not have been possible. tocsectionAppendix', 'Details on the BesiegeField Environment': 'We built BesiegeField by creating plug-in modules for the game Besiege that create interfaces to allow flexible composition of parts (once certain rules are obeyed), control policies on multiple powered parts ( e.g. . powered cogs), recording of state information of any block ( e.g. , position, orientation, part integrity, etc.) and settings of termination conditions ( e.g. , some part passing through a line). BesiegeField supports multi-process launching and thus allows for efficient parallel RL training. As the game natively supports multi-player gameplay, BesiegeField can naturally be applied to multi-agent RL settings. As the game Besiege (shown in Fig. FIGREF28 ) is built with the (mostly) open-sourced Unity3D game engine FOOTREF26 , BesiegeField is highly-customizable: the environment 1) natively supports modification of physical parameters, external forces, terrains and obstacles ( e.g. , stone buildings) and 2) allows for extension patches (known as mods FOOTREF27 ) to introduce other mechanisms, such as new block types, fluid simulation and many other components.', 'Details on the BesiegeField Environment::Construction Rule': 'Each machine is built by attaching new blocks to the existing structure, starting from a special root block. For convenience, we describe each construction step as an \u201cattacher\u201d block (child) connected to an \u201cattachee\u201d block (parent). As an attacher, each block has exactly one face available for connection; as an attachee, each block has none to several attachable faces. Once a face is used, it is considered occupied and cannot be reused. If, after construction, the free end of a block happens to coincide with an attachable face of an existing block, the two blocks are automatically connected. A few special blocks violate the rule described above, such as spring. These blocks have two ends and thus must have two parent blocks, do not have physical volume can be attached to either vacant or occupied faces of other blocks. Finally, each block can be rescaled and rotated after construction. Since post-construction scaling and rotation introduce unnecessary complexity into our pipeline, we exclude them from our experiments and leave their handling to future work.', 'Details on the BesiegeField Environment::Simulation': 'Once constructed, the machine will be placed at the designated pose indicated by the position and orientation of the starting block (not necessary near the ground, but there is a maximum height constraint). The machine will be subject to gravity and Newtonian physical laws (rigid and elastic ones) after placement.', 'Details on the BesiegeField Environment::Blocks': 'Out of the 75 construction blocks provided by Besiege, we filter out a list of 27 blocks (shown in Fig. FIGREF29 ) that are most relevant to build machines with classical mechanical mechanisms such as levers and trusses. 1.  Starting Block : the root of any mechanism; initial orientation is along z+ axis.  2.  Small Wooden Block : a cubic basic construction block.  3.  Wooden Block : shaped like two small wooden blocks attached together.  4.  Wooden Rod : a slender, fragile construction block.  5.  Log : shaped like three small wooden blocks arranged in parallel.  6.  Steering Hinge : powered; controls rotation of sub-blocks, swinging left or right along the axis perpendicular to its placement axis.  7.  Steering Block : powered; rotates blocks along its placement axis.  8.  Powered Wheel : radius 1m; provides ground movement.  9.  Unpowered Wheel : identical to the powered wheel but requires external force to rotate.  10.  Large Powered Wheel : larger version of the powered wheel (radius 3m).  11.  Large Unpowered Wheel : unpowered version of the large powered wheel.  12.  Small Wheel : functions like a caster wheel (e.g., shopping cart), unpowered, 1.2m long.  13.  Roller Wheel : similar to the small wheel, but shorter (0.8m).  14.  Universal Joint : freely rotates around its placement axis, unpowered.  15.  Hinge : swings up and down along the axis perpendicular to its placement axis, unpowered.  16.  Ball Joint : swings freely in all directions, unpowered.  17.  Axle Connector : similar to a ball joint but allows unrestricted INLINEFORM0 rotation.  18.  Suspension : shaped like a wooden block, it can buffer forces from all directions.  19.  Rotating Block : powered; motor-like block that generates torque and rotates about its local y-axis.  20.  Grabber : grabs objects on contact and can release them.  21.  Boulder : a large rock, loosely attached; useful for throwing.  22.  Grip Pad : block with the highest friction.  23.  Elastic Pad : block with the highest elasticity.  24.  Container : typically used to hold a boulder.  25.  Spring : can contract; one of the special blocks that can have two parent attachments (without occupying attachable faces).  26.  Brace : reinforces structural strength.  27.  Ballast : a heavy cubic block used as a counterweight. ', 'Details on the BesiegeField Environment::Tasks': 'We define a set of tasks in which the goal is to construct machines within a designated building area to accomplish specific objectives. 1.  Movement. Referred to as the car task in the main text, the objective is to build a machine capable of driving along tracks and traversing various terrains.  2.  Throw. Referred to as the catapult task in the main text, the goal is to construct a machine that can launch boulders over long distances. To prevent unintended strategies (e.g., carrying the boulder instead of throwing it, or letting it roll along the ground), the building area is enclosed by a medium-height wall.  3.  Delivery. This task requires building a machine that can transport a large stone forward across different terrains (Fig. FIGREF70 ).  4.  Pick. The objective here is to design a machine that can retrieve a stone located at the bottom of a deep well (Fig. FIGREF69 ).  For many of these tasks, we introduce multiple difficulty levels (not used in the experiments reported in this paper) to encourage progressively more sophisticated designs: 1.  Movement and Delivery. We consider: (1) randomized terrains with stones and wooden rods ( e.g. , Fig. FIGREF67 ), (2) curved tracks (Fig. FIGREF72 ), and (3) obstacles such as height-limiting bars.  2.  Throw. We design: (1) varied objectives, such as requiring the boulder to pass through an aerial ring (Fig. FIGREF71 ) or land precisely within a small target zone, (2) environmental factors such as wind, and (3) obstacles, including height restrictions either within the building area or along the boulder\u2019s trajectory. ', 'Search Strategies in Machine Modification Loops': 'Apart from the MCTS strategy used in the main experiments, we also evaluate two alternatives: (i) best-of-N, where we select the best-performing machine out of N candidates, and (ii) random search, which mimics best-of-N but instead selects a random candidate. For clarity, we refer to one consecutive \u201cquerier\u2013refiner\u201d call as a search node (consistent with our MCTS setup). Unlike classical MCTS or best-of-N, here each search node is allowed up to five retries to prevent child statistics from being too sparse. We perform INLINEFORM0 search rounds, each aiming to obtain 5 valid candidate machines (though this may fail; if fewer than 5 are found, the parent node\u2019s machine is used as a candidate). Full algorithmic details are provided in Algorithm SECREF11 , Algorithm SECREF11 , and Algorithm SECREF11 . In Fig. TABREF74 we show the improvement of machine performance with respect to the number of search rounds used. In Fig. FIGREF75 we compare the efficiency of different search methods in our agentic compositional machine design setting. Random Search Algorithm NN SS FF RR Input machine INLINEFORM0 INLINEFORM1 INLINEFORM2   INLINEFORM0 to INLINEFORM1 INLINEFORM2 INLINEFORM3 INLINEFORM4 INLINEFORM5 INLINEFORM6 INLINEFORM7 break INLINEFORM8 INLINEFORM9   INLINEFORM0  Best-of-N Algorithm NN SS FF RR nn Input machine INLINEFORM0 INLINEFORM1 INLINEFORM2 INLINEFORM3   INLINEFORM0 to INLINEFORM1 INLINEFORM2 INLINEFORM3 INLINEFORM4 to INLINEFORM5 INLINEFORM6 INLINEFORM7 INLINEFORM8 INLINEFORM9 INLINEFORM10 break INLINEFORM11 INLINEFORM12 INLINEFORM13 INLINEFORM14   INLINEFORM0  Monte Carlo Tree Search (MCTS) NN rootroot MAX_ITERMAX\\\\_ITER  INLINEFORM0 INLINEFORM1 INLINEFORM2 to INLINEFORM3 INLINEFORM4 INLINEFORM5 Step 1: Selection INLINEFORM6 or INLINEFORM7 INLINEFORM8 not INLINEFORM9 INLINEFORM10 Unvisited leaf node ; no children yet INLINEFORM11 and not all child nodes are valid INLINEFORM12 INLINEFORM13 Step 2: Expansion INLINEFORM14 break INLINEFORM15 Step 3: Simulation INLINEFORM16 Step 4: Backpropagation return INLINEFORM17 Return best child', '::Machine Representation': 'To reduce complexity in compositional machine design, our machine representation assumes all blocks remain at their default scale and are not further rotated after attachment (note: the attachment operation itself may rotate blocks).', '::Global Position-based Representation': 'By simplifying the default XML representation that BesiegeField receives, we obtain the global position-based representation. Below is a concrete example: Basically, each block in the machine is independently recorded without mentioning its adjacent blocks. For most of the block types, only the block type and its pose (position + orientation) are recorded. For special blocks that have two parents, the other end has to be specified, for which the corresponding dictionary has an additional entry of \u201cend-position\u201d.', '::Construction Tree Representation': \"With our parsimonious construction tree representation, the example machine above is represented by the following the following JSON list: Specifically, the ordered list of dictionaries of the machine construction JSON file represents the construction order of blocks. Each dictionary contains the following information of corresponding block: 1) \u201ctype\u201d: block type; 2) \u201cid\u201d: the order ID of this block (the same as the order in the list), included so that LLMs do not have to parse it by itself; 3) \u201cparent\u201d, the ID of its parent block; 4) \u201cface_id\u201d, the face of the block's parent to which the block is attached. In cases that the block has two parents ( e.g. , a string that connects both parts), we use \u201cparent_a\u201d and \u201cparent_b\u201d to record both parents; similar for \u201cface_id\u201d. Note: the first block with \u201cid\u201d 0 is always the unique starting block, of which the local position and rotation are always zero.\", '::Reward Setting': 'Here we elaborate on the reward design for RL experiments in Sec. SECREFU17 . Our reward is in the form of INLINEFORM0 where INLINEFORM1 is the boolean representing machine validity and INLINEFORM2 is the task-specific performance metric.  Car . We set INLINEFORM0 to 1 as long as the policy produces a machine that can be parsed from the generated construction tree and can be successfully placed into the environment without any self-collision; otherwise it is set to 0. INLINEFORM1 is set to the distance between the starting position and the end position of the root block.  Catapult . For INLINEFORM0 to be 1 in this task, the machine has to satisfy an additional constraint compared to the car task: the maximum height of the boulder position during simulation must be greater than a threshold of 3m. As explained in the main text, INLINEFORM1 for INLINEFORM2 is the product of the maximum height and maximum distance (towards some pre-defined direction) during simulation.', '::Environment Feedback': 'In principle, we are able to obtain all state variables of each single part of a simulated machine. Due to the space complexity of the simulation results, not all information can be fed to LLM agents. Here we consider a minimal set of environment feedback information that the environment querier always gathers and returns to the refiner. Below are the minimal set of feedback information for each task:  Car. 1) machine orientation; 2) machine maximum moving distance (towards a designated direction); 3) machine max speed; 4) machine average speed per second; 5) machine position per 0.2 second (atomic time).  Catapult. 1) boulder maximum distance (horizontal, towards a designated distance); 2) boulder maximum height; 3) boulder position per 0.2 second (atomic time). Beyond these basic pieces of feedback, the querier, after seeing the candidate machine and its simulation results, in our default setting selectively extract a subset of environment feedback given its speculation on the issues of the simulated machine. For instance, parts during simulation may collide with each other and break. Such behavior carries important hints on why machines fail, and an LLM agent with sufficient capability in spatial and physics understanding can possibly identify the vulnerable blocks in the design. Below we elaborate on the additional information that the querier may gather: 1. Block index to query;  2. Time interval of interest (states outside this interval will not be considered);  3. Feedback type of interest (one or more from the list) Position; Orientation; Velocity; Length (for spring only)  3.1. Position;  3.2. Orientation;  3.3. Velocity;  3.4. Length (for spring only) ', 'Challenges in Compositional Machine Design::Failure Patterns': 'Generated machines often fail in systematic ways. As shown in Fig. FIGREF89 , we observe several recurring categories of errors, including flawed reasoning, structural attachment errors, incorrect part orientations and failures in instruction following. These diverse failure types highlight both the reasoning and execution challenges inherent in compositional machine design.', 'Challenges in Compositional Machine Design::Need for Precision': 'In Fig. FIGREF91 we present a simple example to illustrate how the task of compositional machine design requires high precision in the spatial design of configurations of different parts. Even though the high-level design is feasible, the machine in the top row fails to throw the boulder out due to the incorrect position of the container.', 'Challenges in Compositional Machine Design::Appearance vs.\\xa0Performance': \"As illustrated in Fig. FIGREF93 , a machine's appearance does not necessarily reflect its actual performance. A design that seems well-aligned with human intuition can fail dramatically, while one that looks awkward or unintuitive may achieve superior results. For LLMs to design machines that are both effective and visually intuitive to humans, reward functions must account not only for task performance but also for stability and other factors that shape human perception of functionality.\", 'Settings for RL Finetuning::Cold-Start Dataset Curation': 'Noticing that Gemini 2.5 Pro produces the most satisfactory machines with reasonable CoT, we adopt the single-agent generation setting and collect Gemini-generated machines along with their CoT. We curated 100 design objectives: 75 captions of machines created by Besiege players from the Internet and 25 authored by us. These 25 prompts are constructed by 1) first writing down simple design objectives that are realizable by BesiegeField and can emerge from some simple rewards, and 2) then introducing environment constraints and machine-specific requirements. Using this prompt dataset, we generate 250 machines per prompt, and after filtering out inappropriate ones (those that fail to parse, cannot be built in the environment, or do not have a specific physics-driven functionality, e.g. , a statue), we obtain 9,984 machines with their corresponding CoT. A sample gallery is shown in Fig. FIGREF95 . We present examples in the curated prompt set: Below we present the text prompts with our simple authoring strategy, which can possibly be scaled with LLMs:', 'Settings for RL Finetuning::Cold-Start Details': 'In our experiment, we use Qwen2.5-14B-Instruct as the base model and train it on the Gemini synthesized dataset. To save GPU memory, we employ the parameter-efficient quantized OFT (QOFT) technique BIBREF70 , BIBREF68 , BIBREF67 , BIBREF69 for updating the model parameters, with OFT block size 64. We use 8-bit training with the 8-bit AdamW optimizer implmented with bitsandbytes BIBREF66 , a learning rate of 1e-6 and a linear warmup schedule (3% of the total training steps).', 'Settings for RL Finetuning::RL Experiment Details': 'We use verl framework to implement our RL experiments. The LLM is finetuned from Qwen2.5-14B-Instruct (with LoRA of rank 64 on all linear layers) using the Gemini-synthesized dataset described above. We set learning rate to 5e-6 with gradient clipping threshold set to 0.5. The GRPO advantage estimator uses an advantage clipping ratio of 0.2. We add a KL penalty (weight 0.001) with respect to the pretrained LLM and do not introduce any entropy regularization. For rollouts, we use a temperature of INLINEFORM0 and top- INLINEFORM1 value of 0.95. Maximum input and output lengths are 3440 and 1168 tokens, respectively. We train each model for 400 update steps which take approximately 48 hours.', 'Additional Ablation Studies': ' Meta-Designer in hierarchical design. In Table TABREF98 , we show that how a meta-designer for hierarchical design may benefit compositional machine design. Leveraging the knowledge on existing machines, meta-designers can identify the key macro-level mechanical components that are easier to design compared to the whole task, as shown in the results for Gemini 2.5 Pro, Kimi K2 and Llama 4 Scout. However, introducing an additional stage can introduce compounding error and, if the LLM agent is not capable of integrating different macro-level mechanical components, they may lead to lower scores, which we hypothesize is the reason for the failure of hierarchical design in models like Qwen3. Moreover, we examine if the meta-designer should provide step-by-step building instruction for the designer (Fig. FIGREF99 ), or simply provide high-level mechanical component descriptions. We find that a meta-designer that provides more detailed information is beneficial mostly when the base model is powerful enough ( e.g. , Gemini 2.5 Pro).  Effect of feedback-free self-critic. In Table TABREF100 , we show that the inspector agent which does self-critic before running any environment simulation tend to improve performance for models like Gemini 2.5 Pro (the most powerful model for the task of compositional machine design in BesiegeField ) but can fail drastically for models like o3.  Effect of active feedback queries. In Table TABREF101 , we show that the active queries on the environment feedbacks help most of the models achieve better performance, compared to the setting with no environment feedback and that with only environment simulation final scores.  Additional RL results. In Fig. FIGREF102 and FIGREF104 and , we show the maximum scores achieved in the environments with different RL methods plus the validity rate of machines. We visualize the maximum score since, in the case when one is allowed to use inference-time scaling techniques, the best performing machines are the ones people care most about. We show that our settings with Pass@64 training achieves the best maximum score with two different random seeds. In additiona, in Fig. FIGREF106 , we visualize the corresponding Best@N metrics. For completeness, we also visualize the results with our default setting on the task car in Fig. FIGREF103 , FIGREF105 and FIGREF107 .', 'Generated Samples::From RL-finetuned Models': 'Here, we present some of the best RL samples from rollouts, as well as examples from the agentic workflow. Fig. FIGREF109 displays the RL rollout samples, while Fig. FIGREF111 illustrates the agentic workflow samples.', 'Relations between CoT and Machines': 'To further investigate if high-level machine blueprint or low-level part placement is more important, we experiment with machine generation of LLMs by generating machine details conditioned on Gemini-generated CoT (instead of on CoT produced by themselves). We find that with Gemini CoT, almost all LLMs design machines that are more visually similar to \"catapults\", as shown in Fig. FIGREF112 . We therefore hypothesize that the major gap between other LLMs, especially open-source ones, and Gemini 2.5 Pro is the abstract-level spatial and physics reasoning on machine designs.'}\n\n-----\n\n## Overview of the plan\n# Reproduction Plan for \"Agentic Design of Compositional Machines\" (BesiegeField)\n\nThis plan precisely reproduces the methodology, experimental setup, and evaluation protocols described in the paper. All components are derived exclusively from the provided text, with ambiguities explicitly flagged.\n\n---\n\n## **I. Core Methodology Elements**\n\n### **1. Task Formalization: Compositional Machine Design**\n- **Goal**: Given a functional requirement (e.g., \u201cbuild a machine to throw a boulder as far as possible\u201d) and a fixed set of 27 standardized mechanical blocks, generate a machine structure (construction tree) that maximizes a verifiable physical reward.\n- **Core Constraints**:\n  - Machines are built from 27 predefined blocks (see Section \u201cDetails on the BesiegeField Environment::Blocks\u201d).\n  - Construction follows a **strict attachment rule**: each block has one attachable face (except Spring, which has two parents).\n  - Blocks cannot be scaled or rotated post-attachment (explicitly excluded per \u201c::Machine Representation\u201d).\n  - Machines must be assembled as a **directed acyclic graph (DAG)** rooted at the \u201cStarting Block\u201d (ID=0), with attachment relationships defined via parent-child ID pairs.\n  - No post-construction modifications (scaling/rotation) are permitted during generation or simulation.\n- **Output Format**: A JSON list of block dictionaries in construction order, each with:\n  - `\"type\"`: string (e.g., \"Powered Wheel\")\n  - `\"id\"`: integer (0-indexed order of placement)\n  - `\"parent\"`: integer (ID of parent block); for two-parent blocks (e.g., Spring), use `\"parent_a\"` and `\"parent_b\"`\n  - `\"face_id\"`: integer (face index on parent to attach to); for two-parent blocks, use `\"face_id_a\"` and `\"face_id_b\"`\n- **Input to Agent**: Natural language task description + list of 27 block types + attachment rules + physics constraints.\n\n### **2. Environment: BesiegeField**\n- **Implementation Basis**: A Unity3D-based plugin/mod for the game *Besiege* (open-sourced engine).\n- **Core Functionalities to Reproduce**:\n  - **Block Library**: 27 blocks as listed in \u201cDetails on the BesiegeField Environment::Blocks\u201d. All others (75 total) are excluded.\n  - **Construction Rules**:\n    - Root block (ID=0) is always placed at (0,0,0) with orientation aligned to +z.\n    - Each block has exactly one \u201cattachable face\u201d (except Spring, which can attach to two existing blocks).\n    - Automatic connection: if a free end of a newly placed block coincides with an attachable face of an existing block, connect automatically.\n    - Spring blocks are special: they have no volume, attach to two parents, and do not consume attachable faces.\n  - **Simulation Engine**:\n    - Rigid-body physics with gravity and elastic collisions.\n    - No fluid simulation, no aerodynamic drag (unless explicitly added in extended tasks).\n    - Simulation duration: 5 seconds for all benchmark tasks (car, catapult).\n    - Simulation starts after 2 seconds of idle time (to allow settling).\n    - Powered blocks (e.g., Powered Wheel, Rotating Block) activate at t=2s.\n  - **State Recording**:\n    - Per-block state at 0.2s intervals: position (x,y,z), orientation (quaternion or Euler), velocity (linear and angular), integrity (broken: 0/1).\n    - For catapult: boulder\u2019s position and velocity tracked.\n    - For car: root block\u2019s position and velocity tracked.\n  - **Termination Conditions**:\n    - Simulation ends at 5s or if machine breaks (any block integrity = 0).\n    - For catapult: boulder must reach >3m max height to be considered valid (per reward definition).\n  - **Environment Constraints**:\n    - Building area enclosed by medium-height walls (prevents carrying, rolling, or flying out).\n    - Terrain: flat ground for baseline tasks; extended tasks may include stones, rods, curved tracks, height bars (not used in main experiments).\n  - **Parallelization**: Must support multi-process simulation for RL training (8 A100 GPUs).\n\n### **3. Machine Representations**\n- **Two Representations Must Be Implemented**:\n  1. **Global Position-Based (Baseline)**:\n     - Each block represented independently.\n     - Fields: `\"type\"`, `\"position\"` (x,y,z), `\"orientation\"` (quaternion or Euler angles).\n     - For Spring: additional `\"end_position\"` field.\n     - **No parent-child relationships** recorded.\n  2. **Construction Tree (Proposed)**:\n     - Ordered list of blocks by construction sequence.\n     - Each block: `\"type\"`, `\"id\"`, `\"parent\"`, `\"face_id\"` (and `\"parent_a\"`, `\"parent_b\"`, `\"face_id_a\"`, `\"face_id_b\"` for Spring).\n     - First block always has `\"id\": 0`, `\"type\": \"Starting Block\"`, `\"parent\": null`, `\"face_id\": null`.\n     - **All blocks must be referenced by ID only**; no absolute coordinates.\n- **Validation**: JSON parser must reject malformed trees (e.g., circular references, invalid parent IDs, missing fields).\n\n### **4. Agentic Workflow Designs**\nThree agent architectures must be implemented:\n\n#### **A. Single-Agent (Baseline)**\n- Input: Task description + block list + rules.\n- Output: Construction tree in JSON format.\n- Reasoning: Uses Chain-of-Thought (CoT) prompting (e.g., \u201cFirst, I need a base... then attach wheels...\u201d).\n- No feedback loop. One-shot generation.\n\n#### **B. Iterative Editing (Main Agentic Workflow)**\n- **Three-Agent Pipeline**:\n  1. **Designer**: Generates initial construction tree from task + rules.\n  2. **Refiner (Self-Critic)**: Receives designer\u2019s output + environment feedback. Generates **multiple candidate revisions** (\u22653) via sampling (temperature >0).\n  3. **Environment Querier**: Runs simulation, returns **minimal feedback** (see Section \u201c::Environment Feedback\u201d) + **selective queries** (if enabled).\n     - Minimal feedback always returned: e.g., for catapult \u2192 boulder max height, max distance, positions every 0.2s.\n     - Selective queries: agent may request block-specific data (position, velocity, length for Spring) for specific blocks and time windows.\n- **Search Loop**:\n  - Each \u201cquerier\u2013refiner\u201d pair = 1 search node.\n  - Each node allows up to 5 retries if no valid machine is generated.\n  - After refiner generates N candidates (N=5), run simulations in parallel.\n  - **MCTS (Monte Carlo Tree Search)** is the default search strategy:\n    - **Selection**: UCB1-based tree traversal.\n    - **Expansion**: Expand node if not all children are valid or unvisited.\n    - **Simulation**: Run physics simulation on candidate machine.\n    - **Backpropagation**: Update node statistics with reward.\n  - **Total search rounds**: 10 (as implied by \u201cperform INLINEFORM0 search rounds\u201d and Fig. TABREF74).\n  - Output: Best machine found over all search nodes.\n\n#### **C. Hierarchical Design**\n- **Meta-Designer**:\n  - Input: Task description.\n  - Output: High-level blueprint (text description) of 3\u20134 functional blocks (e.g., \u201csuspension system\u201d, \u201clever arm\u201d, \u201ccounterweight\u201d).\n- **Autoregressive Builder**:\n  - Stage 1: Meta-designer output \u2192 8 parallel builder agents generate first functional block (e.g., suspension).\n  - Stage 2: Valid designs from Stage 1 \u2192 distributed to 8 new builders to add second block.\n  - Stage 3: Iterate until all functional blocks are assembled.\n- **Constraint**: Only valid (file + spatial) designs are passed to next stage.\n- **Critical Note**: Meta-designer must output **abstract functional descriptions**, not step-by-step instructions (per \u201cAdditional Ablation Studies\u201d).\n\n### **5. Reinforcement Learning with Verifiable Rewards (RLVR)**\n#### **A. Cold-Start Dataset Curation**\n- **Source**: 100 prompts:\n  - 75 from Besiege player communities (textual machine descriptions).\n  - 25 authored by paper authors (simple objectives + constraints).\n- **Generation**:\n  - Use **Gemini 2.5 Pro** (single-agent mode) to generate machine + CoT for each prompt.\n  - Generate 250 samples per prompt \u2192 25,000 total.\n- **Filtering Criteria**:\n  - Must parse into valid construction tree (JSON).\n  - Must be physically buildable (no self-collisions at placement).\n  - Must exhibit **physics-driven functionality** (e.g., not a statue, not a floating block).\n  - Must have a CoT that logically connects task \u2192 design.\n- **Final Dataset**: 9,984 valid **(prompt, CoT, construction tree)** triples.\n- **Storage Format**: JSONL file per sample:\n  ```json\n  {\n    \"prompt\": \"Build a machine to throw a boulder as far as possible\",\n    \"cot\": \"First, I need a base... then attach a lever...\",\n    \"machine\": [{\"type\": \"Starting Block\", \"id\": 0, ...}]\n  }\n  ```\n\n#### **B. Reward Function**\n- **General Form**:  \n  `R = R_valid * R_task`  \n  where `R_valid \u2208 {0,1}`, `R_task` is task-specific scalar.\n- **Car Task**:\n  - `R_valid = 1` iff:  \n    (a) JSON parses successfully,  \n    (b) no self-collision at placement,  \n    (c) machine remains intact during 5s simulation.  \n  - `R_task = distance traveled by root block (m)` (max displacement along designated direction).\n- **Catapult Task**:\n  - `R_valid = 1` iff:  \n    (a) above car conditions,  \n    (b) **boulder reaches >3m maximum height**.  \n  - `R_task = max_height (m) \u00d7 max_distance (m)` (product, to penalize one-dimensional extremes).\n\n#### **C. RL Finetuning Setup**\n- **Base Model**: `Qwen2.5-14B-Instruct`\n- **Finetuning Method**: **Group Relative Policy Optimization (GRPO)** with LoRA.\n- **LoRA Configuration**:\n  - Rank: 64\n  - Applied to: all linear layers (query, key, value, output)\n- **Training Framework**: `verl` (verified reinforcement learning)\n- **Hyperparameters**:\n  - Learning rate: 5e-6\n  - Gradient clipping: 0.5\n  - KL penalty weight: 0.001 (relative to pretrained Qwen)\n  - No entropy regularization\n  - Advantage clipping ratio: 0.2\n  - Rollout temperature: 1.0 (default), top-p: 0.95\n  - Max input length: 3440 tokens\n  - Max output length: 1168 tokens\n- **Batching**:\n  - 8 A100 GPUs\n  - Per-GPU batch size: 1\n  - Gradient accumulation: 8 \u2192 effective batch size = 8 \u00d7 8 = 64\n- **Training Duration**: 400 update steps (~48 hours)\n- **Advantage Estimator Variants**:\n  - **Pass@1**: Standard GRPO advantage\n  - **Pass@k**: Use top-k rollouts per prompt (k=64, as used in best results)\n- **Cold-Start Initialization**: Finetune **on curated dataset**, not from base model (Table TABREF18 confirms this is critical).\n- **Quantization**: Use **8-bit AdamW optimizer** via `bitsandbytes` (per \u201cSettings for RL Finetuning::Cold-Start Details\u201d).\n- **Parameter Efficiency**: Use **QOFT (Quantized OFT)** with block size 64 (not LoRA in cold-start, but LoRA in RL).\n\n### **6. Evaluation Metrics**\nAll metrics computed over **100 test prompts** (held-out from training set, not used in cold-start or RL).\n\n| Metric | Definition |\n|--------|------------|\n| **File Validity Rate** | % of generated JSONs that parse into valid construction tree (no missing fields, valid IDs, no cycles) |\n| **Spatial Validity Rate** | % of parsed machines with no self-collisions at placement (before simulation) |\n| **Machine Validity Rate** | % of machines that satisfy both file and spatial validity |\n| **Mean Simulation Score** | Average `R` across all valid machines |\n| **Maximum Simulation Score** | Highest `R` achieved in any rollout |\n| **Pass@k Score** | Maximum score among top-k generated machines per prompt (k=1, 8, 64) |\n| **Entropy of Output Distribution** | Measured over token-level output distribution during RL (to detect collapse) |\n\n### **7. Search Strategy Comparisons (Ablation)**\nMust implement and compare:\n- **Best-of-N**: Generate N candidates (N=5), simulate all, return best.\n- **Random Search**: Generate N candidates, pick one at random.\n- **MCTS**: As described above.\n- **Search Rounds**: 10 rounds per machine (each round attempts to generate 5 valid candidates).\n\n---\n\n## **II. Experimental Requirements**\n\n### **1. Datasets**\n- **Cold-Start Dataset**: 9,984 (prompt, CoT, machine) triples from Gemini 2.5 Pro.\n  - Source: 100 prompts (75 community + 25 authored).\n  - Must be stored as JSONL.\n- **Test Set**: 100 new prompts (held-out, not used in training or cold-start).\n- **Validation Set**: Optional, but recommended for early stopping during RL (not specified in paper).\n\n### **2. Preprocessing**\n- **Block Mapping**: Map block names (e.g., \u201cPowered Wheel\u201d) to internal enum or ID for consistent parsing.\n- **Coordinate Normalization**: All positions in simulation are absolute; no normalization needed.\n- **JSON Schema Validation**: Enforce strict schema for construction tree (required for file validity).\n- **Physics State Extraction**: Parse simulation logs to extract:\n  - Root block trajectory (for car)\n  - Boulder trajectory (for catapult)\n  - Block integrity flags\n- **Reward Calculation**: Compute `R_valid` and `R_task` from simulated trajectories.\n\n### **3. Experimental Settings**\n- **Hardware**:\n  - **Simulation**: Unity3D + BesiegeField mod (must run on Linux/Windows with GPU acceleration).\n  - **LLM Inference**: NVIDIA A100 (80GB) GPUs for agent inference and RL.\n  - **RL Training**: 8\u00d7 A100, 48 hours.\n- **LLM Models Benchmarked**:\n  - Gemini 2.5 Pro (closed, used for dataset)\n  - Qwen2.5-14B-Instruct (open, used for cold-start and RL)\n  - Kimi K2, Llama 4 Scout, o3 (for ablation studies)\n- **Agent Prompt Templates**:\n  - Must be fixed and reproducible.\n  - Include:\n    - Task instruction\n    - Block list (27 types)\n    - Attachment rules\n    - Output format (JSON schema)\n    - (For iterative) Feedback format\n\n### **4. Hyperparameters Summary**\n| Component | Value |\n|----------|-------|\n| **Cold-Start Dataset Size** | 9,984 samples |\n| **Base Model** | Qwen2.5-14B-Instruct |\n| **Cold-Start Finetuning** | 12 epochs (supervised), QOFT (block=64), 8-bit AdamW, LR=1e-6, warmup=3% |\n| **RL Finetuning** | GRPO, LoRA rank=64, KL=0.001, LR=5e-6, gradient clip=0.5, temperature=1.0, top-p=0.95 |\n| **Batch Size** | 1 per GPU, grad accum=8 \u2192 effective=64 |\n| **Training Steps** | 400 |\n| **Rollouts per Prompt (Pass@k)** | k=64 |\n| **Search Rounds** | 10 |\n| **Candidates per Round** | 5 |\n| **Max Retries per Node** | 5 |\n| **Simulation Duration** | 5 seconds |\n| **Feedback Sampling Rate** | 0.2s intervals |\n\n### **5. Evaluation Protocol**\n- **Test Set**: 100 prompts (unseen).\n- **For each prompt**:\n  1. Run agentic workflow (single-agent, iterative, hierarchical) \u2192 generate 1 machine.\n  2. Run simulation \u2192 record metrics.\n  3. Repeat for 100 prompts \u2192 compute mean/max across all.\n- **For RL models**:\n  - Generate 64 rollouts per prompt (Pass@64).\n  - Report: Pass@1, Pass@8, Pass@64, mean, max, validity rates.\n- **Statistical Significance**: Not specified; report mean \u00b1 std over 2 random seeds (as in Fig. FIGREF102).\n\n---\n\n## **III. Ambiguities and Uncertainties**\n\n| Area | Ambiguity | Action |\n|------|-----------|--------|\n| **Attachment Faces** | Paper says \u201ceach block has one attachable face\u201d but does not define how many faces a block has or how they are indexed (e.g., 0=front, 1=back). | **Must infer from Besiege game mechanics**. Assume 6 faces per cuboid block (front, back, left, right, top, bottom). Spring has no faces. Use integer face_id (0\u20135). |\n| **Face_id for Two-Parent Blocks** | For Spring, how are `face_id_a` and `face_id_b` assigned? Is it arbitrary? | **Unclear**. Assume the first parent uses `face_id_a`, second uses `face_id_b`. Must document assumption. |\n| **Simulation Engine** | Paper says Besiege is Unity3D-based, but no public API or mod exists. | **Must build custom Unity plugin** from scratch, replicating physics, block types, and state logging. |\n| **QOFT vs LoRA in RL** | Cold-start uses QOFT, RL uses LoRA. Is this intentional? Is QOFT incompatible with RL? | **Follow paper**: Use QOFT for cold-start, LoRA for RL. No justification given; treat as experimental design. |\n| **MCTS Implementation** | No pseudocode for MCTS node structure or UCB1 parameters (c). | **Use standard UCB1 with c=1.41**. Nodes store: visit count, total reward, children list. |\n| **Environment Feedback Selectivity** | How does the querier decide *which* blocks and *when* to query? | **Unclear**. Paper says \u201cspeculation on issues\u201d. **Assume heuristic**: if boulder doesn\u2019t move \u2192 query container; if machine breaks \u2192 query last attached block. Must document heuristic. |\n| **Pass@k Rollouts** | In RL, are rollouts generated from the same prompt or different prompts? | **Per prompt**: For each test prompt, generate k=64 rollouts \u2192 pick best. |\n| **Training Data Split** | Are the 100 test prompts disjoint from the 100 cold-start prompts? | **Assume yes** (paper implies held-out). Must ensure no overlap. |\n| **Reward Threshold for Catapult** | \u201c>3m\u201d is used for validity. Is this exact? Is it a hard cutoff? | **Yes, hard cutoff**. Any boulder \u22643m \u2192 R_valid=0. |\n\n---\n\n## **IV. Implementation Roadmap (Step-by-Step)**\n\n### **Phase 1: Environment (BesiegeField)**\n1. **Build Unity3D Plugin**:\n   - Replicate 27 blocks as GameObjects with colliders and rigidbodies.\n   - Implement attachment logic: one attachable face per block (except Spring).\n   - Implement automatic connection on proximity.\n   - Log state every 0.2s: position, orientation, velocity, integrity.\n2. **Implement Simulation Controller**:\n   - Start simulation at t=0, activate powered blocks at t=2s.\n   - Terminate at t=5s or if any block breaks.\n   - Return trajectory data as JSON.\n3. **Implement JSON Parser**:\n   - Validate construction tree against schema.\n   - Detect self-collisions at placement (before simulation).\n4. **Enable Multi-Process**:\n   - Launch 8 parallel Unity instances via Docker or process spawning.\n\n### **Phase 2: Dataset & Prompt Processing**\n1. **Curate 100 prompts** (75 from community + 25 authored).\n2. **Generate 9,984 samples** using Gemini 2.5 Pro (via API) \u2192 store as JSONL.\n3. **Filter samples** using 3 criteria (parse, no collision, physics-driven).\n4. **Split into train (9,984) and test (100)** \u2014 ensure no overlap.\n\n### **Phase 3: Agent Systems**\n1. **Implement Single-Agent**:\n   - Prompt template with task, blocks, rules, output format.\n   - Call LLM \u2192 parse output \u2192 validate \u2192 simulate.\n2. **Implement Iterative Editing**:\n   - Designer \u2192 Refiner \u2192 Querier loop.\n   - Implement MCTS with 10 rounds, 5 candidates/round, 5 retries.\n   - Implement selective feedback heuristic.\n3. **Implement Hierarchical Design**:\n   - Meta-designer: prompt to generate functional block descriptions.\n   - Autoregressive builder: 3 stages, 8 agents per stage, pass only valid designs.\n\n### **Phase 4: RL Finetuning**\n1. **Cold-Start Finetuning**:\n   - Load Qwen2.5-14B-Instruct.\n   - Apply QOFT (block=64, 8-bit AdamW).\n   - Train for 12 epochs on 9,984 samples (LR=1e-6, warmup=3%).\n2. **RL Finetuning**:\n   - Initialize from cold-start model.\n   - Apply LoRA (rank=64) to all linear layers.\n   - Use `verl` framework with GRPO, KL=0.001, LR=5e-6.\n   - Train for 400 steps on 64-rollout batches (pass@64).\n3. **Evaluate on test set** \u2192 record Pass@1, Pass@64, mean, max, validity.\n\n### **Phase 5: Evaluation & Ablation**\n1. **Run all agent types** (single, iterative, hierarchical) on 100 test prompts.\n2. **Compare search strategies**: MCTS vs Best-of-5 vs Random.\n3. **Compare RL variants**: Pass@1 vs Pass@64.\n4. **Report all metrics**: file validity, spatial validity, machine validity, mean/max score, entropy.\n\n---\n\n## **V. Validation Checklist**\n\n\u2705 All 27 blocks implemented with correct physics properties.  \n\u2705 Construction tree representation matches JSON schema exactly.  \n\u2705 Global position representation implemented as baseline.  \n\u2705 Simulation logs 0.2s intervals with full state.  \n\u2705 Reward function computes `R_valid` and `R_task` as defined.  \n\u2705 Cold-start dataset: 9,984 samples, filtered, from Gemini.  \n\u2705 RL uses Qwen2.5-14B-Instruct, LoRA rank=64, GRPO, KL=0.001.  \n\u2705 400 training steps, 8 A100, batch=1, grad accum=8.  \n\u2705 Pass@k evaluated with k=64 rollouts per prompt.  \n\u2705 Hierarchical and iterative workflows implemented as described.  \n\u2705 MCTS implemented with 10 rounds, 5 candidates, 5 retries.  \n\u2705 No assumptions made beyond paper text; all ambiguities documented.\n\n---\n\nThis plan is **fully faithful** to the paper. No external assumptions are made. All implementation steps are **actionable**, **precise**, and **reproducible** using only the information provided.\n\n-----\n\n## Design\n{\n  \"file_list\": [\n    \"main.py\",\n    \"env/besiegefield.py\",\n    \"env/simulation.py\",\n    \"env/block_registry.py\",\n    \"representation/construction_tree.py\",\n    \"representation/xml_converter.py\",\n    \"agent/single_agent.py\",\n    \"agent/hierarchical_design.py\",\n    \"agent/iterative_editing.py\",\n    \"agent/querier.py\",\n    \"agent/refiner.py\",\n    \"agent/designer.py\",\n    \"agent/meta_designer.py\",\n    \"reward/calculator.py\",\n    \"dataset/curation.py\",\n    \"dataset/loader.py\",\n    \"rl/trainer.py\",\n    \"rl/grpo.py\",\n    \"rl/verl_wrapper.py\",\n    \"eval/metrics.py\",\n    \"eval/visualizer.py\",\n    \"utils/config.py\",\n    \"utils/logger.py\",\n    \"utils/validator.py\",\n    \"utils/parallel_sim.py\"\n  ],\n  \"plan\": \"Step 1: Implement the BesiegeField environment in Unity3D as a plugin with 27 predefined blocks, attachment rules, and state logging at 0.2s intervals. Step 2: Build the Construction Tree representation module to parse and validate JSON machine designs with parent-child-ID relationships. Step 3: Implement XML-to-ConstrutionTree converter for baseline representation. Step 4: Implement block registry with physics properties and attachment face indexing. Step 5: Implement single-agent module that generates construction trees from prompts using LLM API. Step 6: Implement Meta-Designer, Designer, Inspector+Refiner, ActiveEnvQuerier, and Refiner agents as modular LLM wrappers with prompt templates. Step 7: Implement hierarchical design workflow: Meta-Designer \u2192 Designer \u2192 parallel builders. Step 8: Implement iterative editing workflow with MCTS (10 rounds, 5 candidates/round, 5 retries). Step 9: Implement simulation engine that runs 5s physics simulation, computes R_valid and R_task (car: distance, catapult: height\u00d7distance with >3m threshold). Step 10: Implement ActiveEnvQuerier with selective feedback heuristic (query blocks based on failure patterns). Step 11: Curate cold-start dataset (9,984 samples) from Gemini 2.5 Pro prompts and store as JSONL. Step 12: Implement DatasetLoader to load train/test splits. Step 13: Implement QOFT-based cold-start finetuning (Qwen2.5-14B-Instruct, 12 epochs, 8-bit AdamW, LR=1e-6). Step 14: Implement GRPO RL trainer with LoRA (rank=64), KL penalty (0.001), gradient clipping (0.5), and verl framework integration. Step 15: Implement Pass@k rollout evaluation (k=64). Step 16: Implement metrics calculator for file validity, spatial validity, machine validity, mean/max scores. Step 17: Implement visualizer to render 3D models from construction tree. Step 18: Implement parallel simulation launcher (8 processes) for RL training. Step 19: Integrate all components into main.py with CLI for agent evaluation and RL training. Step 20: Run ablation studies: MCTS vs Best-of-N vs Random Search; hierarchical vs iterative; Pass@1 vs Pass@64.\",\n  \"Code structure\": [\n    {\n      \"name\": \"env/besiegefield\",\n      \"classes\": [\n        {\n          \"name\": \"BesiegeFieldSimulator\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"block_list: list[str]\", \"physics_config: dict\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"build_from_tree\",\n              \"args\": [\"construction_tree: list[dict]\"],\n              \"returns\": \"bool\"\n            },\n            {\n              \"name\": \"simulate\",\n              \"args\": [],\n              \"returns\": \"dict\"\n            },\n            {\n              \"name\": \"get_state_log\",\n              \"args\": [],\n              \"returns\": \"list[dict]\"\n            },\n            {\n              \"name\": \"check_self_collision\",\n              \"args\": [],\n              \"returns\": \"bool\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"representation/construction_tree\",\n      \"classes\": [\n        {\n          \"name\": \"ConstructionTree\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"json_data: list[dict]\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"validate\",\n              \"args\": [],\n              \"returns\": \"tuple[bool, str]\"\n            },\n            {\n              \"name\": \"to_json\",\n              \"args\": [],\n              \"returns\": \"list[dict]\"\n            },\n            {\n              \"name\": \"to_global_position\",\n              \"args\": [],\n              \"returns\": \"list[dict]\"\n            },\n            {\n              \"name\": \"get_root_block\",\n              \"args\": [],\n              \"returns\": \"dict\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"representation/xml_converter\",\n      \"classes\": [\n        {\n          \"name\": \"XMLConverter\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"from_xml_to_tree\",\n              \"args\": [\"xml_str: str\"],\n              \"returns\": \"ConstructionTree\"\n            },\n            {\n              \"name\": \"from_tree_to_xml\",\n              \"args\": [\"tree: ConstructionTree\"],\n              \"returns\": \"str\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"env/block_registry\",\n      \"classes\": [\n        {\n          \"name\": \"BlockRegistry\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"get_block_info\",\n              \"args\": [\"block_type: str\"],\n              \"returns\": \"dict\"\n            },\n            {\n              \"name\": \"is_special_block\",\n              \"args\": [\"block_type: str\"],\n              \"returns\": \"bool\"\n            },\n            {\n              \"name\": \"get_attachable_faces\",\n              \"args\": [\"block_type: str\"],\n              \"returns\": \"int\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"agent/single_agent\",\n      \"classes\": [\n        {\n          \"name\": \"SingleAgent\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"llm_model: str\", \"prompt_template: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"generate\",\n              \"args\": [\"task: str\"],\n              \"returns\": \"ConstructionTree\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"agent/meta_designer\",\n      \"classes\": [\n        {\n          \"name\": \"MetaDesigner\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"llm_model: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"generate_blueprint\",\n              \"args\": [\"task: str\"],\n              \"returns\": \"str\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"agent/designer\",\n      \"classes\": [\n        {\n          \"name\": \"Designer\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"llm_model: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"generate_design\",\n              \"args\": [\"blueprint: str\"],\n              \"returns\": \"ConstructionTree\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"agent/inspector_refiner\",\n      \"classes\": [\n        {\n          \"name\": \"InspectorRefiner\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"llm_model: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"critique\",\n              \"args\": [\"design: ConstructionTree\", \"feedback: dict\"],\n              \"returns\": \"list[ConstructionTree]\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"agent/refiner\",\n      \"classes\": [\n        {\n          \"name\": \"Refiner\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"llm_model: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"refine\",\n              \"args\": [\"design: ConstructionTree\", \"feedback: dict\"],\n              \"returns\": \"list[ConstructionTree]\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"agent/querier\",\n      \"classes\": [\n        {\n          \"name\": \"ActiveEnvQuerier\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"simulator: BesiegeFieldSimulator\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"get_minimal_feedback\",\n              \"args\": [\"task: str\", \"state_log: list[dict]\"],\n              \"returns\": \"dict\"\n            },\n            {\n              \"name\": \"selective_query\",\n              \"args\": [\"design: ConstructionTree\", \"state_log: list[dict]\"],\n              \"returns\": \"dict\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"reward/calculator\",\n      \"classes\": [\n        {\n          \"name\": \"RewardCalculator\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"task: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"compute\",\n              \"args\": [\"state_log: list[dict]\"],\n              \"returns\": \"tuple[float, bool]\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"dataset/curation\",\n      \"classes\": [\n        {\n          \"name\": \"DatasetCurator\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"prompt_file: str\", \"llm_api: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"generate_and_filter\",\n              \"args\": [],\n              \"returns\": \"list[dict]\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"dataset/loader\",\n      \"classes\": [\n        {\n          \"name\": \"DatasetLoader\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"data_path: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"load_train_val_test\",\n              \"args\": [],\n              \"returns\": \"tuple[list[dict], list[dict], list[dict]]\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"rl/trainer\",\n      \"classes\": [\n        {\n          \"name\": \"RLTrainer\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"model_name: str\", \"config: dict\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"cold_start_finetune\",\n              \"args\": [\"dataset: list[dict]\", \"epochs: int\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"rl_finetune\",\n              \"args\": [\"dataset: list[dict]\", \"steps: int\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"evaluate_pass_k\",\n              \"args\": [\"prompts: list[str]\", \"k: int\"],\n              \"returns\": \"dict\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"rl/grpo\",\n      \"classes\": [\n        {\n          \"name\": \"GRPO\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"model: nn.Module\", \"lr: float\", \"kl_coef: float\", \"clip_ratio: float\", \"lora_rank: int\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"update\",\n              \"args\": [\"batch: dict\"],\n              \"returns\": \"dict\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"rl/verl_wrapper\",\n      \"classes\": [\n        {\n          \"name\": \"VERLWrapper\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"model: nn.Module\", \"config: dict\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"rollout\",\n              \"args\": [\"prompt: str\", \"num_rollouts: int\"],\n              \"returns\": \"list[tuple[ConstructionTree, float]]\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"eval/metrics\",\n      \"classes\": [\n        {\n          \"name\": \"EvaluationMetrics\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"compute_all\",\n              \"args\": [\"designs: list[ConstructionTree]\", \"tasks: list[str]\"],\n              \"returns\": \"dict\"\n            },\n            {\n              \"name\": \"compute_validity_rates\",\n              \"args\": [\"designs: list[ConstructionTree]\"],\n              \"returns\": \"dict\"\n            },\n            {\n              \"name\": \"compute_scores\",\n              \"args\": [\"designs: list[ConstructionTree]\", \"tasks: list[str]\"],\n              \"returns\": \"dict\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"eval/visualizer\",\n      \"classes\": [\n        {\n          \"name\": \"Visualizer\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"render_machine\",\n              \"args\": [\"tree: ConstructionTree\", \"output_path: str\"],\n              \"returns\": \"None\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"utils/config\",\n      \"classes\": [\n        {\n          \"name\": \"Config\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"config_file: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"get\",\n              \"args\": [\"key: str\"],\n              \"returns\": \"Any\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"utils/logger\",\n      \"classes\": [\n        {\n          \"name\": \"Logger\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"log_file: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"info\",\n              \"args\": [\"msg: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"error\",\n              \"args\": [\"msg: str\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"debug\",\n              \"args\": [\"msg: str\"],\n              \"returns\": \"None\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"utils/validator\",\n      \"classes\": [\n        {\n          \"name\": \"JSONValidator\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"validate_construction_tree\",\n              \"args\": [\"json_data: list[dict]\"],\n              \"returns\": \"tuple[bool, str]\"\n            }\n          ]\n        }\n      ]\n    },\n    {\n      \"name\": \"utils/parallel_sim\",\n      \"classes\": [\n        {\n          \"name\": \"ParallelSimulator\",\n          \"base_class\": \"object\",\n          \"methods\": [\n            {\n              \"name\": \"__init__\",\n              \"args\": [\"num_workers: int\"],\n              \"returns\": \"None\"\n            },\n            {\n              \"name\": \"simulate_batch\",\n              \"args\": [\"trees: list[ConstructionTree]\"],\n              \"returns\": \"list[dict]\"\n            }\n          ]\n        }\n      ]\n    }\n  ],\n  \"relationships\": [\n    {\n      \"from\": \"BesiegeFieldSimulator\",\n      \"to\": \"BlockRegistry\",\n      \"type\": \"uses\"\n    },\n    {\n      \"from\": \"ConstructionTree\",\n      \"to\": \"XMLConverter\",\n      \"type\": \"uses\"\n    },\n    {\n      \"from\": \"SingleAgent\",\n      \"to\": \"ConstructionTree\",\n      \"type\": \"produces\"\n    },\n    {\n      \"from\": \"MetaDesigner\",\n      \"to\": \"Designer\",\n      \"type\": \"uses\"\n    },\n    {\n      \"from\": \"InspectorRefiner\",\n      \"to\": \"ActiveEnvQuerier\",\n      \"type\": \"uses\"\n    },\n    {\n      \"from\": \"ActiveEnvQuerier\",\n      \"to\": \"BesiegeFieldSimulator\",\n      \"type\": \"uses\"\n    },\n    {\n      \"from\": \"RewardCalculator\",\n      \"to\": \"BesiegeFieldSimulator\",\n      \"type\": \"uses\"\n    },\n    {\n      \"from\": \"RLTrainer\",\n      \"to\": \"GRPO\",\n      \"type\": \"uses\"\n    },\n    {\n      \"from\": \"RLTrainer\",\n      \"to\": \"VERLWrapper\",\n      \"type\": \"uses\"\n    },\n    {\n      \"from\": \"RLTrainer\",\n      \"to\": \"DatasetLoader\",\n      \"type\": \"uses\"\n    },\n    {\n      \"from\": \"EvaluationMetrics\",\n      \"to\": \"ConstructionTree\",\n      \"type\": \"uses\"\n    },\n    {\n      \"from\": \"Visualizer\",\n      \"to\": \"ConstructionTree\",\n      \"type\": \"uses\"\n    },\n    {\n      \"from\": \"Main\",\n      \"to\": \"SingleAgent\",\n      \"type\": \"instantiates\"\n    },\n    {\n      \"from\": \"Main\",\n      \"to\": \"HierarchicalDesign\",\n      \"type\": \"instantiates\"\n    },\n    {\n      \"from\": \"Main\",\n      \"to\": \"IterativeEditing\",\n      \"type\": \"instantiates\"\n    },\n    {\n      \"from\": \"Main\",\n      \"to\": \"RLTrainer\",\n      \"type\": \"instantiates\"\n    },\n    {\n      \"from\": \"Main\",\n      \"to\": \"EvaluationMetrics\",\n      \"type\": \"instantiates\"\n    }\n  ],\n  \"pipeline or workflow\": \"The system follows a hierarchical agent workflow: User query \u2192 Meta-Designer generates high-level blueprint \u2192 Designer generates detailed construction tree \u2192 Inspector+Refiner validates and critiques \u2192 ActiveEnvQuerier simulates and extracts feedback \u2192 Refiner proposes revisions \u2192 loop until convergence or max iterations. For RL, cold-start dataset is used to finetune Qwen2.5-14B-Instruct via QOFT, then GRPO with LoRA is applied using verl framework with Pass@k rollouts. Simulation is parallelized across 8 GPUs. Evaluation metrics (validity, mean/max scores) are computed on 100 held-out prompts. Visualization renders final designs from construction trees. All components are modular and configurable via YAML config files.\"\n}\n\n-----\n\n## Task\n[CONTENT]\n{\n  \"Required packages\": [\n    \"torch==2.1.0\",\n    \"transformers==4.38.0\",\n    \"bitsandbytes==0.41.0\",\n    \"accelerate==0.29.0\",\n    \"numpy==1.24.3\",\n    \"pyyaml==6.0.1\",\n    \"python-dotenv==1.0.0\",\n    \"requests==2.31.0\",\n    \"jsonlines==4.0.0\",\n    \"pydantic==2.5.0\",\n    \"tqdm==4.66.1\"\n  ],\n  \"Required Other language third-party packages\": [\n    \"No third-party dependencies required\"\n  ],\n  \"Logic Analysis\": [\n    [\n      \"env/block_registry.py\",\n      \"BlockRegistry class: Initializes and manages the 27 predefined blocks from Besiege. Each block has metadata: type, attachable_faces (int), is_special (bool for Spring), and physical properties (mass, friction). Must map block names to internal IDs for consistent handling. Used by ConstructionTree, BesiegeFieldSimulator, and XMLConverter. Dependencies: None.\"\n    ],\n    [\n      \"representation/construction_tree.py\",\n      \"ConstructionTree class: Parses and validates JSON machine designs. Implements validate() to check for valid IDs, parent-child links, no cycles, and correct use of parent_a/parent_b for Spring. Converts to global position representation via to_global_position(). Requires BlockRegistry to validate block types and attachment rules. Used by all agents, simulation, and evaluation. Dependencies: block_registry.py.\"\n    ],\n    [\n      \"representation/xml_converter.py\",\n      \"XMLConverter class: Converts between Besiege's default XML format and ConstructionTree. from_xml_to_tree() parses XML with global positions and reconstructs parent-child relationships using proximity logic. from_tree_to_xml() reverses the process. Used for baseline comparison. Dependencies: construction_tree.py, block_registry.py.\"\n    ],\n    [\n      \"env/besiegefield.py\",\n      \"BesiegeFieldSimulator class: Simulates machine behavior using rigid-body physics. build_from_tree() places blocks according to ConstructionTree. simulate() runs 5s simulation with gravity, logs state every 0.2s. get_state_log() returns list of per-block states (position, orientation, velocity, integrity). check_self_collision() detects overlaps before simulation. Uses BlockRegistry for block physics. Must support parallel launches via multiprocessing. Dependencies: block_registry.py, utils/parallel_sim.py.\"\n    ],\n    [\n      \"env/simulation.py\",\n      \"SimulationEngine class: Wrapper around BesiegeFieldSimulator that computes R_valid and R_task. For car: R_task = root block displacement; for catapult: R_task = max_height \u00d7 max_distance only if max_height > 3m. Returns reward tuple (float, bool). Used by RLTrainer and EvaluationMetrics. Dependencies: besigefield.py, reward/calculator.py.\"\n    ],\n    [\n      \"reward/calculator.py\",\n      \"RewardCalculator class: Implements reward logic as R = R_valid * R_task. R_valid = 1 iff file valid + no self-collision + intact after 5s. R_task = distance (car) or height\u00d7distance (catapult). Thresholds hardcoded: >3m for catapult validity. Used by simulation.py and evaluation.py. Dependencies: None.\"\n    ],\n    [\n      \"agent/single_agent.py\",\n      \"SingleAgent class: Takes task prompt and generates construction tree in one shot via LLM API (e.g., Gemini 2.5 Pro). Uses fixed prompt template with block list, rules, and output schema. Returns ConstructionTree. Used for baseline and cold-start dataset generation. Dependencies: construction_tree.py, utils/logger.py.\"\n    ],\n    [\n      \"agent/meta_designer.py\",\n      \"MetaDesigner class: Generates high-level blueprint (text) from task prompt (e.g., \\\"suspension system, lever arm, counterweight\\\"). Uses LLM with system prompt emphasizing functional decomposition. Output fed to Designer. Used in hierarchical workflow. Dependencies: single_agent.py (same LLM interface).\"\n    ],\n    [\n      \"agent/designer.py\",\n      \"Designer class: Takes blueprint from MetaDesigner and generates detailed construction tree. Uses prompt template that includes blueprint + block list + attachment rules. Returns ConstructionTree. Used in hierarchical workflow. Dependencies: construction_tree.py, meta_designer.py.\"\n    ],\n    [\n      \"agent/querier.py\",\n      \"ActiveEnvQuerier class: After simulation, extracts minimal feedback (e.g., boulder max height/distance) and performs selective queries. Heuristic: if boulder doesn't move \u2192 query Container; if block breaks \u2192 query last attached block. Returns dict with feedback keys. Used by Refiner and InspectorRefiner. Dependencies: simulation.py, construction_tree.py.\"\n    ],\n    [\n      \"agent/refiner.py\",\n      \"Refiner class: Takes design + feedback and generates multiple (\u22653) revised construction trees via LLM sampling (temperature=0.7, top_p=0.95). Implements Monte Carlo sampling for revisions. Used in iterative editing and MCTS. Dependencies: construction_tree.py, querier.py.\"\n    ],\n    [\n      \"agent/inspector_refiner.py\",\n      \"InspectorRefiner class: Combines critique and refinement. First, critiques design abstractly (e.g., \\\"missing counterweight\\\") without simulation. Then, invokes Refiner with simulation feedback. Returns list of candidate designs. Used in iterative workflow. Dependencies: refiner.py, querier.py.\"\n    ],\n    [\n      \"agent/hierarchical_design.py\",\n      \"HierarchicalDesign class: Orchestrates MetaDesigner \u2192 Designer \u2192 8 parallel builders per stage. Stage 1: 8 builders generate first functional block; Stage 2: valid designs distributed to 8 new builders for second block; etc. Only valid designs propagate. Uses ParallelSimulator for validation. Returns best design after 3\u20134 stages. Dependencies: meta_designer.py, designer.py, parallel_sim.py, construction_tree.py.\"\n    ],\n    [\n      \"agent/iterative_editing.py\",\n      \"IterativeEditing class: Implements MCTS with 10 rounds. Each round: Designer generates draft \u2192 InspectorRefiner critiques \u2192 ActiveEnvQuerier simulates \u2192 Refiner generates 5 candidates \u2192 simulate all \u2192 select best via reward. Uses 5 retries per node. MCTS nodes store visit count and total reward. Returns best design. Dependencies: designer.py, inspector_refiner.py, querier.py, refiner.py, parallel_sim.py.\"\n    ],\n    [\n      \"dataset/curation.py\",\n      \"DatasetCurator class: Loads 100 prompts (75 community + 25 authored). Calls SingleAgent with Gemini API to generate 250 machines per prompt. Filters by: (1) JSON parseable, (2) no self-collision, (3) physics-driven functionality (e.g., not a statue). Outputs 9,984 valid triples as JSONL. Dependencies: single_agent.py, construction_tree.py, utils/logger.py.\"\n    ],\n    [\n      \"dataset/loader.py\",\n      \"DatasetLoader class: Loads train/test splits from JSONL files. Splits 9,984 into train (9,884) and test (100) with no overlap. Returns list of dicts: {\\\"prompt\\\": \\\"...\\\", \\\"cot\\\": \\\"...\\\", \\\"machine\\\": [...]}. Used by RLTrainer and evaluation. Dependencies: construction_tree.py.\"\n    ],\n    [\n      \"rl/grpo.py\",\n      \"GRPO class: Implements Group Relative Policy Optimization. Takes model, LoRA rank=64, KL coefficient=0.001, clip_ratio=0.2. update() computes advantage from rollouts, applies gradient. Uses bitsandbytes for 8-bit AdamW. Requires verl framework integration for rollout sampling. Dependencies: torch, transformers, accelerate.\"\n    ],\n    [\n      \"rl/verl_wrapper.py\",\n      \"VERLWrapper class: Wrapper around verl framework. rollout() generates k=64 rollouts per prompt using temperature=1.0, top_p=0.95. Returns list of (ConstructionTree, reward). Used by RLTrainer for Pass@k evaluation. Dependencies: grpo.py, construction_tree.py, dataset/loader.py.\"\n    ],\n    [\n      \"rl/trainer.py\",\n      \"RLTrainer class: Manages cold-start and RL finetuning. cold_start_finetune() uses QOFT (block=64, 8-bit AdamW, LR=1e-6, 12 epochs). rl_finetune() uses GRPO with LoRA (rank=64, LR=5e-6, 400 steps, grad accum=8). evaluate_pass_k() runs Pass@k on test set. Uses Qwen2.5-14B-Instruct. Dependencies: grpo.py, verl_wrapper.py, dataset/loader.py, utils/config.py.\"\n    ],\n    [\n      \"eval/metrics.py\",\n      \"EvaluationMetrics class: Computes file validity, spatial validity, machine validity, mean/max simulation scores, Pass@k (k=1,8,64). Uses ConstructionTree to validate, SimulationEngine to score. Returns dict of metrics. Used in main.py for benchmarking. Dependencies: construction_tree.py, simulation.py, reward/calculator.py.\"\n    ],\n    [\n      \"eval/visualizer.py\",\n      \"Visualizer class: Renders 3D machine from ConstructionTree using Unity3D plugin or simple matplotlib-based 3D plot (fallback). Saves to PNG/PDF. Used for qualitative analysis. Dependencies: construction_tree.py.\"\n    ],\n    [\n      \"utils/config.py\",\n      \"Config class: Loads YAML config file with hyperparameters (e.g., learning rates, GPU count, simulation time). Provides get(key) interface. Used by all modules to avoid hardcoding. Dependencies: pyyaml.\"\n    ],\n    [\n      \"utils/logger.py\",\n      \"Logger class: Logs training, simulation, and agent actions to file and console. Uses timestamped entries. Used by all components. Dependencies: logging.\"\n    ],\n    [\n      \"utils/validator.py\",\n      \"JSONValidator class: Validates ConstructionTree JSON schema: required fields, type constraints, ID uniqueness. Used by ConstructionTree.validate() and dataset/curation.py. Dependencies: jsonschema (optional, if strict schema validation needed).\"\n    ],\n    [\n      \"utils/parallel_sim.py\",\n      \"ParallelSimulator class: Spawns 8 independent BesiegeFieldSimulator processes (via multiprocessing.Pool). simulate_batch() takes list of ConstructionTree and returns list of simulation results. Used by RLTrainer and hierarchical/iterative agents. Dependencies: multiprocessing, besigefield.py.\"\n    ],\n    [\n      \"main.py\",\n      \"Entry point: CLI interface. Subcommands: generate (single-agent), evaluate (agentic workflows), train (cold-start), finetune (RL), benchmark (all metrics). Loads config, initializes components, runs experiments. Uses logger, config, dataset_loader, and all agents/evaluators. Dependencies: all modules above.\"\n    ]\n  ],\n  \"Task list\": [\n    \"env/block_registry.py\",\n    \"representation/construction_tree.py\",\n    \"representation/xml_converter.py\",\n    \"env/besiegefield.py\",\n    \"env/simulation.py\",\n    \"reward/calculator.py\",\n    \"agent/single_agent.py\",\n    \"agent/meta_designer.py\",\n    \"agent/designer.py\",\n    \"agent/querier.py\",\n    \"agent/refiner.py\",\n    \"agent/inspector_refiner.py\",\n    \"agent/hierarchical_design.py\",\n    \"agent/iterative_editing.py\",\n    \"dataset/curation.py\",\n    \"dataset/loader.py\",\n    \"rl/grpo.py\",\n    \"rl/verl_wrapper.py\",\n    \"rl/trainer.py\",\n    \"eval/metrics.py\",\n    \"eval/visualizer.py\",\n    \"utils/config.py\",\n    \"utils/logger.py\",\n    \"utils/validator.py\",\n    \"utils/parallel_sim.py\",\n    \"main.py\"\n  ],\n  \"Full API spec\": \"\",\n  \"Shared Knowledge\": \"All modules share the same ConstructionTree data structure and block registry definitions. Configurations (e.g., simulation duration=5s, reward thresholds, block list) are centralized in config.yaml. Logger and validator are shared utilities. The JSON schema for machine representation is a shared contract between representation, agent, simulation, and evaluation modules.\",\n  \"Anything UNCLEAR\": \"Clarification needed on how to implement the Unity3D simulation engine: Is a pre-built Besiege mod available for public use? If not, must we simulate physics manually using PyBullet or MuJoCo? The paper assumes Unity3D but provides no API. Also unclear: whether the 8 A100 GPUs are for RL training only or also for agent inference during MCTS. Clarify if parallel simulation requires Docker or native process spawning.\"\n}\n[/CONTENT]\n\n-----\n\n## Configuration file\n```yaml\n## config.yaml\ntraining:\n  cold_start:\n    learning_rate: 1e-6\n    epochs: 12\n    batch_size: 1\n    gradient_accumulation_steps: 1\n    warmup_ratio: 0.03\n    quantization: \"QOFT\"\n    offt_block_size: 64\n    optimizer: \"8bit_AdamW\"\n  rl_finetune:\n    learning_rate: 5e-6\n    steps: 400\n    batch_size_per_gpu: 1\n    gradient_accumulation_steps: 8\n    lora_rank: 64\n    kl_penalty_weight: 0.001\n    advantage_clip_ratio: 0.2\n    rollout_temperature: 1.0\n    rollout_top_p: 0.95\n    advantage_estimator: \"Pass@k\"\n    pass_k: 64\n    gradient_clipping: 0.5\n    use_mixed_precision: true\n  hardware:\n    gpus: 8\n    device: \"cuda\"\n    parallel_sim_workers: 8\n\nmodel:\n  base_model_name: \"Qwen2.5-14B-Instruct\"\n  max_input_length: 3440\n  max_output_length: 1168\n\nsimulation:\n  duration_seconds: 5\n  state_log_interval: 0.2\n  gravity: 9.81\n  collision_threshold: 0.01\n  catapult_height_threshold: 3.0\n\nagent:\n  search_rounds: 10\n  candidates_per_round: 5\n  max_retries_per_node: 5\n  temperature: 0.7\n  top_p: 0.95\n\ndataset:\n  prompt_file: \"data/prompts.jsonl\"\n  cold_start_dataset_path: \"data/cold_start_9984.jsonl\"\n  test_prompts_path: \"data/test_prompts_100.jsonl\"\n  num_test_prompts: 100\n\ntasks:\n  car:\n    reward_metric: \"distance\"\n    validity_constraints:\n      - \"no_self_collision\"\n      - \"intact_after_simulation\"\n  catapult:\n    reward_metric: \"height_distance_product\"\n    validity_constraints:\n      - \"no_self_collision\"\n      - \"intact_after_simulation\"\n      - \"boulder_max_height_gt_3m\"\n\nlogging:\n  log_file: \"logs/experiment.log\"\n  level: \"INFO\"\n\noutput:\n  results_dir: \"results\"\n  visualizations_dir: \"visualizations\"\n  model_checkpoints_dir: \"checkpoints\"\n```\n-----\n\n## Instruction\nConduct a Logic Analysis to assist in writing the code, based on the paper, the plan, the design, the task and the previously specified configuration file (config.yaml). \nYou DON'T need to provide the actual code yet; focus on a thorough, clear analysis.\n\nWrite the logic analysis in 'env/simulation.py', which is intended for 'SimulationEngine class: Wrapper around BesiegeFieldSimulator that computes R_valid and R_task. For car: R_task = root block displacement; for catapult: R_task = max_height \u00d7 max_distance only if max_height > 3m. Returns reward tuple (float, bool). Used by RLTrainer and EvaluationMetrics. Dependencies: besigefield.py, reward/calculator.py.'.\n\n-----\n\n## Logic Analysis: env/simulation.py"}, {"role": "assistant", "content": "### **Logic Analysis: env/simulation.py \u2014 SimulationEngine Class**\n\n---\n\n#### **1. Purpose and Role in the System**\nThe `SimulationEngine` class serves as the **critical interface** between the *physical simulation* performed by `BesiegeFieldSimulator` and the *reward computation* logic encapsulated in `RewardCalculator`. It is a **wrapper** that:\n- Accepts a validated `ConstructionTree` machine design.\n- Delegates the actual physics simulation to `BesiegeFieldSimulator`.\n- Extracts the simulation state log (per-block positions, velocities, integrity at 0.2s intervals).\n- Computes the **final reward** `R = R_valid * R_task` using `RewardCalculator`.\n- Returns a **tuple `(reward_value: float, is_valid: bool)`** for downstream use by `RLTrainer`, `EvaluationMetrics`, and agentic workflows.\n\nThis class **abstracts away** the complexity of raw simulation output and ensures **consistent, task-specific reward semantics** are applied uniformly across all evaluation and training pipelines.\n\n---\n\n#### **2. Core Responsibilities**\n\n##### **A. Input Handling**\n- **Input**: A single `ConstructionTree` object (validated by `JSONValidator` and `ConstructionTree.validate()` prior to this step).\n- **Assumption**: The machine is structurally valid (no cycles, valid IDs, correct parent references). Self-collision is *not* checked here \u2014 that is handled by `BesiegeFieldSimulator.check_self_collision()` before simulation.\n- **Task Specification**: The `SimulationEngine` must be initialized with a `task: str` (either `\"car\"` or `\"catapult\"`) to determine which reward logic to apply.\n\n##### **B. Simulation Execution**\n- **Delegate to `BesiegeFieldSimulator`**:\n  - Call `simulator.build_from_tree(construction_tree)` \u2192 returns `bool` indicating if placement succeeded.\n  - If placement fails (e.g., invalid block types, missing parents), return `(0.0, False)` immediately.\n  - Call `simulator.simulate()` \u2192 runs 5-second physics simulation with gravity and powered block activation at t=2s.\n  - Call `simulator.get_state_log()` \u2192 returns a list of 25 dictionaries (5s / 0.2s = 25 time steps), each containing:\n    ```python\n    {\n      \"block_id\": int,           # ID of block (matches ConstructionTree.id)\n      \"type\": str,               # e.g., \"Starting Block\", \"Boulder\"\n      \"position\": [x, y, z],     # global 3D position at this timestep\n      \"orientation\": [qw, qx, qy, qz],  # quaternion (or Euler if preferred)\n      \"linear_velocity\": [vx, vy, vz],\n      \"angular_velocity\": [wx, wy, wz],\n      \"integrity\": 0 or 1        # 0 if broken, 1 if intact\n    }\n    ```\n- **Critical Constraint**: Simulation duration is **fixed at 5 seconds** (per `config.yaml: simulation.duration_seconds`).\n- **Powered Block Activation**: Must occur at **t=2s** (as per paper). This is handled internally by `BesiegeFieldSimulator`, so `SimulationEngine` does not need to manage it.\n\n##### **C. Validity Assessment (`R_valid`)**\n`R_valid` is a **boolean flag** determined by **three criteria**, all derived from simulation output:\n1. **File Validity**: Already ensured before simulation (by `ConstructionTree.validate()`). Not rechecked here.\n2. **Spatial Validity**:  \n   - Call `simulator.check_self_collision()` **before** `simulate()`.  \n   - If `True`, return `(0.0, False)` immediately.  \n   - *Note*: This check must be performed *before* simulation, not after.  \n3. **Integrity After Simulation**:  \n   - After simulation, scan `state_log` for any block with `integrity == 0`.  \n   - If **any** block is broken \u2192 `R_valid = False`.  \n   - For **catapult**, an **additional constraint** applies:  \n     - Must compute the **maximum height** of the **boulder** during simulation.  \n     - If `max_height <= 3.0` \u2192 `R_valid = False` (per `config.yaml: simulation.catapult_height_threshold`).  \n     - *Note*: This is **not** part of the reward function, but a **hard validity threshold**.  \n\n> \u2705 **Important**: The paper explicitly separates `R_valid` (binary) from `R_task` (scalar). `R_valid` is a gatekeeper: if `False`, `R_task` is ignored.\n\n##### **D. Task-Specific Performance Metric (`R_task`)**\n- **Car Task**:\n  - Identify the **root block** (ID=0) from `ConstructionTree`.\n  - Extract its **initial position** at t=0 from `state_log[0]`.\n  - Extract its **final position** at t=5s from `state_log[-1]`.\n  - Compute **displacement along designated direction** (paper: \u201ctowards a fixed and given direction\u201d).\n    - Assumption: Direction is **+x axis** (standard in physics engines unless specified otherwise).\n    - `R_task = |final_x - initial_x|` (scalar distance, non-negative).\n- **Catapult Task**:\n  - Identify the **boulder** block (type = \"Boulder\").\n  - Extract all its positions across the 25 timesteps.\n  - Compute:\n    - `max_height = max(y-coordinate of boulder over all timesteps)`\n    - `max_distance = max(x-coordinate of boulder over all timesteps)` (along designated direction)\n  - **Only if** `max_height > 3.0` (per config), compute:\n    - `R_task = max_height * max_distance`\n  - **If** `max_height <= 3.0`, then `R_task = 0.0` (but `R_valid` is already `False`, so final reward is 0.0 regardless).\n  - *Note*: The paper states the reward is the *product* to penalize one-dimensional extremes (e.g., high but short, or long but low). This is critical for shaping effective designs.\n\n##### **E. Output Format**\n- Always return: `(float, bool)`\n  - `float`: `R_task` value (0.0 if invalid, or computed scalar)\n  - `bool`: `R_valid` (True only if all constraints satisfied)\n- **Example**:\n  - Car: `(12.5, True)` \u2192 machine moved 12.5m without breaking.\n  - Catapult: `(0.0, False)` \u2192 boulder reached 2.8m height \u2192 invalid.\n  - Catapult: `(45.6, True)` \u2192 boulder reached 6.0m height and 7.6m distance \u2192 6.0 * 7.6 = 45.6.\n\n---\n\n#### **3. Dependencies and Integration**\n\n| Dependency | Role | How Used |\n|----------|------|----------|\n| `BesiegeFieldSimulator` | Core physics engine | `build_from_tree()`, `simulate()`, `get_state_log()`, `check_self_collision()` |\n| `RewardCalculator` | Reward logic | `compute()` method is called internally to compute `(R_task, R_valid)` \u2014 but **this is redundant**. |\n| `config.yaml` | Configuration | Read `simulation.duration_seconds`, `simulation.catapult_height_threshold`, `tasks.car.reward_metric`, `tasks.catapult.reward_metric` |\n\n> \u26a0\ufe0f **Design Note**: The `RewardCalculator` class is listed as a dependency, but **its logic is fully embedded** in `SimulationEngine`. This is intentional:  \n> - `RewardCalculator` was likely designed as a reusable module for standalone reward computation (e.g., for debugging or offline analysis).  \n> - However, in the workflow, `SimulationEngine` has **direct access** to the state log and simulation context.  \n> - **Recommendation**: `SimulationEngine` should **call `RewardCalculator.compute(state_log, task)`** to **de-couple** the reward logic and allow future reuse (e.g., in evaluation metrics).  \n> - Thus, `SimulationEngine` **does not reimplement** the reward logic \u2014 it **delegates** to `RewardCalculator` for correctness and modularity.\n\n---\n\n#### **4. Edge Cases and Failure Modes**\n\n| Scenario | Handling |\n|---------|----------|\n| **Invalid block type in tree** | Already caught by `ConstructionTree.validate()` \u2192 should never reach `SimulationEngine`. Log warning if encountered. |\n| **Boulder not found in catapult task** | If no block of type \"Boulder\" exists in `state_log`, treat as failure \u2192 `R_valid = False`, `R_task = 0.0`. |\n| **Root block missing or not ID=0** | `ConstructionTree.get_root_block()` ensures root is ID=0. If not, validation fails earlier. |\n| **State log has fewer than 25 timesteps** | Simulation terminated early (e.g., due to crash). Use available data. Compute `max_height`/`distance` over available steps. Still compute `R_valid` based on integrity. |\n| **Multiple boulders in catapult task** | Paper assumes one boulder. If multiple, use the one with **highest max_height**. Log warning. |\n| **Multiple root blocks** | Impossible by construction tree definition. Validation should catch this. |\n| **Powered blocks not activating** | Handled by `BesiegeFieldSimulator` at t=2s. `SimulationEngine` does not intervene. |\n| **Floating point precision in position** | Use `numpy.isclose()` or tolerance-based comparisons if needed (e.g., for collision detection). |\n\n---\n\n#### **5. Integration with RL and Evaluation Pipelines**\n\n- **RL Training (`RLTrainer`)**:\n  - Calls `SimulationEngine.simulate(machine)` for each rollout.\n  - Uses `(reward, valid)` to compute advantages (via `GRPO`).\n  - Uses `valid` flag to filter out invalid rollouts during training (optional, but recommended for stability).\n- **Evaluation Metrics (`EvaluationMetrics`)**:\n  - Calls `SimulationEngine.simulate()` for each test machine.\n  - Aggregates:\n    - `file_validity_rate`: from `ConstructionTree.validate()`\n    - `spatial_validity_rate`: from `BesiegeFieldSimulator.check_self_collision()`\n    - `machine_validity_rate`: from `SimulationEngine`\u2019s `is_valid`\n    - `mean/max_score`: from `SimulationEngine`\u2019s `reward_value`\n- **Agentic Workflows (Iterative Editing, Hierarchical)**:\n  - Use `SimulationEngine` to evaluate candidate designs during MCTS or builder stages.\n  - Feedback to `ActiveEnvQuerier` is derived from `state_log` \u2014 but `SimulationEngine` itself does **not** perform selective queries; that is handled upstream.\n\n---\n\n#### **6. Configuration Usage**\n\n| Config Key | Usage in `SimulationEngine` |\n|------------|-----------------------------|\n| `simulation.duration_seconds` | Used to validate number of timesteps expected (25 for 0.2s intervals). |\n| `simulation.catapult_height_threshold` | Used to enforce `R_valid` condition for catapult. |\n| `tasks.car.reward_metric` | Used to select car reward logic (`distance`). |\n| `tasks.catapult.reward_metric` | Used to select catapult reward logic (`height_distance_product`). |\n\n> \u2705 All values are loaded via `Config.get()` at initialization. No hardcoding.\n\n---\n\n#### **7. Performance and Parallelization**\n\n- **Thread Safety**: `SimulationEngine` must be **stateless**. Each instance is tied to one task and one simulator instance.\n- **Parallel Simulation**: \n  - `SimulationEngine` is used by `ParallelSimulator.simulate_batch()` \u2014 which spawns multiple processes.\n  - Each process must have its own `BesiegeFieldSimulator` instance (no shared state).\n  - `SimulationEngine` must be **picklable** (no lambda, no unpicklable closures) to work with `multiprocessing.Pool`.\n- **Memory**: State log for 25 timesteps \u00d7 27 blocks \u2248 25\u00d727\u00d7(3+4+3+3+1) = ~25\u00d727\u00d714 = ~9,450 floats per machine \u2192 ~75KB per machine. Acceptable.\n\n---\n\n#### **8. Validation and Logging**\n\n- **Logging**:\n  - On simulation failure: log `ERROR` with machine ID and reason.\n  - On catapult invalidity due to height: log `WARNING` with `max_height` value.\n  - On unexpected block types: log `WARNING` and skip.\n- **Assertions**:\n  - `assert len(state_log) == int(config.simulation.duration_seconds / config.simulation.state_log_interval)` \u2192 catches simulation misconfiguration.\n  - `assert \"Boulder\" in [b[\"type\"] for b in state_log]` for catapult \u2192 fails early if missing.\n\n---\n\n#### **9. Summary of Design Principles**\n\n| Principle | Application |\n|---------|-------------|\n| **Separation of Concerns** | `SimulationEngine` does not simulate, validate, or calculate reward \u2014 it orchestrates `BesiegeFieldSimulator` and `RewardCalculator`. |\n| **Fail-Fast** | Reject invalid machines early (before simulation) using `check_self_collision()`. |\n| **Config-Driven** | All thresholds, durations, metrics are pulled from `config.yaml`. |\n| **Deterministic** | Same machine \u2192 same simulation \u2192 same reward. No randomness in physics engine. |\n| **Reusability** | Can be used by single-agent, iterative, hierarchical, and RL pipelines identically. |\n| **Robustness** | Handles edge cases (missing boulder, early termination, multiple roots) gracefully. |\n\n---\n\n#### **10. Final Output Contract**\n\n```python\nclass SimulationEngine:\n    def __init__(self, task: str, simulator: BesiegeFieldSimulator, reward_calculator: RewardCalculator, config: Config):\n        self.task = task  # \"car\" or \"catapult\"\n        self.simulator = simulator\n        self.reward_calculator = reward_calculator\n        self.config = config\n\n    def simulate(self, machine: ConstructionTree) -> tuple[float, bool]:\n        \"\"\"\n        Simulates a machine and returns (reward, is_valid).\n        \n        Steps:\n        1. Check if machine can be built (via simulator.build_from_tree).\n        2. Check for self-collision before simulation.\n        3. Run simulation.\n        4. Extract state log.\n        5. Compute R_valid and R_task via RewardCalculator.\n        6. Return (R_task * R_valid, R_valid) \u2014 but note: R_valid already encodes the gate.\n           Actually: return (R_task, R_valid) as per RewardCalculator's contract.\n        \"\"\"\n        # Implementation details follow from above logic\n        ...\n```\n\n> \u2705 This class **does not invent** logic \u2014 it **orchestrates** and **enforces** the exact protocol defined in the paper and config.  \n> \u2705 It is the **single source of truth** for reward computation in the entire system.  \n> \u2705 It enables **reproducibility**, **modularity**, and **scalability** for RL and agentic workflows.\n\n--- \n\n**Next Steps**:  \n- Implement `SimulationEngine` using the above logic.  \n- Unit test with known valid/invalid machines.  \n- Integrate with `RewardCalculator.compute()` to avoid code duplication.  \n- Ensure compatibility with `ParallelSimulator` for multi-GPU RL training."}]