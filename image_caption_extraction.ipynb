{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3403aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PDF Figure Extractor\n",
    "This notebook extracts all figure images and their corresponding captions from a research paper (Latex),\n",
    "saving each image to disk and recording its file path–caption pairs for later analysis or dataset creation.\n",
    "\"\"\"\n",
    "import os\n",
    "from src.utils import * \n",
    "from pylatexenc.latex2text import LatexNodes2Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6012c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"data/input/latex\"\n",
    "output_path = \"data/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e479391e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file': 'data/input/latex/arXiv-2510.14980v1/iclr2026_conference.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\vspace{-3.5mm}\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/teaser_final_new.pdf}\\n  \\\\vspace{-5mm}\\n  \\\\caption{\\\\footnotesize The task of compositional machine design is illustrated in our \\\\envname environment. The figure shows a high-level sketch of the agentic workflow (w/ Gemini Pro 2.5), along with the resulting machines and their simulated performance. The design objective is to create a machine that throws boulders long distances.}\\n  \\\\label{fig:teaser_candidate}\\n  \\\\vspace{2.5mm}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/iclr2026_conference.tex', 'snippet': '\\\\begin{figure}[t!]\\n  \\\\centering\\n  \\\\vspace{-3mm}\\n  \\\\includegraphics[width=\\\\linewidth]{figures/environment_intro_cropped.pdf}\\n  \\\\captionsetup{font=footnotesize} %\\n  \\\\vspace{-6.5mm}\\n  \\\\caption{\\\\footnotesize Demonstration of the machine design tasks in our experiments. (Left: \\\\textit{car}; Right: \\\\textit{catapult}).}\\n  \\\\label{fig:task_demo}\\n  \\\\vspace{-1.5mm}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/iclr2026_conference.tex', 'snippet': '\\\\begin{figure}[t!]\\n  \\\\centering\\n  \\\\includegraphics[width=0.98\\\\linewidth]{figures/xml_intro_v2_cropped.pdf}\\n  \\\\vspace{-2.5mm}\\n  \\\\captionsetup{font=footnotesize} %\\n  \\\\caption{\\\\footnotesize Demonstration of the default XML representation and our construction tree representation. Parent block info is in blue and child info is in red.}\\n  \\\\label{fig:XML-intro}\\n  \\\\vspace{-4.5mm}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/iclr2026_conference.tex', 'snippet': '\\\\begin{figure}[t!]\\n  \\\\centering\\n  \\\\vspace{-2mm}\\n  \\\\includegraphics[width=0.98\\\\linewidth]{figures/gemini_cot_example_v3.pdf}\\n  \\\\vspace{-2mm}\\n  \\\\captionsetup{font=footnotesize} %\\n  \\\\caption{\\\\footnotesize Example CoT of inspector agents (w/ Gemini 2.5 Pro). Blue text highlights the moderate capability of LLMs in spatial reasoning and imagined physical simulation.}\\n  \\\\label{fig:gemini-cot-example}\\n  \\\\vspace{-1mm}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/iclr2026_conference.tex', 'snippet': '\\\\begin{figure}[t!]\\n  \\\\centering\\n  \\\\includegraphics[width=0.98\\\\linewidth]{figures/o3_cot_example_v4_green_cropped.pdf}\\n  \\\\vspace{-2mm}\\n  \\\\captionsetup{font=footnotesize} %\\n  \\\\caption{\\\\footnotesize Example CoT of inspector agents (w/ OpenAI o3). Red text highlights reasoning errors.}\\n  \\\\label{fig:o3-cot-example}\\n  \\\\vspace{-4.5mm}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/iclr2026_conference.tex', 'snippet': '\\\\begin{figure}[t!]\\n  \\\\centering\\n  \\\\vspace{-2mm}\\n  \\\\includegraphics[width=\\\\linewidth, clip, trim={0 0.7cm 0 0}]{figures/LLM_Comp_v4_cropped.pdf}\\n  \\\\captionsetup{font=footnotesize} %\\n  \\\\vspace{-6mm}\\n  \\\\caption{\\\\footnotesize Machines produced by agentic systems with different LLMs (Top: \\\\textit{car}; Bottom: \\\\textit{catapult}).}\\n  \\\\label{fig:test-time-scaling-comp}\\n  \\\\vspace{-1.5mm}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=0.9\\\\linewidth]{figures/game_editor_view.png}\\n  \\\\caption{\\\\footnotesize Besiege editor view.}\\n  \\\\label{fig:game_editor_view}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=0.9\\\\linewidth]{figures/block_stats.png}\\n  \\\\caption{\\\\footnotesize Common useful blocks in constructing standard machines in \\\\envname.}\\n  \\\\label{fig:block_intro}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/tasks/movement_rocky.png}\\n  \\\\caption{\\\\footnotesize Illustration of the task \\\\textit{car} / \\\\textit{movement} on a rocky terrain, a more difficult setting compared to the environment used for the \\\\textit{car} task in our experiments.}\\n  \\\\label{fig:task_movement_rocky}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/tasks/throw.png}\\n  \\\\caption{\\\\footnotesize Illustration of the task \\\\textit{catapult} / \\\\textit{throw}.}\\n  \\\\label{fig:task_throw}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/tasks/pick.png}\\n  \\\\caption{\\\\footnotesize Illustration of the task \\\\textit{pick}.}\\n  \\\\label{fig:task_pick}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/tasks/delivery.png}\\n  \\\\caption{\\\\footnotesize Illustration of the task \\\\textit{delivery} with a bump on the track.}\\n  \\\\label{fig:task_delivery}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/tasks/thru_ring.png}\\n  \\\\caption{\\\\footnotesize Illustration of the task \\\\textit{catapult} / \\\\textit{Throw} with the objective of throwing the boulder through the target ring.}\\n  \\\\label{fig:task_thru_ring}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/tasks/curved_track.png}\\n  \\\\caption{\\\\footnotesize Illustration of the task \\\\textit{car} / \\\\textit{movement} with a curved track.}\\n  \\\\label{fig:task_curved_track}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/RL_Metrics/search_strategy.png}\\n  \\\\caption{\\\\footnotesize The variation in machine average scores with the increasing number of LLM node expansion operations under different search strategies.}\\n  \\\\label{fig:search_curve}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/failure_mode_v3_cropped.pdf}\\n  \\\\caption{\\\\footnotesize Examples to illustrate failure patterns. In each example, the original machine is shown on the left and the modified machine on the right. Failure patterns are sampled from Qwen3-Coder-480B-A35B-Instruct.}\\n  \\\\label{fig:failure-mode}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/tiny_modify_v3_cropped.pdf}\\n  \\\\caption{\\\\footnotesize Illustration of how machines built with feasible high-level designs may fail due to inaccurate part placement. Machine sampled from Gemini 2.5 Pro. Left: designed machines; Right: simulation results.}\\n  \\\\label{fig:tiny-modify}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/throw_comp_v4_cropped.pdf}\\n  \\\\caption{\\\\footnotesize Boulder-throwing trajectories for various machine designs generated by Gemini 2.5 Pro. From left to right, each row first shows the machine design, followed by a time-lapsed bird’s-eye view of its throw.}\\n  \\\\label{fig:throw-traj}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/synthesised_dataset_v3_cropped.pdf}\\n  \\\\caption{\\\\footnotesize Examples of Gemini-synthesized machines.}\\n  \\\\label{fig:synthesized_dataset}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/designer_detailed_designer_cropped.pdf}\\n  \\\\caption{\\\\footnotesize Construction guidance comparison of \\\\textit{Meta Designer} and \\\\textit{Detailed Meta Designer}, sampled with Gemini 2.5 Pro.}\\n  \\\\label{fig:detailed-meta-designer}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=0.5\\\\linewidth]{figures/RL_Metrics/Catapult/score_max.png}\\n  \\\\caption{\\\\footnotesize \\\\textit{Catapult} task machine scores across RL steps. KL regularization helps the model discover better structure designs. Pass@64 is greatly more efficient at uncovering powerful machine designs. Pass@8 (roll-out 8) outperforms Pass@1 (roll-out 64) in efficiency and matches its performance with fewer roll-outs. No cold start models lack the advanced knowledge needed to find better machines.} \\\\label{fig:RL-catapult-max-score}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n    \\\\centering\\n    \\\\includegraphics[width=.5\\\\linewidth]{figures/RL_Metrics/Car/score_max.png}\\n    \\\\caption{\\\\footnotesize \\\\textit{Car} machine scores across RL steps. The RL finetuning hyperparameter setting is the same as the base hyperparameter setting of \\\\textit{Catapult}. Machine performance slightly rises as training steps increase.}\\n    \\\\label{fig:RL-car-max-score}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': \"\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/RL_Metrics/Catapult/MachineValid_Reward.png}\\n  \\\\caption{\\\\footnotesize \\\\textit{Catapult task} machine validity rate and reward non-zero rate across RL steps. The machine validity rate refers to the proportion of machines that can successfully run simulations. The reward non-zero rate represents the ratio of machines that can simulate with a non-zero reward. LLM constructs more legal machines as training steps increase, and rewards non-zero machines. Pass@8 and Pass@1 converge early. ``No KL'' fills roll-outs with failure cases, slowing performance gains. ``No cold start'' lacks design knowledge, encounters more failures than no KL, and improves validity rate most slowly. The base setting balances convergence and performance improvement.}\\n  \\\\label{fig:RL-catapult-valid-rate}\\n\\\\end{figure}\"}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/RL_Metrics/Car/MachineValid_Reward.png}\\n  \\\\caption{\\\\footnotesize \\\\textit{Car task} machine validity rate and reward non-zero rate across RL steps. The machine validity converges early and remains stable during further training.} \\\\label{fig:RL-car-valid-rate}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': \"\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/RL_Metrics/Catapult/Val_Best.png}\\n  \\\\caption{\\\\footnotesize \\\\textit{Catapult task}. Average Best@N metric. At each test step, the LLM generates 64 samples, selects the top $N$ samples, and records the maximum score. This process is repeated 1,000 times, and the mean value is calculated. Base settings (both seeds) dominates Best@N performance; excluding base settings, ``no KL'' dominates the rest. Pass@1 and Pass@8 spawn only a handful of high-performance machines. No cold start produces machines of more average quality.}\\n  \\\\label{fig:RL-catapult-best@n}\\n\\\\end{figure}\"}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/RL_Metrics/Car/Val_Best.png}\\n  \\\\caption{\\\\footnotesize \\\\textit{Car task}. Mean Best@N metrics. Similar to the machine validity rate, the Best@N performance increases quickly and remains stable in rest training periods.}\\\\label{fig:RL-car-best@n}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/RL_sample_new_v2.pdf}\\n  \\\\caption{\\\\footnotesize Qwen2.5-14B-Instruct cold started RL model \\\\textit{catapult} task sample from roll-out. Throwing distances are labeled on the bottom-right corner of the image.}\\n  \\\\label{fig:RL_best_sample}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/test_time_scaling_gallery_withcaption.pdf}\\n  \\\\caption{\\\\footnotesize The LLM inference gallery of machine-generated samples. The rows, from top to bottom, were inferred by the following models, respectively: Claude 4 Opus, Gemini 2.5 Pro, o3, Doubao Seed 1.6, and Qwen3-Coder-480B-A35B-Instruct. Throwing distances are labeled on the bottom-right corner of the image.}\\n  \\\\label{fig:test_time_scaling_gallery}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2510.14980v1/appendix.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/LLM_feed_gemini_cot_v4_cropped.pdf}\\n  \\\\caption{\\\\footnotesize Comparison between generated machines conditioned on their own CoT or Gemini-generated CoT.}\\n  \\\\label{fig:LLM-feed-gemini-cot}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2205.14135v2/figs/benchmarks.tex', 'snippet': '\\\\begin{figure}\\n\\\\centering\\n\\\\includegraphics[width=5.5in]{figs/attention_benchmarks.pdf}\\n\\\\iftoggle{arxiv}{}{\\n\\\\vspace{-1em}\\n}\\n\\\\caption{\\\\textbf{Left:} runtime of forward pass + backward pass. \\\\textbf{Right:} attention memory usage.}\\n\\\\label{fig:benchmark}\\n\\\\iftoggle{arxiv}{}{\\n\\\\vspace{-1.0em}\\n}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2205.14135v2/figs/banner.tex', 'snippet': '\\\\begin{figure*}[t]\\n}{\\n\\\\begin{figure}[t]\\n}\\n\\\\centering\\n\\\\includegraphics[width=5.5in]{figs/banner_pdf.pdf}\\n\\\\caption{\\n\\\\textbf{Left:} \\\\sysname uses tiling to prevent materialization of the large $N \\\\times N$ attention matrix (dotted box) on (relatively) slow GPU HBM. In the outer loop (red arrows), \\\\sysname loops through blocks of the $\\\\vK$ and $\\\\vV$ matrices and loads them to fast on-chip SRAM.\\nIn each block, \\\\sysname loops over blocks of $\\\\vQ$ matrix (blue arrows), loading them to SRAM, and writing the output of the attention computation back to HBM.\\n\\\\textbf{Right:} Speedup over the PyTorch implementation of attention on GPT-2.\\n\\\\sysname does not read and write the large $N\\\\times N$ attention matrix to HBM, resulting in an 7.6$\\\\times$ speedup on the attention computation.}\\n\\\\label{fig:banner}\\n\\\\iftoggle{arxiv}{}{\\n\\\\vspace{-2em}\\n}\\n\\\\iftoggle{icmlworkshop}{\\n\\\\end{figure*}'}\n",
      "{'file': 'data/input/latex/arXiv-2205.14135v2/src/exp_supp.tex', 'snippet': '\\\\begin{figure}[ht]\\n  \\\\centering\\n  \\\\includegraphics[width=0.7\\\\textwidth]{figs/gpt2_flashattn_training.pdf}\\n  \\\\caption{\\\\label{fig:gpt2_training_curve}Validation perplexity of GPT-2\\n    small/medium using two implementations.\\n    We confirm that \\\\sysname yields the same validation curves as the baseline\\n    implementation from HuggingFace.}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2205.14135v2/src/exp_supp.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=5.5in]{figs/flashattn_speedup.jpg}\\n  \\\\caption{Speedup over standard PyTorch attention at different sequence lengths, on A100.}\\n  \\\\label{fig:A100_speedup}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2205.14135v2/src/exp_supp.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=5.5in]{figs/flashattn_speedup_a100_d128.jpg}\\n  \\\\caption{Speedup over standard PyTorch attention at different sequence lengths, on A100, with head dimension 128.}\\n  \\\\label{fig:A100_speedup_128_dim}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2205.14135v2/src/exp_supp.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=5.5in]{figs/flashattn_speedup_3090.jpg}\\n  \\\\caption{Speedup over standard PyTorch attention at different sequence lengths, on RTX 3090.}\\n  \\\\label{fig:rtx3090_speedup}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2205.14135v2/src/exp_supp.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\centering\\n  \\\\includegraphics[width=5.5in]{figs/flashattn_speedup_t4.jpg}\\n  \\\\includegraphics[width=5.5in]{figs/flashattn_speedup_t4_fwd.jpg}\\n  \\\\caption{Speedup over standard PyTorch attention at different sequence lengths, on T4. \\\\textbf{Top:} Combined forward pass + backward pass. \\\\textbf{Bottom:} Forward pass only.}\\n  \\\\label{fig:t4_speedup}\\n\\\\end{figure}'}\n",
      "{'file': 'data/input/latex/arXiv-2205.14135v2/src/theory.tex', 'snippet': '\\\\begin{figure}[t]\\n  \\\\captionsetup{font=small}\\n    \\\\centering\\n    \\\\begin{minipage}{2.3in}\\n        \\\\centering\\n        \\\\resizebox{0.98\\\\linewidth}{!}\\n        {\\n        \\\\begin{tabular}{@{}c|ccc@{}}\\n          Attention & Standard & \\\\sysname \\\\\\\\ \\\\hline\\n          GFLOPs & 66.6 & 75.2 \\\\\\\\\\n          HBM R/W (GB) & 40.3 & 4.4 \\\\\\\\\\n          Runtime (ms) & 41.7 & 7.3\\n        \\\\end{tabular}\\n        }\\n    \\\\end{minipage}\\n    \\\\begin{minipage}{3in}\\n        \\\\centering\\n        \\\\includegraphics[width=3in]{figs/flashattn_micros.pdf}\\n    \\\\end{minipage}\\n    \\\\captionsetup{font=small}\\n    \\\\caption{\\\\label{fig:micros}\\n    \\\\textbf{Left}: Forward + backward runtime of\\n    standard attention and \\\\sysname for GPT-2 medium\\n    (seq.\\\\ length 1024, head dim.\\\\ 64, 16 heads, batch size 64) on\\n    A100 GPU.\\n    HBM access is the primary factor affecting runtime.\\n    \\\\textbf{Middle}: Forward runtime of \\\\sysname\\n    (seq.\\\\ length 1024, head\\n    dim.\\\\ 64, 16 heads, batch size 64)\\n    on A100 GPU. Fewer HBM accesses result in faster runtime, up to a point.\\n    \\\\textbf{Right}: The runtime (for seq.\\\\ length 4K) of\\n  block-sparse \\\\sysname is faster than \\\\sysname by a factor proportional\\n  to the sparsity.\\n    }\\n    \\\\vspace{-1.0em}\\n\\\\end{figure}'}\n"
     ]
    }
   ],
   "source": [
    "# Get list of PDF files in input directory\n",
    "papers = {}\n",
    "\n",
    "for file in os.listdir(input_path):\n",
    "    # testing\n",
    "    papers[file] = []\n",
    "    # extract raw figures\n",
    "    for i in extract_raw_figures(input_path+'/'+file):\n",
    "        \n",
    "        image_path_line = [line for line in i['snippet'].splitlines() if \"\\\\includegraphics\" in line][0]\n",
    "        print(i)\n",
    "        caption_line = [\n",
    "            line for line in i['snippet'].splitlines()\n",
    "            if re.search(r'\\\\caption(?:\\s*\\[[^\\]]*\\])?\\s*\\{', line)\n",
    "        ][0]\n",
    "\n",
    "        papers[file].append(( \\\n",
    "            os.path.join(input_path,file, extract_figure_name_and_caption(image_path_line, caption_line)[0]), \\\n",
    "            extract_figure_name_and_caption(image_path_line, caption_line)[1]\n",
    "        ))\n",
    "# for i in papers['arXiv-2205.14135v2']:\n",
    "    # print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a821c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = {'file': 'data/input/latex/arXiv-2510.14980v1/iclr2026_conference.tex', 'snippet': '\\\\begin{figure}[h!]\\n  \\\\vspace{-3.5mm}\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{figures/teaser_final_new.pdf}\\n  \\\\vspace{-5mm}\\n  \\\\caption{\\\\footnotesize The task of compositional machine design is illustrated in our \\\\envname environment. The figure shows a high-level sketch of the agentic workflow (w/ Gemini Pro 2.5), along with the resulting machines and their simulated performance. The design objective is to create a machine that throws boulders long distances.}\\n  \\\\label{fig:teaser_candidate}\\n  \\\\vspace{2.5mm}\\n\\\\end{figure}'}\n",
    "\n",
    "\n",
    "y ={'file': 'data/input/latex/arXiv-2205.14135v2/figs/banner.tex', 'snippet': '\\\\begin{figure*}[t]\\n}{\\n\\\\begin{figure}[t]\\n}\\n\\\\centering\\n\\\\includegraphics[width=5.5in]{figs/banner_pdf.pdf}\\n\\\\caption{\\n\\\\textbf{Left:} \\\\sysname uses tiling to prevent materialization of the large $N \\\\times N$ attention matrix (dotted box) on (relatively) slow GPU HBM. In the outer loop (red arrows), \\\\sysname loops through blocks of the $\\\\vK$ and $\\\\vV$ matrices and loads them to fast on-chip SRAM.\\nIn each block, \\\\sysname loops over blocks of $\\\\vQ$ matrix (blue arrows), loading them to SRAM, and writing the output of the attention computation back to HBM.\\n\\\\textbf{Right:} Speedup over the PyTorch implementation of attention on GPT-2.\\n\\\\sysname does not read and write the large $N\\\\times N$ attention matrix to HBM, resulting in an 7.6$\\\\times$ speedup on the attention computation.}\\n\\\\label{fig:banner}\\n\\\\iftoggle{arxiv}{}{\\n\\\\vspace{-2em}\\n}\\n\\\\iftoggle{icmlworkshop}{\\n\\\\end{figure*}'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957c4747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\includegraphics[width=5.5in]{figs/banner_pdf.pdf}\n",
      "\\begin{figure*}[t]\n",
      "}{\n",
      "\\begin{figure}[t]\n",
      "}\n",
      "\\centering\n",
      "\\includegraphics[width=5.5in]{figs/banner_pdf.pdf}\n",
      "\\caption{\n",
      "\\textbf{Left:} \\sysname uses tiling to prevent materialization of the large $N \\times N$ attention matrix (dotted box) on (relatively) slow GPU HBM. In the outer loop (red arrows), \\sysname loops through blocks of the $\\vK$ and $\\vV$ matrices and loads them to fast on-chip SRAM.\n",
      "In each block, \\sysname loops over blocks of $\\vQ$ matrix (blue arrows), loading them to SRAM, and writing the output of the attention computation back to HBM.\n",
      "\\textbf{Right:} Speedup over the PyTorch implementation of attention on GPT-2.\n",
      "\\sysname does not read and write the large $N\\times N$ attention matrix to HBM, resulting in an 7.6$\\times$ speedup on the attention computation.}\n",
      "\\label{fig:banner}\n",
      "\\iftoggle{arxiv}{}{\n",
      "\\vspace{-2em}\n",
      "}\n",
      "\\iftoggle{icmlworkshop}{\n",
      "\\end{figure*}\n"
     ]
    }
   ],
   "source": [
    "image_path_line = [line for line in y['snippet'].splitlines() if \"\\\\includegraphics\" in line][0]\n",
    "print(image_path_line)\n",
    "\n",
    "# print(y['snippet'])\n",
    "# print(y['snippet'])\n",
    "caption_line = [\n",
    "            line for line in y['snippet'].splitlines()\n",
    "            if re.search(r'\\\\caption(?:\\s*\\[[^\\]]*\\])?\\s*\\{', line)\n",
    "        ][0]\n",
    "\n",
    "print(y['snippet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a28528",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
