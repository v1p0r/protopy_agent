{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from utils import print_response\n",
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b31729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser for .py version\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# parser.add_argument('--paper_name',type=str)\n",
    "\n",
    "# parser.add_argument('--model_name',type=str, default=\"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\") \n",
    "# parser.add_argument('--tp_size',type=int, default=2)\n",
    "# parser.add_argument('--temperature',type=float, default=1.0)\n",
    "# parser.add_argument('--max_model_len',type=int, default=128000)\n",
    "\n",
    "# parser.add_argument('--paper_format',type=str, default=\"JSON\", choices=[\"JSON\", \"LaTeX\"])\n",
    "# parser.add_argument('--pdf_json_path', type=str) # json format\n",
    "# parser.add_argument('--pdf_latex_path', type=str) # latex format\n",
    "\n",
    "# parser.add_argument('--output_dir',type=str, default=\"\")\n",
    "\n",
    "# args    = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\"\n",
    "tp_size = 2\n",
    "temperature = 1.0\n",
    "max_model_len = 128000\n",
    "\n",
    "paper_format = \"json\"\n",
    "pdf_json_path = None\n",
    "pdf_latex_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54da717",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_msg = [{'role': \"system\", \"content\": f\"\"\"You are an expert researcher and strategic planner with a deep understanding of experimental design and reproducibility in scientific research. \n",
    "You will receive a data pair in json format. \n",
    "Your task is find the figures from the data pair with the caption by using the caption alone, and return the figure path and the caption.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Using the textual caption, find the figure from the data pair that are in one of the three \n",
    "2. Be Clear and Structured: Present the plan in a well-organized and easy-to-follow format, breaking it down into actionable steps.\n",
    "3. Prioritize Efficiency: Optimize the plan for clarity and practical implementation while ensuring fidelity to the original experiments.\"\"\"}]\n",
    "\n",
    "\n",
    "image_msg = [\n",
    "        {'role': 'user', 'content': \"\"\"You write elegant, modular, and maintainable code. Adhere to Google-style guidelines.\n",
    "\n",
    "Based on the paper, plan, design specified previously, follow the \"Format Example\" and generate the code. \n",
    "Extract the training details from the above paper (e.g., learning rate, batch size, epochs, etc.), follow the \"Format example\" and generate the code. \n",
    "DO NOT FABRICATE DETAILS â€” only use what the paper provides.\n",
    "\n",
    "You must write `config.yaml`.\n",
    "\n",
    "ATTENTION: Use '##' to SPLIT SECTIONS, not '#'. Your output format must follow the example below exactly.\n",
    "\n",
    "-----\n",
    "\n",
    "# Format Example\n",
    "## Code: config.yaml\n",
    "```yaml\n",
    "## config.yaml\n",
    "training:\n",
    "  learning_rate: ...\n",
    "  batch_size: ...\n",
    "  epochs: ...\n",
    "...\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "## Code: config.yaml\n",
    "\"\"\"\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = args.model_name\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "if \"Qwen\" in model_name:\n",
    "    llm = LLM(model=model_name, \n",
    "            tensor_parallel_size=tp_size, \n",
    "            max_model_len=max_model_len,\n",
    "            gpu_memory_utilization=0.95,\n",
    "            trust_remote_code=True, enforce_eager=True, \n",
    "            rope_scaling={\"factor\": 4.0, \"original_max_position_embeddings\": 32768, \"type\": \"yarn\"})\n",
    "    sampling_params = SamplingParams(temperature=temperature, max_tokens=131072)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llm(msg):\n",
    "    # vllm\n",
    "    prompt_token_ids = [tokenizer.apply_chat_template(messages, add_generation_prompt=True) for messages in [msg]]\n",
    "\n",
    "    outputs = llm.generate(prompt_token_ids=prompt_token_ids, sampling_params=sampling_params)\n",
    "\n",
    "    completion = [output.outputs[0].text for output in outputs]\n",
    "    \n",
    "    return completion[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "trajectories = []\n",
    "total_accumulated_cost = 0\n",
    "output_dir = \"./image_agent_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776151af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, instruction_msg in enumerate([caption_msg, image_msg]):\n",
    "    current_stage = \"\"\n",
    "    if idx == 0 :\n",
    "        current_stage = f\"[image_agent] Caption extraction\"\n",
    "    elif idx == 1:\n",
    "        current_stage = f\"[image_agent] extract \"\n",
    "    print(current_stage)\n",
    "\n",
    "    trajectories.extend(instruction_msg)\n",
    "\n",
    "    completion = run_llm(trajectories)\n",
    "    \n",
    "    # response\n",
    "    completion_json = {\n",
    "        'text': completion\n",
    "    }\n",
    "\n",
    "    # print and logging\n",
    "    print_response(completion_json, is_llm=True)\n",
    "\n",
    "    responses.append(completion_json)\n",
    "\n",
    "    # trajectories\n",
    "    trajectories.append({'role': 'assistant', 'content': completion})\n",
    "\n",
    "\n",
    "# save\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(f'{output_dir}/planning_response.json', 'w') as f:\n",
    "    json.dump(responses, f)\n",
    "\n",
    "with open(f'{output_dir}/planning_trajectories.json', 'w') as f:\n",
    "    json.dump(trajectories, f)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
